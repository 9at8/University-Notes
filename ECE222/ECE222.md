ECE222
======

Section 001 (mixed engineering)

    Andrew Morton
    arrmorto@uwaterloo.ca

# 14/9/15

Computer architecture and assembly language programming.

There's a single Saturday lecture to make up for Thanksgiving Monday, sometime on the 1:30-2:20 slots. There are 6 make-up lecture slots on Fridays at 1:30 PM-2:20 PM.

Midterm on October 28 at 8:30 AM, 75 minutes. Textbook is optional but recommended.

No tutorials for the first week. Tentative office hours for this section are Wednesdays at 12:30 PM.

Finding the magnitude of a negative two's complement number is done by flipping all of the bits and adding one, but a better way is to flip all the bits left of the rightmost 1, and interpreting the resulting number as the unsigned binary magnitude.

# 16/9/15

Continuation of number sysytems and binary - see CS241 and ECE214e notes for reference.

Overflow occurs when the result cannot be represented using the given number of bits, such as when two excessively large unsigned values are added together to get a value larger than $2^n - 1$. It is always important to check for overflow when doing arithmetic. In computers, there is usually an overflow flag in a status register.

For subtraction, the overflow/borrow bit represents whether the sign of the result differs from the sign of either operand - if there are both positive and negative values as the operands and result.

**Sign extension** is the replication of the leftmost bit to make a binary number of a particular width larger. For example, sign extending 1010 to 8 bits results in 11111010.

Computers can be general purpose or application-specific. Types of computers include personal computers, workstations, mainframes, supercomputers, embedded computers.

# 18/9/15

Hack the North starts today at 6PM! Lab 0 is done individually but you should still have a partner.

A **programmable computer** is a device that can store a sequence of instruction, execute a stored sequence of instructions, and conditionally select a path of execution (control transfer). One of the first computers programmable computers designed was mechanical - the analtyical engine by Charles Babbage.

Some of the tehnologies used for programmable omputers are mechanical, vacuum tube, transistors, integrated circuits, VLSI, and nanotechnological integration.

The Harvard Mark I (1944) was the first computer to implement the Harvard architecture (separate code and data). The Manchester Baby (1948) was the first to implement the von Neumann architecture (code in same memory as data).

A **digital computer** uses digital electronic circuits to implement a programmable computer. Generally, these consist of input/output (keyboards, monitors, and network cards), memory, and the CPU (the ALU and control unit), as well as the interconnection network that connects these all together.

For this course, memory will be represented as an array of bytes. The **word length** of the computer depends on the processor, and these days is generally 16, 32, or 64 bits. A computer with word length $n$ has words of $n$ bits - a word would be an $n$ bit binary number. A **long word** is a $2n$ bit binary number.

A memory unit has a clock, read enable, write enable, and address inputs, and has data output. Most computers have multiple levels of memory, from closer to the processor (fastest) to farthest from the processor (slower):

* Registers are the fastest memory, being built into the processor, but are very small, storing only a few bytes.
    * These generally are just implemented with flip-flops.
* Caches are also generally built into the processor further away, and can store several kilobytes or megabytes.
    * There are often separate instruction and data caches.
    * Caches implement temporal locality (recently accessed data can be retrieved again faster) and spatial locality (fetch nearby memory faster, such as fetching the next few instructions to execute).
    * There can also be multiple levels of caches, from L1 (fastest/smallest) to L3 (slowest/largest).
    * Caches use SRAM for memory, which is basically just a series of flip-flops.
* Primary memory (RAM) is a lot slower, but can store gigabytes.
    * This is generally implemented with DRAM, which is basically just a transistor switching the high voltage to a capacitor that is also connected to ground.
    * DRAM is much smaller, but needs to be refreshed and works slower.
* Secondary memory (hard drives/SSDs) are extremely slow, and can store gigabytes and terabytes of data.

In each level, we can store exponentially more data, but it takes an exponentially longer time to read or write.

# 16/9/15 - Additional Lecture

Modern CISC CPUs translate complex machine code into microcode/microops first, then execute those simpler instructions. CPUs have to fetch the operation, fetch the operands, perform the operaion, then store the result.

The current instruction is stored in the **instruction register** (IR), and the address of the next instruction is always the value in the **program counter** (PC). The **memory address register** (MAR) contains the current memory address to read or write to if applicable. The **memory data register** (MDR) contains the current data to read or write to memory if applicable. The general purpose registers hold data and addresses.

The control unit drives the ALU to execute instructions.

A **bus** is a set of wires that can have different writers and readers at different times. One unit may write to the bus at a time, but many can read from it at any time. Writing to a bus is called **bus driving**. Since short circuits can occur if two units drive the bus at the same time, the control unit in CPUs manages which unit is allowed to drive at any time. Buses are often implemented using tri-state buffers.

A CPU is connected to memory and I/O via a bus. Nowadays, however, the limitation that only one unit can write at a time is too restrictive, so we use multiple buses. Modern bus standards include PCI, PCIe, and USB.

Since the CPU's connection to memory and I/O is both over a bus, I/O is generally treated a lot like memory. This allows techniques such as **memory-mapped I/O**, where I/O listens on the bus for reads and writes to certain addresses, and dispatches actions based on that. This allows simpler I/O access from the CPU by simply using the standard memory manipulation instructions.

An **instruction** is a command tha tells the CPU to do something like move data, transfer control flow, or do math. A **program** is a sequence of instructions.

For every instruction, the CPU must fetch the instruction, decode which one it is, fetch the operands if applicable, perform the operation, then store the results if applicable.

We access memory by address - each address represents a unit of memory. For most computers, each byte is assigned an address - this is **byte addressable memory**. Some systems assign one address per word instead - this is **word addressable memory**. For example, MIPS has an address for each byte, but memory can only be accessed if it's aligned to a word boundary.

In SI, a kilobyte is $10^3$ bytes, or 1 kB, and a kibibyte is $2^{10}$, or 1 KiB. The same goes for megabyte ($10^6$ bytes, or 1 MiB) vs. mebibyte ($2^{20} bytes$), gigabyte vs. gibibyte, terabytes vs. tibibytes, petabytes vs. pebibytes, and exabytes vs. exbibytes. This is because the standard SI prefixes should always refer to powers of 10, while the powers of 2 get different prefixes. KB is an incorrect unit, since uppercase K represents Kelvin.


# 21/9/15


For most computers, and especially for the computers in our course, word sizes are 32 bits, and characters are 1 byte. The default text encoding we will use is ASCII. We will also assume our systems are byte addressable.

The **byte ordering/endianness** of the computer determines how the bytes of numbers are ordered physically in memory. The **little endian** byte ordering is the most common, and assigns the less significant digits in the number to the bytes at smaller addresses, and the more significant digits to the bytes at larger addresses. For example, 0x1234 is represented as consecutive bytes 0x04, 0x03, 0x02, and 0x01. The **big endian** byte ordering is the opposite order, and 0x1234 is represented wth the consecutive bytes 0x01, 0x02, 0x03, and 0x04. While big endian looks more like the human representation of the number, little endian is more logical for things like arrays of numbers. Some architectures like PowerPC support switching between either convention.

The endianness of numbers is very important if transferring data between computers. The same bytes read on a big endian machine will result in a different number than one read on a little endian machine. Most networking stacks will handle this automatically, but sometimes it is necessary to read/write the bytes in an explicit, fixed byte order to ensure all computers can read it the same.

Lowercase and uppercase letters in ASCII differ only by one bit. In order to make this work, though, the lowercase and uppercase characters are not adjacent in the ASCII table.

What the Control key does is it hides the top nibble of the character - for example, Ctrl + C hides the top bits of C (0x43), to get 0x03, the end of text character.

An address on a byte-addressible computer is **aligned** if it is a multiple of the word size. For example, on a 32-bit computer an address is aligned if it is a multiple of 4. Unaligned addresses may take longer to access, or even be forbidden by the architecture - ARM, for example, will raise an exception/interrupt upon unaligned accesses.

Every processor will have instructions for data transfer between memory and registers, arithmetic/logic, braching/jumping/control flow, and I/O (generally memory mapped, so these can just be the same as for data transfer between memory and registers).

The **instruction set architecture** (ISA) specifies how a processor works - the instructions of a processor (the operations and their format), the registers, control registers, memory layout (like memory banks), exceptions, and so on. Examples of ISAs are ARM, x86, MIPS, and SPARC. There are often variations and flavors of each ISA, like the 64-bit variant of x86, x86-64.

A **reduced instruction set computer** (RISC) ISA has a fixed size for each instruction (each instruction takes the same number of bits), and have a load/store architecture (memory is accessed only via load/store instructions, and all other operations work on registers). RISC ISAs are simpler to construct and understand - for example, the fixed sized instructions mean decoding is a lot easier.

In contrast, a **complex instruction set computer** (CISC) ISA can have variable length instructions, and many instructions can also do things like accessing memory. These are harder to construct, but we can do more with each instruction - each instruction is harder to decode, because we have to read some of it first to know how much to keep reading.

# 23/9/15

Assemly language is a symbolic representation of machine code. It uses mnemonics to represent operations/instructions. See CS241 notes for basic overview of language format.

Assembly language uses **register transfer level** notation:

* `R0` through to `R15` are names for general purpose registers.
* Control registers/signals are reserved bare words, like `T1` and `T2`.
* Other bare identifiers are memory locations (like labels) - `some_label`.
* Square brackets around a memory location or register represent the value at that memory location or memory address - `[R0]` means "value of `R0`" while `[LOCATION]` means `*R0` in C.
* Square brackets can be nested - `[[LOCATION]]` means `**LOCATION`.

RTL notation is not standardized and may differ between texts.

RTL notation  can represent instructions in terms of how they manipulate data, like $R1 \leftarrow [LOCATION]$, or $\text{if } [R0] == 1 \text{ then } R0 = 50$. Notation like $R1 \leftarrow [R1] + [LOCATION]$ makes it immediately obvious what the instruction does.

RTL notation can also be used to describe instructions in assembly language in a more comprehensible way. For example, `ADD R0, R1, R2` can be written as $R0 \leftarrow [R1] + [R2]$, `LOAD R0, LOCATION` can be written as `R0 \leftarrow [LOCATION]`, and `STORE R0, LOCATION` can be written as `LOCATION \leftarrow [R0]`.

Since registers don't have addresses, they will never appear on the right side of the $\leftarrow$ in square brackets.

Some instructions can have literal values as well, called **immediate values**. For example, `SUBTRACT R2, R2, 5`, which can be written as $R2 \leftarrow [R2] - 5$, has the immediate value 5.

Branching in RTL notation simply sets the control register `PC`. For example, `BRANCH_IF_ZERO R0, LOOP` can be written as $\text{if } [R0] == 1 \text{ then } PC \leftarrow LOOP$.

**Addressing modes** are different ways to specify where to find the operand of an instruction. The location/type of operand results in an **effective address**, when applicable. The effective address is where we would write to if that operand is an output, and is similar to the address of an lvalue in C.

# 25/9/15

A good resource for learning ARM is the [Davespace ARM reference](http://www.davespace.co.uk/arm/).

The **immediate** addressing mode means that the operand is a constant - we simply put the constant directly in the instruction. For example, the `#2` ($2$) in `MOVE R0, #2` $R0 \leftarrow 2$. Since the constant is inside the instruction, and the instruction itself needs to take up some bits, the constants must be smaller than the word size.

The **register** addressing mode means that the operand is a register. For example, the `R0` ($[R1]$) in `MOVE R0, R1` ($R0 \leftarrow [R1]$). The effective address here is $R1$.

The **absolute/direct** addressing mode means that the operand is a known, fixed address in memory. For example, the `LABEL` ($LABEL$) in `JUMP LABEL` ($PC \leftarrow LABEL$). The effective address here is $LABEL$. Note that this addressing mode is generally only supported for control flow instructions like JUMP - for MOVE, we would use something like `MOVE R0, #LABEL` to store the address of the label itself.

The **register indirect** addressing mode means that the operand is the contents of the memory address specified by a register, like dereferencing a pointer. For example, the `[R1]` ($[[R1]]$) in `LOAD R0, [R1]` ($R0 \leftarrow [[R1]]$). The effective address here is $R0$. This is also sometimes denoted`(R1)` (parentheses rather than square brackets).

Here is an assembly program to sum an array of numbers and store it in ARRAY_SUM, in a pseudo-assembly language:

    LOAD R2, ARRAY_LENGTH
    CLEAR R3
    MOVE R4, #ARRAY_START
    LOOP: LOAD R5, [R4]
    ADD R3, R3, R5
    ADD R4, R4, #4
    SUBTRACT R2, R2, #1
    BRANCH_IF_NONZERO R2, LOOP
    STORE R3, ARRAY_SUM

The **index** addressing mode is a useful extension of indirect addressing, where the operand is the contents of the memory address specified by a register plus a constant address. For example, the `5(R1)` ($[[R0] + 5]$) in `MOVE R0, 5(R1)` ($R0 \leftarrow [[R1] + 5]$). The effective address here is $[R1] + 5$. Note that in the code, all constants are generally decimal. This addressing mode is very useful for working with structs.

The **base with index** addressing mode is an even more flexible extension of indirect addressing, where the operand is the contents of the memory address specified by a register (specifying the base address) plus another (specifying an offset). For example, the `[R1, R2]` ($[[R1] + [R2]]$) in `MOVE R0, [R1, R2]` ($R0 \leftarrow [[R1] + [R2]]$). The effective address here is $[R1] + [R2]$. This addressing mode is very useful for working with arrays.

# 28/9/15

The **base with index and offset** addressing mode combines the above two, where there is a base address and an offset. For example, the `5(R1, R2)` ($[R1] + [R2] + 5$) in `MOVE R0, 5(R1, R2)` ($R0 \leftarrow [R1] + [R2] + 5$). The effective address here is $[R1] + [R2] + 5$.

The **PC-relative** addressing mode is similar to the index addressing mode, but the offset is always added to the program counter. For example, the `5(PC)` ($[PC] + 5$) in `MOVE R0, 5(PC)` ($R0 \leftarrow [PC] + 5$). The effective address here is $[PC] + 5$. When a PC-relative operand is a label, the assembler will generally convert that into the `OFFSET(PC)` form automatically - `SOME_LABEL BRANCH_IF_ZERP R0, SOME_LABEL` gets translated to `SOME_LABEL BRANCH_IF_ZERP R0, -4(PC)`. This is very useful for branch instructions.

The **auto-increment** addressing mode is similar to register indirect addressing, but the register is incremented by the number of bytes to read after the read occurs. For example, the `[R1]+` ($[[R1]]$ then $R1 \leftarrow [R1] + 4$) in `LOAD R0, [R1]+` ($R0 \leftarrow [R1] + 4$ then $R1 \leftarrow [R1] + 4$). This is very useful for working with stacks and queues, especially in combination with auto-decrement addressing.

There is also the **auto-decrement** addressing mode, which is simply `-[R1]` rather than `[R1]+`. The register is decremented by the amount to be read before the read occurs. There are also the `[R1]-` and `+[R1]` modes, which do the writing in the opposite order as `-[R1]` and `[R1]+`.

The **call stack** is used for many things, such as subroutine parameters, return addresses, and local variables. The stack starts at the highest memory address, and grows downward. The top element of the stack is always pointed to by the `SP` register. To push onto the stack, we decrement SP and write in the data we want to push onto the stack. To pop off the stack, we read out the top element, and then increment SP.

A subroutine is a block of instructions that can be executed repeatedly - this is good for deduplication and modularity. Subroutines can be called using the `CALL` instruction, and return using the `RETURN` instruction.

When we do a call, we need to save the return address somewhere. We may store it on the stack, but starting with MIPS, RISC processors started putting the return address in the link register (`LR`). x86, on the other hand, stores the return address on the call stack.

# 30/9/15

On our ARM machines, R13 is the stack pointer, R14 is the link register, and R15 is the program counter.

To make a call, we use the `CALL SOME_SUBROUTINE` instruction, which stores the value of PC in the link register, and branch to the target of the call. To return, we use the `RETURN` instruction to jump back to the address saved in that link register.

If we call a subroutine and within that subroutine, call another subroutine, the link register's value (the return address) gets overwritten by the inner call. To retain the return addresses, we push the link register contents to the stack before calling the inner subroutine, and pop it off ino the link register again after calling it. This can fail if there is a stack overflow or the stack is managed incorrectly.

**Parameters** can be passed using registers, memory locations, and on the stack.

Parameters are passed using registers if and only if there are few parameters, the subroutine is non-recursive, and the subroutine does not call other subroutines that use those same registers. Passing by registers is the fastest option, since it avoids main memory accesses.

Passing parameters using memory locations is rarely used - it's analogous to passing values using global variables.

In all other situations, parameters are passed on the stack, by pushing the last parameter to the first parameter, calling the subroutine, and then popping off all the parameters again - the caller manages the parameter pushing and popping.

Using registers:

    ; N is the array length, NUM_1 to NUM_N are the elements of the array
    LOAD R2, N
    MOVE R4, #NUM1
    CALL LISTADD ; call LISTADD subroutine
    STORE R3, SUM
    
    LISTADD:
    ; R2 is the array length, R4 is the address of the first element - we pass parameters in registers
    ; push R5 on the stack so we can restore it later
    STORE R5, -(SP)
    
    CLEAR R3 ; R3 stores the result
    LOOP:
    ; we can freely modify the parameters as we want to
    LOAD R5, (R4)+
    ADD R3, R3, R5
    SUBTRACT R2, R2, #1
    BRANCH_IF_NONZERO R2, LOOP
    
    ; restore R5 and return - R3 contains the result by this point
    LOAD R5, (SP)+
    RETURN

Using the stack:

    ; N is the array length, NUM_1 to NUM_N are the elements of the array
    MOVE R2, #NUM1
    STORE R2, -(SP) ; second parameter
    LOAD R2, N
    STORE R2, -(SP) ; first parameter
    CALL LISTADD ; call LISTADD subroutine
    ADD SP, SP, #4 ; pop the first parameter off
    LOAD R2, (SP)+ ; pop the second parameter off - the result is stored in this space
    STORE R2, SUM ; save the result to SUM
    
    LISTADD:
    ; push R2, R3, R4, R5 on the stack so we can restore it later
    STORE R2, -(SP)
    STORE R3, -(SP)
    STORE R4, -(SP)
    STORE R5, -(SP)
    
    CLEAR R3 ; R3 stores the temporary result
    LOOP:
    LOAD R5, (R4)+
    ADD R3, R3, R5
    SUBTRACT R2, R2, #1
    BRANCH_IF_NONZERO R2, LOOP
    STORE R3, 20(SP) ; store the result in the space originally used for the first parameter passed on the stack
    
    ; restore R2, R3, R4, R5 and return - top of stack contains the result by this point
    LOAD R2, (SP)+
    LOAD R3, (SP)+
    LOAD R4, (SP)+
    LOAD R5, (SP)+
    RETURN

# 2/10/15

When we enter a subroutine, we push the **frame pointer** (`FP`), followed by spaces for the local variables, followed by saved registers - together, these form a **stack frame**.

The frame pointer is used as a convenient way to refer to local variables and saved registers - even as the stack pointer changes as we're using it, the frame pointer doesn't change. The parameters are at a positive offset from the frame pointer, while local variables and saved registers are at a negative offset.

    LOAD R2, PARAM2
    STORE R2, -(SP)
    LOAD R2, PARAM1
    STORE R2, -(SP)
    CALL SUB1
    LOAD R2, (SP) # obtain return value
    ADD SP, SP, #8 # pop all parameters off the stack
    
    SUB1:
    # save registers
    STORE LINK_REG, -(SP)
    STORE FP, -(SP)
    MOVE FP, SP # initialize frame pointer to between parameters and local variables
    STORE R2, -(SP) # local variable for parameter
    STORE R3, -(SP) # local variable for parameter
    STORE R4, -(SP) # local variable
    STORE R5, -(SP) # local variable
    LOAD R2, 8(FP) # get first parameter
    LOAD R3, 12(FP) # get second parameter
    
    ; do stuff
    ; we can use -4(FP) to -16(FP) to refer to the local variables
    
    ; call another subroutine
    LOAD R4, PARAM3
    STORE R4, -(SP)
    CALL SUB2
    LOAD R4, (SP)+ # obtain return value
    
    ; do other stuff
    
    # save the result onto the stack
    STORE R5, 8(FP) # the space used by the first parameter
    
    # restore registers
    LOAD R5, (SP)+
    LOAD R4, (SP)+
    LOAD R3, (SP)+
    LOAD R2, (SP)+
    LOAD FP, (SP)+
    LOAD LINK_REG, (SP)+
    RETURN
    
    SUB2:
    # save registers
    # we don't have to store LINK_REG because we aren't making any other subroutine calls
    STORE FP, -(SP)
    MOVE FP, SP # initialize the frame pointer to between parameters and local variables
    STORE R2, -(SP) # local variable for parameter
    STORE R3, -(SP) # local variable
    LOAD R2, 4(FP) # get the parameter
    
    ; do stuff
    ; we can use -4(FP) and -8(FP) to refer to the local variables
    
    # save the result onto the stack
    STORE R3, 4(FP) # the space used by the first parameter
    
    # restore registers
    LOAD R3, (SP)+
    LOAD R2, (SP)+
    LOAD FP, (SP)+
    RETURN

# 2/10/15 - Additional Lecture

In addition to arithmetic instructions like `ADD` and `SUB`, we also have logical operations like `AND DEST, A, B`, `OR DEST, A, B`, `SHIFTL DEST, VALUE, AMOUNT`, `SHIFTR DEST, VALUE, AMOUNT`, `ROTATEL DEST, VALUE, AMOUNT`, `ROTATER DEST, VALUE, AMOUNT`. Rotating without carry rotates ignoring the carry bit, but the bit that corresponds to it is still stored in the carry bit.

ARM ISA
-------

The **assembler** is responsible for generating the machine language program from the assembly code. The three operand instructions need to fit into a single word, while also supporting immediate values. Instructions in ARM take the following form:

ARM instructions have a fixed length (32 bits) and only access memory using dedicated load/store instructions, which puts them in the RISC category. However, there are also a variety of CISC-like features, such as the many addressing modes, conditionally executing instructions, and store/load of multiple registers.

ARM memory is byte addressable with 32-bit addresses, and supports little and big endian representations, configurable to either. It supports aligned 32-bit words, 16-bit half words, and bytes.

ARM has 16 data registers, R0 to R15. R15 is the program counter, R13 is conventionally used as the stack pointer, and R14 is conventionally used as the link register. The CPSR/PSR register contains various status bits, such as negative (`N`), zero (`Z`), overflow (`V`), carry (`C`), and interrupt masks. These status codes are used by instructions that explicitly specify that they access the status bits, and are also used by the condition bits on conditional instructions.

In ARM, all the addressing modes except for immediate/register direct are derived from indexed addressing. The offset can be specified as an immediate value, or another register.

The instructions we have been using so far are similar to ARM, but not the same. For example, `MOVE R0, R1` is actually `LDR R0, R1` (load register) - `LDR` supports a register or an immediate value for the value to load. This can be used to do register direct (`LDR R0, R1`), immediate value (`LDR R0, #123`), and PC-relative addressing (`LDR R0, SOME_LABEL`).

Arithmetic/logic instructions are largely the same, such as `ADD DEST, ADDEND, ADDEND` (addition), `SUB DEST, MINUEND, SUBTRAHEND` (subtraction), and `MUL DEST, MULTIPLICAND, MULTIPLICAND`. For these, the second source operand (a source operand is an operand that is not a destination - one that is not written to) can either be a register or an immediate value (the immediate values have some restrictions, which are managed by the assembler).

# 5/10/15

Addressing modes in ARM:

* PC-relative addressing: `LDR R0, LABEL` translates to $R0 \leftarrow [PC] + offset(LABEL)$, where $offset(label)$ is the relative offset of the label.
* Pre-index addressing (analogous to index addressing): `LDR R0, [R1, #25]` translates to $R0 \leftarrow [[R1] + 25]$.
* Pre-index addressing with writeback (analogous to auto-increment/auto-decrement addressing): `LDR R0, [R1, #4]!` translates to $R0 \leftarrow [[R1] + 4]; R1 \leftarrow [R1] + 4$.
* Pre-index addressing with offset: `LDR R0, [R1, R2]` translates to $R0 \leftarrow [[R1] + [R2]]$, and `LDR R0, [R1, -R2]` translates to $R0 \leftarrow [[R1] - [R2]]$. Also works with writeback mode.
* Pre-index addressing with offset and index: `LDR R0, [R1, R2, #-5]` translates to $R0 \leftarrow [[R1] + [R2] - 5]$, and `LDR R0, [R1, -R2, 5]` translates to $R0 \leftarrow [[R1] - [R2] + 5]$. Also works with writeback mode.
* Post-index addressing with write-back (analogous to auto-increment/auto-decrement): `LDR R0, [R1], #4` translates to $R0 \leftarrow [[R1]]; R1 \leftarrow [R1] + 4$.
* Post-index addressing with write-back and offset: `LDR R0, [R1], R2` translates to $R0 \leftarrow [[R1] + [R2]]; R1 \leftarrow [R1] + [R2]$, and `LDR R0, [R1, -R2]` translates to $R0 \leftarrow [[R1] - [R2]]; R1 \leftarrow [R1] - [R2]$.
* Post-index addressing with write-back and offset and index: `LDR R0, [R1], R2, #-5` translates to $R0 \leftarrow [[R1]]; R2 \leftarrow [R1] + [R2] - 5$, and `LDR R0, [R1, -R2, 5]` translates to $R0 \leftarrow [[R1]]; R1 \leftarrow [R1] - [R2] + 5$.

All of these addressing modes can be used each of the memory instructions.

Additional memory operations include `LDR`/`STR` (load/store register), `LDRH`/`STRH` (zero-extended load/store half-word), `LDRB`/`STRB` (zero-extended load/store byte), and `LDRSH`/`LDRSB` (sign-extended load half-word/byte).

There are also instructions to access multiple consecutive memory locations, `LDM R0!, {R1, R3, R5}`/`STM R0!, {R1, R3, R5}` (load/store multiple) means $R1 \leftarrow [R0] + 0; R3 \leftarrow [R0] + 4; R5 \leftarrow [R0] + 8$. The `!` is optional in each case, and means that the address of the last value loaded should be written back into `R0`.

For certain arithmetic/logic/move instructions like `ADD` and `MOV`, we can also apply some operations to the second source operand before performing the operation. For example, `ADD, R0, R1, R2, OPERATION` where `OPERATION` is a value like `LSL #5`/`LSR #5` (left-shift/right-shift R2 by 5), `ASR #5` (arithmetic shift R2 right by 5 bits; basically right-shift with sign extension), `ROR #5` (rotate R2 right by 5 bits). Internally, the `LSL DEST, SRC, AMOUNT`, `LSR DEST, SRC, AMOUNT`, and other shifting instructions are translated into moves using these operations.

The `MOV R0, REGISTER_OR_VALUE` instruction is like a more limited but smaller version of `LDR R0, REGISTER_OR_VALUE` - it can only set a register to another register's value, or an immediate value (which has some restrictions, managed by the assembler). `MVN R0, REGISTER_OR_VALUE` is the same as `MVN R0, REGISTER_OR_VALUE`, but R0 is set to the bitwise NOT of `REGISTER_OR_VALUE` rather than the plain value. Also, MOV supports the additional operations on the second source operand (like shifting and rotating), while `LDR` does not.

Logical operations in ARM include `AND` (bitwise AND), `ORR` (bitwise OR), and `EOR` (bitwise XOR). These also support the operations on the second operand.

The test instructions are used to do comparisons, and are often used with the conditional branching instructions. `TST R0, #1` does a logical AND between R0 and 1, then sets the Z status bit according to whether the result is 0. `TEQ R0, 5` does a logical XOR between R0 and 1, then also sets Z according to the result. `CMP R0, R1` subtracts R1 from R0, then updates the Z, N, and possibly other status bits according to the result. Note that these write only to the status bits, not to the registers themselves.

The test instructions always write to the status registers. Arithmetic/logic/move instructions can do this too, if we use the S variant of them. For example `ADDS` does the same thing as `ADD`, but also sets status bits like carry, zero, and negative.

The branch instructions are used to modify control flow, often conditionally based on the status bits. There are several of these instructions, all beginning with B and having the form `BCONDITION LABEL` (the operand uses PC-relative addressing):

* Unconditional/always: `B LABEL`/`BAL LABEL` branches unconditionally to `LABEL`.
* Equality: `BEQc LABEL` and `BNE LABEL` branches to `LABEL` if `Z` (zero) is 1 or 0, respectively.
* Carry set/unset: `BCS LABEL`/`BHS LABEL` and `BCC LABEL`/`BLO LABEL` branches to `LABEL` if `C` (carry) is 1 or 0, respectively.
* Minus/positive: `BMI LABEL` and `BPL LABEL` branches to `LABEL` if `N` (negative) is 1 or 0, respectively.
* Overflow set/unset: `BVS LABEL` and `BVC LABEL` branches to `LABEL` if `V` (overflow) is 1 or 0, respectively.
* Unsigned higher/lower-or-same (greater/less-or-equal-to): `BHI LABEL` and `BLS LABEL` branches to `LABEL` if `Z` and not `C` ($Z \wedge \overline C$) is 1 or 0, respectively.
* Signed greater-or-equal/less: `BGE LABEL` and `BLT LABEL` branches to `LABEL` if `N` xor `V` ($N \oplus V$) is 1 or 0, respectively.
* Signed greater/less-or-equal: `BGT LABEL` and `BLE LABEL` branches to `LABEL` if Z, or `N` xor `V` ($Z \vee (N \oplus V)$), is 1 or 0, respectively.

# 7/10/15

Branch statements can be used to implement any kind of control flow .

An **assembler** is a program that accept assembly language and outputs an object program in machine code - one instruction in assembly language is one machine instruction. Each line of assembly language contains labels, the operation, operands, and comments, all of which are optional.

**Assembler directives** are commands to the assembler itself, rather than being translated to machine code. This allows us to do things like speifying the entry point of the program (`ENTRY`), define constants/data, and set code/data section locations (`AREA CODE`/`AREA DATA`). Directives like `DCW` (declare word) can be used to declare literal values, and often takes the form `SOME_LABEL DCW 0x12345678, 0x87654321` (two constant words that can be referenced by `SOME_LABEL`):

    AREA CODE ; code section
    ENTRY ; entry point of the program
    
    LDR R0, X ; load thevalue of X into R0
    
    AREA DATA ; data section
    X DCW 0x25 ; declare a word

Other directives include `NAME EQU VALUE`, which can be used to define symbolic names fo numerical values (like `X EQU 5`) and `RN`, which can be used to give names to registers (`COUNTER RN 3`).

There are also **pseud-instructions**, which aren't real instructions, but get translated into real, possibly multiple instructions. For example, `LDR R0, =LABEL` loads the address of `LABEL` into R0 (as opposed to `LDR R0, LABEL`, which loads the value at `LABEL` instead). Also, `LDR R0, CONSTANT_VALUE` is translated to `MOV R0, CONSTANT_VALUE` if `CONSTANT_VALUE` is of the right form, and otherwise is translated into `LDR R0, CONSTANT_DEFINITION` and `CONSTANT_DEFINITION DCW CONSTANT_VALUE` - the constant is stored at a memory location, and is loaded from that memory location when required.

Summing an array:

    LDR R1, N
    LDR R2, =ARRAY
    MOV R0, #0
    LOOP:
    LDR R3, [R2], #4
    ADD R0, R0, R3
    SUBS R1, R1, #1
    BGT LOOP
    STR R0, SUM
    
    N DCW 5 ; number of array elements
    ARRAY DCW 2, 4, 6, 8, 10 ; elements of array
    SUM DCW 0 ; sum of the array is output in here

# 9/10/15

`STM`/`LDM`, as mentioned earlier, can do multiple register stores/loads all in a single instruction:

* The FD/IA (increment after) suffix adds the final offset to the register after performing the store/load: `STMFD R0!, {R1, R2, R3}` (store R1-R3 into memory address at R0, write final address into R0)
* The EA/DB (decrement before) suffix subtracts the final offset from the register before performing the store/load: `STMEA R0!, {R1, R2, R3}` (store R1-R3 into memory address at R0, write final address into R0)
* This also supports conditional prefixes to run the instruction conditionally based on status bits: `STMFDGT R0, {R1}` (store R1 into memory address at R0)

This is very useful for pushing multiple things onto (`STMFD R13!, {R1, R2, R3}`) or off of (`LDMFD R13!, {R1, R2, R3}`) the stack. The `!` ensures that the final address of R13 (stack pointer) is updated to represent the top element of the stack.

Also, `BL LABEL` is the branch and link instruction, which branches to `LABEL` and sets the address of the next line as the value of the link register - the return address. This is useful for calling subroutines.

This allows for a very elegant calling convention:

    LDR R0, #123 # set parameter 1
    BL SUBROUTINE # call the subroutine
    
    # accepts 1 parameter in R0, and puts the return value in R0
    SUBROUTINE:
    STMFD R13!, {R14, R1, R2} # push the link register and any other desired register values onto the stack
    ; we conventionally don't need to save the registers for the parameters (R0) since they are only used for this subroutine anyways - plus, we're reusing it for the return value
    
    ; do things with R1 and R2, since they're saved now
    
    LDMFD, R13, {R15, R1, R2} # pop the link register's value into the program counter (to do the return) and restore the other register values

The above saves/restores registers using only two instructions, and also does the return at the end. The return value is conventionally put in R0, though we could also push it onto the stack (if the result can't fit into just a register).

Without the multiple store/load instructions, we would have to manually push each register value, then at the end manually restore the register values and return using something like `BX R14`.

# 14/10/15

A program needs to be assembled in two passes if and only if it includes instructions that reference labels below it in the program (forward references).

Assemblers will assemble modules as if each one will be loaded at location 0, and then the linker relocates it as appropriate. There is position dependent and position independent machine code generated by instructions - position independent code is the same as position dependent code, but it also includes information that allows the linker to relocate it.

The **interconnection network** is the circuitry that connects the processor, memory, and I/O, like the system bus. Communication takes place over a shared address space. I/O devices are often memory mapped - they share the same address space as the memory, and in general simply appear as memory locations. As a result, we can access these I/O devices simply using the standard load/store instructions.

I/O devices typically have three registers exposed as memory locations - data, status, and control. Often, the control and status registers have the same address, where loading from it reads the status register and writing to it sets the control register.

Programs will generally interact with I/O by **polling** (program-controlled I/O) or with **interrupts** (device-controlled I/O).

For polling, there will generally be a bit in the status register that tells us whether the I/O device has data ready to read, and then the program repeatedly checks this and reads if necessary. This is really inefficient if the reads occur infrequently, such as reading keypresses from a keyboard - most of the time, the CPU will simply be checking status registers. We want to allow other things to run while we're waiting for I/O to get reading - to let I/O devices alert the processor when it's ready. This is the role of interrupts.

# 16/10/15

I/O devices will often have a dedicated signal on a special processor line, called IRQ (interrupt request), on which the device can send signals. When the processor receives one of these **interrupts** signals, it switches to an **interrupt service routine/interrupt handler** (ISR). Interrupts are used to allow the processor to respond to high priority events.

An interrupt service routine is a small program stored in memory. ISRs should be as short and fast as possible, and do the minimum needed to satisfy the I/O device, since it is blocking the main program from running - they usually copy data into a buffer for the main program to process later. ISRs generally have to acknowledge the interrupt in their body to clear the interrupt from processing.

The steps before the ISR is called can take a significant amount of time - this delay is called **interrupt latency**.

Some pieces of code are critical and should never be interrupted. For this purpose, there is a CSPIE (interrupt enable) bit in the processor status (PS) register that controls whether interrupts are handled, or just ignored. This is useful for things like disabling interrupts in realtime code sections, or disabling interrupts within an ISR to avoid recursive interrupts.

The interrupt process occurs as follows:

* The I/O device asserts an interrupt.
* The processor finishes executing the current instruction and everything in its pipeline (or just stops executing it if there's an exception like invalid memory access).
* The processor state is saved (program counter PC, status register PS).
* Interrupts disabled by setting interrupt enable to 0 in PS.
* The correct ISR corresponding to the device is looked up.
* The ISR is called, servicing the device (the ISR should deactivate the interrupt to clear the interrupt request, by setting the INTA line).
* The processor state is restored.
* Interrupts enabled by setting interrupt enable to 1 in PS.
* The next instruction is executed (or not, if there was an exception).

The IRQ could just be a single signal, where upon receiving a signal, we just poll every device to see if it requested an interrupt, but this adds a lot of interrupt latency. What we can do instead is have the IRQ line accept a vector, and then map that to ISR addresses using an **interrupt vector table** (an array, generally at a fixed address, of ISR addresses where indices are the vector values) - these are **vectored interrupts**. However, vectored interrupts require IRQ to have a lot more lines to represent a vector.

One way to implement the IRQ line is by having a weakly pulled-up line pulled down by any of the I/O devices (each one either pulls down the line or is disconnected). When the line is pulled down, the processor detects this as an interrupt, and the I/O device stops pulling the line down (clearing the interrupt request) when the ISR services the I/O device.

Servicing the I/O device is done by asserting the interrupt acknowledge signal INTA, which is sent from the processor to the first I/O device and passed down the line until a device needing service receives it. This is a single line, and when set to 1 means that the processor acknowledges that the interrupt was raised. The I/O device needing service always passes on 0, while other devices pass on the original value, since we want to only acknowledge one interrupt at a time (if there are multiple active, setting INTA only acknowledges the first one).

The processor can determine which I/O device asserted the interrupt by either polling each of them in turn, or having another set of lines to transfer the vector if using vectored interrupts. Alternatively, IRQ can be weakly pulled-down and I/O devices can pull it up.

Another way to implement IRQ is to simply have one IRQ line per I/O device. This is much simpler, but requires a lot more lines - one IRQ and one INTA line per I/Oo device. Plus, the number of I/O devices is fixed by what is built into the processor.

If multiple interrupts occur at the same time, **arbitration** is needed. Most systems will have an interrupt priority mechanism, where higher priority interrupts get to execute first. In single-signal IRQ implementations, the priority is defined by the order that INTA signals are passed from one device to the next - the earlier the device in the chain, the higher its priority. For multiple dedicated IRQ lines, the processor must choose just one of them to process at a time.

**Interrupt nesting** allows higher priority ISRs to interrupt lower priority ones - this helps avoid higher priority ISRs being ignored while low-priority ISRs are running (and interrupts are disabled). This is done by having separate interrupt enable flags for high and low priority interrupts - low priority ISRs only disable low priority interrupts while running, while high priority ones disable both low and high priority interrupts while running.

# 19/10/15

An example of where interrupt nesting is important is for keyboard and display interrupts - while we are in the display interrupt handlers, we still want to keep receiving keyboard input.

The upon interrupt requests, the status register PS is saved to the interrupt status register IPS. The IENABLE register has one bit per device representing whether interrupts are enabled for it, while the IPENDING register has one bit per device representing whether the current interrupt request exists and has not been serviced. Registers such as these are accessed using special control register instructions, which we will call `move_control SOURCE, DESTINATION` for simplicity.

Simple interrupts example:

    ; THIS SHOULD BE IN THE MAIN PROGRAM
    ; clear the line buffer
    move R2, #LINE_BUFFER
    store R2, BUFFER_PTR
    
    ; enable keyboard interface interrupts
    move R2, #2
    store R2, KEYBOARD_STATUS ; keyboard status register is a special location in memory
    
    ; enable CPU keyboard interrupts
    move_control IENABLE, R2
    or R2, R2, #2
    move_control R2, IENABLE
    
    ; enable CPU interrupts in general
    move_control PS, R2
    or R2, R2, #1
    move_control R2, PS
    
    ; THIS SHOULD BE IN THE ISR
    ; save used registers
    push R2
    push R3
    
    ; save keyboard character to the line buffer
    load_byte R3, KEYBOARD_DATA ; keyboard data register is special location in memory
    load R2, BUFFER_PTR
    store R3, (R2)
    add R2, R2, #4
    store R2, BUFFER_PTR
    
    ; restore resgisters
    pop R3
    pop R2

Non-maskable interrupts (NMI) are those that trigger regardless of the interrupt enable bits.

# 21/10/15

Multiple interrupts example:

    ; THIS SHOULD BE IN THE MAIN PROGRAM
    ; clear the line buffer
    move R2, #LINE_BUFFER
    store R2, BUFFER_PTR
    
    ; enable keyboard interface interrupts
    move R2, #2
    store R2, KEYBOARD_STATUS ; keyboard status register is a special location in memory
    
    ; enable display interrupts
    move R2, #4
    store R2, DISPLAY_STATUS ; display status register is a special location in memory
    
    ; enable CPU keyboard/display interrupts
    move_control IENABLE, R2
    or R2, R2, #2
    or R2, R2, #4
    move_control R2, IENABLE
    
    ; enable CPU interrupts in general
    move_control PS, R2
    or R2, R2, #1
    move_control R2, PS
    
    ; THIS SHOULD BE IN THE ISR
    ; save used registers
    push LINK
    push FP
    push R2
    push R3
    
    ; test interrupt pending to see if display generated an interrupt
    move_control R2, IPENDING
    and R3, R2, #4
    branch_if_zero R3, NOT_DISPLAY
    call DISPLAY_ISR
    jump DONE
    
    ; test interrupt pending to see if keyboard generated an interrupt
    NOT_DISPLAY:
    and R3, R2, #2
    branch_if_zero R3, DONE
    call KEYBOARD_ISR
    
    ; restore resgisters
    DONE:
    pop R3
    pop R2
    pop FP
    pop LINK
    
    KEYBOARD_ISR:
    ; DO KEYBOARD HANDLER STUFF HERE
    
    DISPLAY_ISR
    ; DO DISPLAY HANDLER STUFF HERE

Note that the priority of the interrupts were defined in software here - we're checking the display first, so the display always has higher priority.

**Exceptions** are simply any type of execution interruption, and include interrupts as well as interruptions from inside the processor.

While interrupts are for I/O devices, we also have internal faults like error recovery (zero division, bad instruction), debugging, and various utility faults for operating system multitasking primitives. For example, breakpoints on the CPU are generated by inserting a `trap` instruction that allows a special routine to handle it. On most OSs, system calls are made using exceptions.

A **watchdog timer** is a mechanism used for embedded systems that need to be very reliable. A timer in the background, when it runs out, triggers a non-maskable interrupt that resets the processor (say, every second or so) - the software has to reset the timer (kicking the watchdog) every so often, or else the timer will run out and reset the program. This ensures that if the program ever freezes or locks up, the wachdog timer will reset the program to try again.

Hardware
--------

When state changes occur on device inputs, it takes time before the output state updates to match. While the output is updating, it is possible that the state will be transient and invalid. This is the purpose of the clock - to ensure we can wait until the signals are fully propagated before continuing.

A negative edge-triggered D flip-flop is simply an MS flip-flop, two D-latches one after the other with the same clock, the second one's clock signal being inverted - all the abstract hardware must, in the end, boil down to real hardware. A multiplexer can be made from AND gates for each input and NOT gates for select lines.

Buses have address signals, data signals, and control signals. On the processor bus, there is an address decoder that reads the address lines and sets the enable line on the corresponding device, such as RAM or each memory mapped I/O device. Enabling a device connects it to the bus, and only one device may be connected at a time.