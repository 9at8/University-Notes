<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CO487 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso.light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body onload="highlight()">
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="http://www.linkedin.com/pub/anthony-zhang/8b/aa5/7aa" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:azhang9@gmail.com" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="/anthony-zhang.asc" class="info">GPG key</a></li>
  </ul>
<p style="display:none"><span class="math">\[
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1 \right\rceil}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}^P)}
\]</span></p>
<h1 id="co487">CO487</h1>
<p>Applied cryptography.</p>
<pre><code>Alfred Menezes
Section 001
Email: ajmeneze@uwaterloo.ca
Office hours: Mondays 3:00pm-5:00pm, Fridays 1:00pm-3:00pm in MC 5026
Mondays/Wednesdays/Fridays 11:30pm-12:20pm</code></pre>
<h1 id="section">4/3/16</h1>
<p>All course resources are on LEARN. Course has 5 assignments (summing up to 20% of final grade), midterm (worth 30%), and a final exam (worth 50%). Midterm is March 8, 2017 at 7-9pm.</p>
<p>Cryptography is a tool we can use to secure communicatoins when there are malicious adversaries. Some of the fundaental goals of cyptography are:</p>
<ul>
<li>Confidentiality - data is secret to all people except authoeized parties.</li>
<li>Data Integrity - data is unaltered.</li>
<li>Origin authentication - data can be confirmed to be from a particular source.</li>
<li>Non-repudiation - once a statement is published, it is not possible to deny/revoke it later.</li>
</ul>
<p>Different applications might require different subsets of these goals.</p>
<p>In this course, we use Bob and Alice as placeholders to represent two parties trying to communicate securely. We use Eve or Mallory as a placeholder to represent one or more adversaries trying to attack the communications (by injecting data, eavesdropping, or other approaches, depending on the threat model)</p>
<p>Some famous early practical uses of cryptography was the enigma machine, which used multiple spinning rotors to encrypt/decrypt messages. In that cryptosystem, the German military leadership and the German U-boats had the role of Bob and Alice, trying to communicate confidentially, and Alan Turing and his team had the role of Eve, trying to break the confidentiality guarantees and read those communications.</p>
<p>However, cryptosystems like Enigma and its successor, Lorenz, are a far cry from modern cryptosystems, which have a much more mathematically sound foundation. Modern cryptography is what makes online banking, online shopping, and cellular networks possible.</p>
<p>For example, SSL, the protocol that makes online security possible, ensures origin authentication and confidentiality between a user and a website. SSL uses symmetric-key encryption to implement confidentiality, and a MAC scheme (HMAC) to implement origin authentication. Of course, to make this possible they both need to have the same secret key for the symmetric-key cryptography, and for the MAC. To confidentially and authentically share this secret key, we use public-key encryption. Of course, to make this possible we need a way to obtain authentic copies of the public keys of both parties - this is implemented using digital signatures, where trusted third parties known as certificate authorities keep track of public keys that are considered authentic (generally by vetting the site owner in the real world), and digitally sign them to confirm that they're authentic. The certificate authorities' public keys are pre-installed in the browser, which acts as a root of trust - if you trust that public key is authentic, and that the certificate authorities are correctly keeping track of authentic .</p>
<p>SSL is one of the most successful cryptosystems ever deployed, used for tons of sites on the internet. However, there are a number of possible weaknesses that might result in the guarantees being broken:</p>
<ul>
<li>The crypotgraphy itself might be weak (e.g., previously, SSL supportied using RC4 for the symmetric-key encryption, which is nowadays easy to break).</li>
<li>Quantum computers can attack public-key encryption systems like RSA.</li>
<li>Random number generators used in the protocol might have weaknesses (e.g., Netscape's flawed RNG, NSA's backdoored EC-DRBG CSPRNG).</li>
<li>Certificate authorities (e.g., social engineering resulting in Verisign digitally signing non-authentic certificates).</li>
<li>Bugs in crpytographic code (e.g., Heartbleed)</li>
<li>Misuse of cryptography, like encrypting the wrong thing.</li>
<li>Phishing/social engineering attacks on users themselves.</li>
<li>The server itself leaking data - SSL only protects data in transit, not when it's on the server.</li>
</ul>
<p>This demonstrates some useful concepts:</p>
<ul>
<li>Symmetric-key encryption is used to ensure confidentiality.</li>
<li>MAC schemes are used to ensure authentication.</li>
<li>Public-key encryption is used to ensure confidentiality, integrity, authentication, and non-repudiation.</li>
<li>Digital signatures is used to ensure integrity, authentication, and non-repudiation.</li>
</ul>
<p>Cryptography is only one part of a large information security ecosystem, including other things like secure operating systems, auditing mechanisms, trusted computing, and risk analysis. In this context, cryptography provides a lot of useful and essential tools, but it's not all there is to security. Attackers will generally target the weakest part of the system, and if that link fails, it is possible that the entire system will.</p>
<p>This course focuses on breadth over depth. For depth, take CO 485 and try out the readings for this course as well.</p>
<h1 id="section-1">6/1/17</h1>
<p>SSL in more detail:</p>
<ol style="list-style-type: decimal">
<li>Client makes request to the website (not the full URL, just the host).</li>
<li>Server responds with the website's certificate, which contains the website identification info (like host and etc.).</li>
</ol>
<h2 id="symmetric-key-encryption">Symmetric-key encryption</h2>
<p>A <strong>symmetric key encryption scheme</strong> (SKES) is a definition containing:</p>
<ul>
<li>A plaintext space <span class="math inline">\(M\)</span>.</li>
<li>A ciphertext space <span class="math inline">\(C\)</span>.</li>
<li>A key space <span class="math inline">\(K\)</span>.</li>
<li>A family of encryption functions <span class="math inline">\(E_k: M \to C, \forall k \in K\)</span>.</li>
<li>A family of decryption functions <span class="math inline">\(D_k: C \to M, \forall k \in K\)</span>.</li>
</ul>
<p>To use one of these to implement message confidentiality, Alice and Bob agree on a particular <span class="math inline">\(k \in K\)</span> over a secure channel (so that nobody else knows about the value of <span class="math inline">\(k\)</span>). Then, Alice can compute <span class="math inline">\(c = E_k(m)\)</span>, where <span class="math inline">\(m\)</span> is the message, and then sends <span class="math inline">\(c\)</span> to Bob over an unsecure channel. Bob can read the message by then computing <span class="math inline">\(m = D_k(c)\)</span>, while anyone without <span class="math inline">\(k\)</span> would have to figure out the correct <span class="math inline">\(D_k\)</span> function to use. An SKES can be designed such that finding the correct <span class="math inline">\(D_k\)</span> would be very difficult.</p>
<p>A substitution cipher is an SKES, under this definition: <span class="math inline">\(M\)</span> is the set of all English messages, <span class="math inline">\(C\)</span> is the set of all encrypted messages, <span class="math inline">\(K\)</span> is the set of all permutations of the English alphabet, <span class="math inline">\(E_k\)</span> maps letters onto <span class="math inline">\(k\)</span> by index, and <span class="math inline">\(D_k\)</span> does the inverse mapping.</p>
<p>A <strong>security model</strong> defines what the adversay is capable of, like what they can do to the communicating parties. For example, there are passive attacks like <strong>ciphertext attacks</strong> (attacker can obtain ciphertext, like if they're listening on the same network), <strong>known-plaintext attacks</strong> (attacker knows some of the plaintext as well the resulting ciphertext, like knowing that someone always signs off their message with their name). There are also active attacks, like <strong>chosen-plaintext attacks</strong> (attacker can choose some part of the plaintext), <strong>clandestine attacks</strong> (attacker is willing to use bribery/blackmail/etc.), and <strong>side-channel attacks</strong> (power analysis, RF emissions analysis, timing attacks).</p>
<p>The security model also includes the attacker's computational abilities. For example, information-theoretic security models assume the attacker has infinite computational resources, complexity-theoretic security models assume the attacker has a turing machine capable of computing any polynomial-time algorithm efficiently, and computational-theoretic security models assume the attacker simply has a lot of computers available.</p>
<p>The attacker's goals, in decreasing order of priority: recovering the secret key, recovering plaintext from ciphertext (without the key), or learn some characteristics of the plaintext given ciphertext (besides message length).</p>
<p>An SKES is <strong>secure</strong> if and only if it is resistant to a chosen-plaintext attack by a computationally bounded adversary (computational-theoretic security). A secure SKES is necessary but not sufficient to guarantee confidentiality.</p>
<p>Additionally, we also assume that the adversaries know everything about the cryptosystem except the plaintext and the key, including the all the algorithms and communicatoin mechanisms.</p>
<p>An SKES should ideally be efficient (for encryption/decryption), have small keys (but not so small that it makes brute force attacks possible), and be secure (even against the designer of the SKES).</p>
<p>A <strong>work factor</strong> measures how hard a task is, in terms of how many computations are needed to complete it: <span class="math inline">\(2^{56}\)</span> operations is easy, <span class="math inline">\(2^{64}\)</span> is feasible, <span class="math inline">\(2^{80}\)</span> operations is barely feasible, and <span class="math inline">\(2^{128}\)</span> operations is infeasible. This will change as our computers get faster. For example, the entire bitcoin network is doing <span class="math inline">\(2^{61}\)</span> hashes per second. However, we use <span class="math inline">\(2^{128}\)</span> operations as infeasible because the Landauer limit tells us doing that many operations on a classical computer would take a significant fraction of the world's power output for a year.</p>
<p>For example, a substitution cipher is not secure, because it's trivially broken by a chosen-plaintext attack. By choosing the plaintext as the alphabet, the ciphertext is just the secret key. In fact, it's not even secure against ciphertext-only messages. Although it's infeasible to exhaustively try every permutation of the alphabet for valid-looking decrypted messages, we can simply use letter frequency analysis to try likely candidates first.</p>
<p>A polyalphabetic cipher uses multiple alphabet permutations for substitution, choosing between them with a particular algorithm. For example, a Vigenere cipher has a word with non-repeated letters added to the message's letters mod 26. This is nice because as the message grows longer, the letter frequency graph is a bit flatter. We can break that by using a chosen-plaintext attack with plaintext &quot;AAAAAAAAAAAAAAAAAA&quot;, so if &quot;A&quot; corresponds to the numerical value 0, the ciphertext is just the key. Therefore, the Vigenere cipher is not secure.</p>
<p>From now on, we assume plaintext, keys, and ciphertext are all binary strings. What happens when we apply the concept of a Vignere cipher, but with a uniformly random key that's as long as the entire message?</p>
<p>A <strong>one time pad</strong> XORs a random key with the plaintext (the key is as long as the message). However, it's important to not reuse keys, because <span class="math inline">\(c_1 = m_1 \xor k_1\)</span> and <span class="math inline">\(c_2 = m_2 \xor k_2\)</span> implies that <span class="math inline">\(c_1 \xor c_2 = m_1 \xor m_2\)</span>, which leaks a lot of information about the plaintext. If the key is uniformly randomly selected, every key is equally likely, so every ciphertext is also equally likely. This is information-theoretically secure - a one-time pad provably cannot be broken by a ciphertext-only attack even by attackers with infinite computational resources. While one-time pads have these nice properties, in practice they are hard to use because the key has to be as long as the ciphertext, making sharing keys a pain.</p>
<p>A <strong>stream cipher</strong> is like a one-time pad, but instead of a truly random key, we use a pseudorandom bit generator, where the PRBG's seed is the secret key. This is no longer perfectly secure because it depends on the quality of the randomness of the PRBG, but it's often a practical compromise since the key can be a lot shorter. Like with a one-time pad, we also shouldn't re-use keys, since that would give us some of the values of the PRBG's output by XORing the ciphertexts, which would make it easier to learn the PRBG's state. One example of a stream cipher is RC4.</p>
<h1 id="section-2">9/1/17</h1>
<p>The PRBG should satisfy two requirements:</p>
<ul>
<li>Indistinguishability requirement - the output should be indistinguishable from a random sequence.</li>
<li>Unpredictability requirement - the output should not be predictable even if some of the previous outputs are known.</li>
</ul>
<p>Most random number generators built into programming languages are not cryptographically secure - they're only intended to satisfy the indistinguishability requirement. For example, <code>rand</code> in UNIX uses a linear congruential generator with known constants, which is straightforward to predict.</p>
<p>RC4 was designed by Rivest, the R in RSA. It was used in everything from SSL/TLS to Adobe Acrobat, as one of the most popular stream ciphers around. It's nice because it's very fast and has variable key sizes, but was proprietary for a long time has a lot of weaknesses, even though none of them are catastrophic. It consists of a key scheduling algorithm, and a keystream generator.</p>
<p>The key scheduling algorithm generates a random-looking permutation of <span class="math inline">\(0, \ldots, 255\)</span>. It starts by initializing <span class="math inline">\(S\)</span> with <span class="math inline">\(0, \ldots, 255\)</span>, and <span class="math inline">\(\overline{K}\)</span> to the key repeated over and over until it fills 256 entries in the array. Then, the array entries in <span class="math inline">\(S\)</span> are swapped based on <span class="math inline">\(j_{i + 1} = (S[i] + \overline{K} + j_i) \mod 256\)</span>. The keystream generator just applies that permutation to generate the keystream, which is then XORed with the plaintext to get the ciphertext.</p>
<p>Wireless networks lose the physical security of wired networks, and security for those networks is a lot harder because attackers can do it from a distance with no physical evidence. The original WiFi standard, IEEE 802.11, includes the Wireless Equivalent Privacy (WEP) protocol for protecting link-level data in transit between clients and access points. WEP was intended to provide confidentiality using RC4, data integrity using a checksum, and access control by rejecting improperly encrypted packets.</p>
<p>In WEP, the client first shares a 40-bit or 104-bit key with the access point (this was because the US classified cryptography as munitions, disallowing most cryptography with keys greater than 40 bits for export; and keys greater than 104 bits for domestic use). Messages are then divided into fixed-size packets, which are then each encrypted with a per-packet initialization vector (IV). The issue is that WEP didn't specify certain things, like how the key should be distributed, and how IVs should be managed.</p>
<p>Implementations ended up using one shared key per LAN, infrequently changed, and just generating random IVs or using consecutive integers as IVs. To send a packet, a party would select a 24-bit IV, compute the CRC-32 checksum of the message, the checksum is then appended to the plaintext, and then XORed with the RC4 keystream to get the ciphertext, where the key is the IV the shared WEP key appended to the IV. The sender then transmits the IV and the ciphertext. The receiver then, having the IV and the WEP shared key, gets gets the plaintext concatenated with the checksum, and then verifies that the checksum is correct, rejecting the packet if the checksum doesn't validate.</p>
<p>Turns out, WEP implements none of its goals. One problem is IV collision - since the IV is only 24-bits, the birthday paradox means that only about <span class="math inline">\(2^{12}\)</span> packets are needed for a collision. If two packets have the same IV, then <span class="math inline">\(c_1 \lxor c_2 = m_1 \lxor m_2\)</span> - the ciphertexts can be XORed to get the plaintexts, which can then be analyzed using known plaintexts or statistical analysis, so confidentiality is broken. Another problem is that the checksum is linear - we can make certain changes to the ciphertext while still ensuring that the checksum will verify correctly, so data integrity is broken. Finally, the checksum is unkeyed, so knowing the plaintext for one encrypted packet is enough to get the RC4 keystream and encrypt messages properly themselves.</p>
<p>Shamir and co. (the S in RSA) came up with an even better attack in 2001, based on the fact that 104-bit keys were infrequently changed, the IV is very predictable/randomly selected, and we know the first byte of the plaintext (the protocols add known headers to the plaintext before encrypting). With 5 million packets, the secret key itself can be recovered. Modern techniques can recover the key in just 40000 packets.</p>
<p>IEEE published updated wireless security standards. For example, WPA was a temporary replacement, and WPA2 came out afterwards, using AES instead of RC4, and designed to be much stronger.</p>
<h1 id="section-3">11/1/17</h1>
<p>Assignment 1 should be started now.</p>
<p>Attacks only get better over time, never worse. In WEPs case, it wasn't the security of the algorithms like RC4 that were broken, it was the use of those algorithms that was incorrect. In the future, thanks to upcoming advances related to Moore's law and quantum computing, currently secure cryptosystems could easily become broken.</p>
<p>A <strong>block cipher</strong> is the other common type of SKES. While a stream cipher encrypts one bit at a time, a block cipher breaks up the plaintext into fixed-length blocks, encrypting the message one block at a time. Some commonly known block ciphers are DES and AES.</p>
<p>DES has a 56-bit key length (which is now relatively easy to break), and a block size of 64 bits. AES (Rijndael, &quot;rined'all&quot;) is its successor, and has a 128/192/256 bit key length. There are currently no significant known attacks on AES.</p>
<p>Clause Shannon gave a couple of principles for designing good block ciphers:</p>
<ul>
<li>Diffusion - each ciphertext bit should depend as many plaintext bits as possible.</li>
<li>Confusion - there should be a complicated relatoinship between key and ciphertext bit.</li>
<li>Key size - keys should be large enough to prevent exhaustive search.</li>
</ul>
<p>Also, block ciphers should be fast, so we can use them in more applications.</p>
<p>A Feistel cipher is a class of ciphers, including DES. Feistel ciphers are parameterized based on <span class="math inline">\(n\)</span> (half of block size), <span class="math inline">\(h\)</span> (number of rounds), and <span class="math inline">\(l\)</span> (key size). It generates <span class="math inline">\(h\)</span> subkeys from the cipher key, one for each round. Each key is used to generate a component function <span class="math inline">\(f_1, \ldots, f_h\)</span> that &quot;scrambles&quot; its input.</p>
<p>Each block <span class="math inline">\(m\)</span> is then broken into two halves, <span class="math inline">\(\tup{m_0, m_1}\)</span>. Then, we perform <span class="math inline">\(h\)</span> encryption rounds: at each round <span class="math inline">\(i\)</span>, the right half gets moved into the left half, and the original left half is XORed with <span class="math inline">\(f_i\)</span> of the original right half, and that becomes the right half. After those <span class="math inline">\(h\)</span> rounds, the two halves are the ciphertext.</p>
<h1 id="section-4">13/1/17</h1>
<p>;wip: feistel ciphers</p>
<p>The New Data Seal cipher was invented by IBM as the predecessor to DES. It's a Feistel cipher, and is a relatively complicated one, but it also happens to be completely broken today to chosen-plaintext attacks. It has a block size of 64 bits, and uses 16 rounds, so <span class="math inline">\(n = 64, h = 16\)</span>. Here's the basic idea:</p>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(S_k: \set{0, 1}^8 \to \set{0, 1}^8\)</span> be the secret key - an arbitrary function of a byte.</li>
<li>Let <span class="math inline">\(f: \set{0, 1}^{64} \to \set{0, 1}^{64}\)</span>, the component function, be defined as follows:
<ol style="list-style-type: decimal">
<li>Since the input is 64-bits, let <span class="math inline">\(z = \tup{z^1, \ldots, z^8}\)</span> be the 8 bytes of the input.</li>
<li>For each byte <span class="math inline">\(z^j\)</span>, let <span class="math inline">\(n_1^j = z^j[7:4]\)</span> and <span class="math inline">\(n_2^j = z^j[3:0]\)</span> - the two nibbles of the byte.</li>
<li>Let <span class="math inline">\(t = S_k(z^1[7] \ldots z^8[7])\)</span> - the key function applied to the byte obtained by taking the first bit of each byte in <span class="math inline">\(z\)</span>.</li>
<li>For each byte <span class="math inline">\(z_j\)</span>, if bit <span class="math inline">\(j\)</span> of <span class="math inline">\(t\)</span> is 1, let <span class="math inline">\(p_1^j = S_1(n_2^j)\)</span> and <span class="math inline">\(p_2^j = S_0(n_1^j)\)</span>, otherwise let <span class="math inline">\(p_1^j = S_0(n_1^j)\)</span> and <span class="math inline">\(p_2^j = S_1(n_2^j)\)</span>. <span class="math inline">\(S_0, S_1\)</span> are functions defined by the NDS specification (that are too long to list here), and we're swapping the nibbles if the corresponding bit of the key function <span class="math inline">\(S_k\)</span> is true.</li>
<li>Output <span class="math inline">\(P(p_1^1 p_2^1 \ldots p_1^8 p_2^8)\)</span> - a scrambling function <span class="math inline">\(P\)</span> applied to all of the scrambled and permuted nibbles concatenated together. <span class="math inline">\(P\)</span> is also a function defined by the NDS specification (that is too long to list here).</li>
</ol></li>
<li>For each 16-byte block of the input <span class="math inline">\(z = \tup{z^1, \ldots, z^8}\)</span>, run the Feistel cipher ladder with <span class="math inline">\(f\)</span> as the component function:
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(m_0, m_1\)</span> be the two 8-byte halves of the 16-byte block.</li>
<li>For 16 rounds <span class="math inline">\(1 \le j \le 16\)</span>, set <span class="math inline">\(m_j\)</span> to <span class="math inline">\(m_{j - 1}\)</span> and <span class="math inline">\(m_{j + 1}\)</span> to <span class="math inline">\(m_{j - 1} \lxor f\)</span>.</li>
<li>Output <span class="math inline">\(m_{16} m_{17}\)</span>.</li>
</ol></li>
</ol>
<p>Since <span class="math inline">\(S_k\)</span> can be considered a random function, there are <span class="math inline">\(2^8\)</span> possible values of <span class="math inline">\(S_k(x)\)</span> for each of the <span class="math inline">\(2^8\)</span> possible values of <span class="math inline">\(x\)</span> - we might think of serializing the function as a 256-byte sequence. That means there are <span class="math inline">\(256^{256}\)</span> possible values of <span class="math inline">\(S_k\)</span>, or <span class="math inline">\(2^{2048}\)</span>, which makes trying every possible <span class="math inline">\(S_k\)</span> computationally infeasible.</p>
<p>In fact, we can recover the entire secret key from the ciphertext in a few hundred chosen plaintext attacks. The main issue is that there's no subkeys - each round used the same component function and secret key, rather than deriving unique component functions for each round - each <span class="math inline">\(f_1, \ldots, f_h\)</span> is the same function! Let <span class="math inline">\(T\)</span> denote the function that does one round of encryption, with regard to the secret key <span class="math inline">\(S_k\)</span>. Basically, <span class="math inline">\(T(\tup{m_{i - 1}, m_i}) = \tup{m_i, m_{i - 1} \xor f(m_i)}\)</span> for some fixed function <span class="math inline">\(f\)</span> and the two halves of the message are <span class="math inline">\(m_0, m_1\)</span>.</p>
<p>Clearly, applying <span class="math inline">\(T(m)\)</span> to the message 16 times is the full encryption function. Let's represent this as <span class="math inline">\(T^{16}(m)\)</span>. Let <span class="math inline">\(F = T^{16}\)</span> - this is the full encryption function, since the cipher is just applying <span class="math inline">\(T\)</span> 16 times. Clearly, <span class="math inline">\(T(F(m)) = T(T^{16}(m)) = T^{17}(m) = T^{16}(T(m)) = F(T(m))\)</span> for any byte <span class="math inline">\(m\)</span>.</p>
<p>Here's the attack. For every possible byte <span class="math inline">\(r\)</span>, we want to determine <span class="math inline">\(S_k(r)\)</span>. Select <span class="math inline">\(u = (m_0, m_1)\)</span> such that the byte formed by taking the first bit of each byte in <span class="math inline">\(m_1\)</span> is <span class="math inline">\(r\)</span>, and <span class="math inline">\(p_1^j \ne p_2^j\)</span> for <span class="math inline">\(1 \le j \le 8\)</span> the scrambled nibbles aren't the same within each of the 8 bytes in <span class="math inline">\(m_1\)</span>.</p>
<p>As an aside, <span class="math inline">\(x^*\)</span> seems to mean &quot;the first bit of each byte in <span class="math inline">\(x\)</span>&quot;.</p>
<p>By the rules of the chosen plaintext attack, we can get Bob to give us <span class="math inline">\(\tup{a, b} = F(u)\)</span>, but not what <span class="math inline">\(F(m)\)</span> or <span class="math inline">\(T(m)\)</span> are (we know the values of the function at this point, but that's it).</p>
<p>However, we know that <span class="math inline">\(T(F(u)) = F(T(u)) = \tup{b, \cdot}\)</span>. Since the value of <span class="math inline">\(S_k(r)\)</span> is only a byte, we can guess every possible value of <span class="math inline">\(S_k(r)\)</span>, and check each guess <span class="math inline">\(t\)</span> by computing <span class="math inline">\(T_t(u)\)</span> and then get Bob to give us <span class="math inline">\(F(T_t(u)) = \tup{c, d}\)</span>. Clearly, <span class="math inline">\(b \ne c\)</span> implies that <span class="math inline">\(S_k(r) \ne t\)</span>, and <span class="math inline">\(b = c\)</span> implies that <span class="math inline">\(S_k(r) = t\)</span> is very very likely (there is a tiny chance of accidentally getting it right). This is because we're assuming that <span class="math inline">\(F\)</span> works roughly like a random permutation, so since <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> are 64 bits, <span class="math inline">\(F(T_t(u))\)</span> has only a <span class="math inline">\(\frac 1 {2^{64}}\)</span> probability of <span class="math inline">\(b = c\)</span> without <span class="math inline">\(S_k(r) = t\)</span>, because we selected <span class="math inline">\(u\)</span> such that <span class="math inline">\(p_1^j \ne p_2^j\)</span>. Eventually, we get every possible value of <span class="math inline">\(S_k\)</span>.</p>
<p>Also, since we check every possible byte <span class="math inline">\(r\)</span> (256 values), and for each value of <span class="math inline">\(r\)</span>, we guess-and-check possible bytes <span class="math inline">\(t\)</span> (on average, 128 checks, worst case 256), we should expect <span class="math inline">\(128 \times 256 = 2^{15}\)</span> chosen plaintexts on average before recovering the entirety of <span class="math inline">\(S_k\)</span>.</p>
<p>The entire attack can be summarized as:</p>
<ol style="list-style-type: decimal">
<li>For each possible byte <span class="math inline">\(r\)</span>:
<ol style="list-style-type: decimal">
<li>Find a byte <span class="math inline">\(u = \tup{m_0, m_1}\)</span> such that <span class="math inline">\(m_1^* = r\)</span> and <span class="math inline">\(p_1^j \ne p_2^j, 1 \le j \le 8\)</span>.</li>
<li>Get Bob to compute <span class="math inline">\(F(u) = \tup{a, b}\)</span>.</li>
<li>For each possible byte <span class="math inline">\(t\)</span>:
<ol style="list-style-type: decimal">
<li>Compute <span class="math inline">\(T_t(u)\)</span>.</li>
<li>Get Bob to compute <span class="math inline">\(F(T_t(u)) = \tup{c, d}\)</span>.</li>
<li>If <span class="math inline">\(b = c\)</span>, we know that <span class="math inline">\(S_k(r) = t\)</span> with overwhelming probability, and then go to the next <span class="math inline">\(r\)</span>.</li>
</ol></li>
</ol></li>
<li>Now we have <span class="math inline">\(S_k(r)\)</span>, the secret key. We can use this to decrypt the ciphertext.</li>
</ol>
<p>Basically, we need about <span class="math inline">\(2^{15}\)</span> chosen plaintexts to recover the entire secret key, which is quite feasible on today's computers.</p>
<h1 id="section-5">16/1/17</h1>
<p>Chosen plaintext attacks are not always feasible, but when they are they're very powerful. For example, consider a mail forwarder that encrypts incoming emails and forwards them to another destination.</p>
<p>DES is one of NDS' successors. Originally with 64-bit keys, the NSA weakened the final standard to 56 bits. DES is pretty weak compared to modern ciphers, but 3-DES is still commonly in use. The design principles are classified, but it's been heavily analyzed.</p>
<p>DES is a Feistel cipher with 16 rounds, a 64-bit block and a 56-bit key. For each round of the cipher, a 48-bit subkey is derived from the 56-bit secret key, by selecting 48 bits from the secret key. The plaintext halves are also expanded from 32-bits to 48-bits. After each Feistel round completes, we use 8 S-box functions (which are publicly known) to scramble the XORed result and reduce 48-bit results to 32-bits. This is the source of nonlinearity in DES, and is very important for security.</p>
<p>With a key space of size <span class="math inline">\(2^{56}\)</span>, it's perfectly practical to just brute force today, even if we can't do it on our laptops just yet. A massively parallel effort broke a DES-encrypted message in just over 22 hours in 1999, in response to a challenge set by RSA security. Also, it's got a block size of 64-bits, which means that you'd expect a collision at around <span class="math inline">\(2^{32}\)</span> uniformly distributed blocks, thanks to the birthday paradox. So, on a busy network, if Alice and Bob are sending many blocks back and forth, Eve might observe a duplicated block, which tells us a little bit of information about the plaintext - those two corresponding blocks in the plaintext are identical (this isn't much of a problem in practice, but is still an issue).</p>
<p>Differential cryptoanalysis attacks can be used to recover the key in <span class="math inline">\(2^{47}\)</span> chosen plaintexts, though this is usually an infeasibly large number of chosen plaintexts in practice (turns out, DES was specifically designed to guard against this - the NSA was aware of the attack before it was public knowledge). Linear cryptoanalysis attacks can do the same thing in just <span class="math inline">\(2^{43}\)</span> chosen plaintexts, which is slightly more practical.</p>
<p>After these weakenings, 3-DES was invented as a more secure SKES in order to take advantage of existing DES hardware (DES was designed for hardware acceleration). Basically, it's just DES applied to DES applies to DES applied to the plaintext. Note that applying ciphers repeatedly doesn't always provide more security (consider a substitution cipher, for example), but in this case it provides reasonably good. Another variant is Double-DES, which is DES applied to DES applied to the plaintext (each DES function has its own key, so we have a 112-bit key overall).</p>
<p>Turns out Double-DES is vulnerable to a meet-in-the-middle attack. Basically, if <span class="math inline">\(E_{k_1}, E_{k_2}\)</span> are the two DES encryption functions in Double-DES and <span class="math inline">\(c = E_{k_2}(E_{k_1}(m))\)</span>, then <span class="math inline">\(E^{-1}(c) = E_{k_1}(m)\)</span>.</p>
<p>Suppose we have 3 known plaintext/ciphertext pairs <span class="math inline">\(\tup{m_1, c_1}, \ldots, \tup{m_3, c_3}\)</span>. For each possible 56-bit <span class="math inline">\(k_2\)</span>, decrypting <span class="math inline">\(c_1\)</span> with our guess for <span class="math inline">\(k_2\)</span>, and store that plaintext and the key used in a table, indexed by the plaintext. Then, for each possible 56-bit <span class="math inline">\(k_1\)</span>, try encrypting the <span class="math inline">\(m_1\)</span> with our guess for <span class="math inline">\(k_1\)</span>, and see if it matches any entry in the table. If there's a match, and those guesses for <span class="math inline">\(k_1, k_2\)</span> also satisfy <span class="math inline">\(c_2 = E_{k_2}(E_{k_1}(m_2))\)</span> and <span class="math inline">\(c_3 = E_{k_2}(E_{k_1}(m_3))\)</span>, then our guesses for <span class="math inline">\(k_1, k_2\)</span> are the actual secret keys.</p>
<p>Due to this attack, Double-DES is only slightly better than plain DES, with about <span class="math inline">\(2^{57}\)</span> bits of security and requiring about <span class="math inline">\(2^{56}(64 + 56)\)</span> bits of memory to store the table. The main hard part is getting the ~1 exabyte of storage needed to mount this attack, but it's quite within the realm of possibility. We can even do a time-memory tradeoff and do <span class="math inline">\(2^{56 + s}\)</span> DES operations in return for <span class="math inline">\(2^{56 - s}\)</span> bits of memory, which can easily bring the memory requirements down to a manageable size while keeping the number of operations feasible.</p>
<h1 id="section-6">18/1/17</h1>
<p>Why do we need 3 pairs of known plaintext/ciphertext pairs rather than just 1 or 2? Well, for each key in the key space, we can think of the encryption function is just a random function (it's not, but this is a good enough assumption for our purposes).</p>
<p>Let <span class="math inline">\(k\)</span> be the actual <span class="math inline">\(l\)</span>-bit secret key (so <span class="math inline">\(E_k(m) = c\)</span>) and <span class="math inline">\(k&#39;\)</span> (also <span class="math inline">\(l\)</span> bits) be our guess for this key. If <span class="math inline">\(E_{k&#39;}\)</span> is a uniformly random function (from our assumption), then it clearly has a <span class="math inline">\(\frac 1 {2^L}\)</span> probability of satisfying <span class="math inline">\(E_{k&#39;}(m) = c\)</span>, where <span class="math inline">\(L\)</span> is the number of bits in the plaintext - it might just randomly happen to output the right ciphertext given our particular plaintext. What's the probability that our guess is correct if it satisfies <span class="math inline">\(E_{k&#39;}(m) = c\)</span>?</p>
<p>Suppose <span class="math inline">\(E_{k&#39;}(m) = c\)</span> and <span class="math inline">\(k&#39; \ne k\)</span> (our guess for the key is incorrect, but gives the right ciphertext for our particular plaintext). Then the number of <span class="math inline">\(E_{k&#39;}\)</span> such that <span class="math inline">\(E_{k&#39;}(m) = c\)</span> is <span class="math inline">\(\frac{2^l - 1}{2^{L}}\)</span> (<span class="math inline">\(2^l - 1\)</span> is the number of keys in the keyspace that are not the actual key, and <span class="math inline">\(2^{L}\)</span> is the number of possible plaintexts). This is essentially the number of incorrect keys that work for a single plaintext/ciphertext pair without actually being the correct key.</p>
<p>We want to use enough plaintext/ciphertext pairs such that the expected number of these incorrect keys is close to 0. Clearly, with <span class="math inline">\(t\)</span> of these pairs, we have <span class="math inline">\(\frac{2^l - 1}{2^{Lt}}\)</span> expected false keys. For Double-DES, one pair gives us <span class="math inline">\(\frac{2^{112} - 1}{2^{64}}\)</span> expected incorrect keys, which is far too many. With 3 pairs, we get around <span class="math inline">\(\frac 1 {2^{16}}\)</span> expected false keys, much more reasonable.</p>
<p>There's also triple DES, which is just applying DES three times now - <span class="math inline">\(c = E_{k_1}(E_{k_2}(E_{k_3}(m)))\)</span>, where <span class="math inline">\(c\)</span> is the resulting ciphertext, <span class="math inline">\(m\)</span> is the plaintext, and <span class="math inline">\(k_1, k_2, k_3\)</span> are the three 56-bit DES keys. We don't have any proof that it's more secure than DES alone, but a meet-in-the-middle attack takes around <span class="math inline">\(2^{112}\)</span> steps, around <span class="math inline">\(2^{64}\)</span> message/plaintext pairs, and a huge table.</p>
<p>Given our plaintext <span class="math inline">\(m = m_1 \ldots m_t\)</span>, how do we encrypt it if the Block cipher modes of operation:</p>
<ul>
<li>Electronic Codebook (ECB) - input is split into blocks, and then each block is encrypted with the key using the block cipher. In other words, for each plaintext block <span class="math inline">\(i\)</span>, <span class="math inline">\(c_i = E_k(m_i)\)</span>.
<ul>
<li>This is very bad, never use it - identical plaintext blocks result in identical ciphertext blocks under the same key, so chosen-plaintext attacks can tell you whether a given plaintext block is equal to an attacker-chosen plaintext block.</li>
</ul></li>
<li>Cipher Block Chaining (CBC) - select a random <span class="math inline">\(L\)</span>-bit initialization vector (where <span class="math inline">\(L\)</span> is the block size) as <span class="math inline">\(c_0\)</span>. Then, for each plaintext block <span class="math inline">\(i\)</span>, let <span class="math inline">\(c_i = E_k(m_i \lxor c_{i - 1})\)</span>.
<ul>
<li>This is actually proven to be semantically secure against chosen plaintext attacks, assuming that the block cipher itself is semantically secure.</li>
</ul></li>
</ul>
<p>AES was developed as part of a public, open competition in 1997 to build a successor to DES. It needed to have 3 key sizes (128, 192, and 256 bits), have a 128-bit block size, and be efficiently implementable on hardware/software. While 128 bits is infeasible for the foreseeable future, the larger key sizes are intended to protect against potential future attacks, as well as quantum computers - Grover's algorithm can perform exhaustive key search in only <span class="math inline">\(2^{\frac 1 2 l}\)</span> operations, where <span class="math inline">\(l\)</span> is the number of bits in the key.</p>
<p>With 15 submissions initially, Rijndael won in the end. Rijndael became AES in late 2001.</p>
<p>Rijndael is an iterated block cipher, not a Fiestel cipher. Specifically, a substitution-permutation network. Currently, there's no known attack better than exhaustive key search on AES.</p>
<p>We won't cover the technical details of AES in this course, but some more details are available in the slides</p>
<h1 id="section-7">20/1/17</h1>
<p><span class="math inline">\(x \in_R S\)</span> means that <span class="math inline">\(x\)</span> is randomly and independently chosen from <span class="math inline">\(S\)</span>.</p>
<p>A hash function is a fixed function that transforms an input of arbitrary length and output a fixed-length string, called a <strong>digest</strong>. Some common hash functions are MD5, SHA1, and SHA512.</p>
<p>Formally, an <span class="math inline">\(n\)</span>-bit hash function is <span class="math inline">\(H: \set{0, 1}^* \to \set{0, 1}^n\)</span>. A good hash function should satisfy three examples:</p>
<ul>
<li><strong>Pre-image resistance</strong> - given a randomly selected hash value <span class="math inline">\(y \in \set{0, 1}^n\)</span>, it is computationally infeasible to find <span class="math inline">\(x\)</span> such that <span class="math inline">\(H(x) = y\)</span>.
<ul>
<li>In other words, it's hard to invert the hash function.</li>
<li>Consider a service that stores accounts as user IDs and hashes of passwords. If the account data was leaked and the hash function didn't have pre-image resistance, attackers could obtain the</li>
</ul></li>
<li><strong>Second pre-image resistance</strong> - given a randomly selected hash value <span class="math inline">\(x \in \set{0, 1}^*\)</span>, it is computationally infeasible to find a <span class="math inline">\(x&#39; \ne x\)</span> such that <span class="math inline">\(H(x&#39;) = H(x)\)</span>.
<ul>
<li>In other words, it's hard to find a collision for a given input in the hash function.</li>
<li>Consider a software publisher that has users verify their updates using a certain hash. If the hash function doesn't have second pre-image resistance, attackers can construct a different update that still passes verification.</li>
</ul></li>
<li><strong>Collision resistance</strong> - it is computationally infesible to find <span class="math inline">\(x, x&#39; \in \set{0, 1}^*\)</span> such that <span class="math inline">\(x \ne x&#39;\)</span> and <span class="math inline">\(H(x) = H(x&#39;)\)</span> (a <strong>collision</strong> is such a pair <span class="math inline">\(\tup{x, x&#39;}\)</span>).
<ul>
<li>In other words, it's hard to find any collisions in the hash function.</li>
<li>Note that hash functions must necessarily 0, have collisions, by pidgeonhole principle and the fact that the output space is finite while the input space is infinite. However, it should be computationally feasible to find even a single one.</li>
<li>Consider the common practice of digital signature schemes signing the hash of the message rather than the message itself (due to overhead of signing long messages using things like RSA). If a hash wasn't collision resistant, the signer could find a collision <span class="math inline">\(x, x&#39;\)</span>$, sign <span class="math inline">\(x\)</span>, and later on claim to have signed <span class="math inline">\(x&#39;\)</span> instead. That means Alice might</li>
<li>Collision resistance implies second pre-image resistance (this is easily proved via the contrapositive).</li>
<li>Second pre-image resistance doesn't imply collision resistance, however (this is easily proved by constructing a hash function with only 1 collision that is computationally feasible to find).</li>
<li>Collision resistance also doesn't imply pre-image resistance. Let <span class="math inline">\(H\)</span> be an <span class="math inline">\(n - 1\)</span>-bit pre-image and collision resistant hash function. Let <span class="math inline">\(\overline H = \begin{choices} 1 . x \text{ if } x \text{ has } n - 1 \text{ bits} \\ 0 . H(x) \end{choices}\)</span>. Clearly, <span class="math inline">\(H&#39;\)</span> is still collision-resistant, but any random hash value that begins with a 1 (so 50% of all hash values) has a trivially computable pre-image (just take off the 1 at the beginning). Therefore, <span class="math inline">\(H\)</span> is a function that is collision resistant yet not pre-image resistant.</li>
<li>That said, if the hash function is somewhat uniform (so hash values all tend to have roughly equal numbers of pre-images), collision resistance does guarantee preimage resistance. We'll prove this by contradiction. Suppose we have a hash function <span class="math inline">\(H\)</span> that is collision resistant and somewhat uniform, but not pre-image resistant. Let <span class="math inline">\(x\)</span> be an arbitrary input, and find a pre-image of <span class="math inline">\(H(x)\)</span>. Since <span class="math inline">\(H(x)\)</span> has roughly the same number of pre-images as for any other hash value, it should have a lot of pre-images. Plus, since it's not pre-image resistant, we can find another <span class="math inline">\(x&#39;\)</span> such that <span class="math inline">\(H(x&#39;) = H(x)\)</span>. However, <span class="math inline">\(x&#39;\)</span> and <span class="math inline">\(x\)</span> are now a collision, which we found efficiently, so <span class="math inline">\(H\)</span> isn't collision resistant - contradiction! Therefore <span class="math inline">\(H\)</span> must be pre-image resistant as well.</li>
<li>Therefore, collision resistance is the hardest property to achieve in practice, which makes sense, since the hash function must have infinite collisions.</li>
</ul></li>
</ul>
<p>A <strong>Davies-Meyer hash function</strong> is a family of hash functions that uses block ciphers. Basically, given a fixed IV <span class="math inline">\(H_0\)</span> and an <span class="math inline">\(n\)</span>-bit block encryption function <span class="math inline">\(E_k\)</span>, we break up the plaintext into <span class="math inline">\(n\)</span>-bit blocks <span class="math inline">\(x_1, \ldots, x_t\)</span> (after appending 1 to the end and padding with 0 to the nearest block size), then <span class="math inline">\(H_i = E_{x_i}(H_{i - 1}) \lxor H_{i - 1}\)</span> and <span class="math inline">\(H_t\)</span> is the hash value.</p>
<p>A <strong>one-way function</strong> is a pre-image resistant hash function. A <strong>cryptographic hash function</strong> is a pre-image resistant and collision-resistant hash function.</p>
<p>A <strong>generic attack</strong> is an attack on a hash function that treats it as a black-box/ideal hash function. As a result, a generic attack must treat the hash function as a random function <span class="math inline">\(H: \set{0, 1}^* \to \set{0, 1}^n\)</span> (an ideal hash function is a random function). In practice, actual random functions are too complex to represent in a reasonable way.</p>
<p>A generic attack for finding pre-images: select arbitrary <span class="math inline">\(x \in \set{0, 1}^*\)</span> until we find <span class="math inline">\(H(x) = y\)</span>. Clearly, we expect about <span class="math inline">\(2^n\)</span> time. A generic attack for finding collisions: select arbitrary <span class="math inline">\(x \in \set{0, 1}^*\)</span> and store them in a table indexed by <span class="math inline">\(H(x)\)</span>, until a hash is found. By birthday paradox, we expect that to take about <span class="math inline">\(\sqrt{2^n}\)</span> time and memory.</p>
<h1 id="section-8">23/1/17</h1>
<p>Checking for collisions generically, as mentioned last class, would take around <span class="math inline">\(\sqrt{2^n}\)</span> time and memory. However, there's actually a generic attack for finding collisions that has the same order of running time (<span class="math inline">\(\sqrt{\frac{\pi 2^n}{2}}\)</span>), but requires far less memory.</p>
<p>Basically, given <span class="math inline">\(H: \set{0, 1}^* \to \set{0, 1}^n\)</span>, we want to find <span class="math inline">\(x_1, x_2 \in \set{0, 1}^*\)</span>, where <span class="math inline">\(x_1 \ne x_2\)</span> yet <span class="math inline">\(H(x_1) = H(x_2)\)</span>. How does this algorithm, known as the Van Oorschot/Weiner (VW) algorithm, work?</p>
<p>First, we assume that <span class="math inline">\(H: \set{0, 1}^n \to \set{0, 1}^n\)</span> is a random function. Now, we'll search for <span class="math inline">\(x_1, x_2\)</span> in <span class="math inline">\(\set{0, 1}^n\)</span> rather than <span class="math inline">\(\set{0, 1}^*\)</span>, by defining a sequence of hash values <span class="math inline">\(w_0 \in_R \set{0, 1}^n, w_i = H(w_{i - 1})\)</span> - a sequence consisting of a hash value, the hash of that hash value, the hash of the hash of that hash value, and so on. This is a random sequence since we're assuming <span class="math inline">\(H\)</span> is a random function.</p>
<p>Clearly, there must be a repeat (collision) in the sequence somewhere, because an element of the sequence can only have one of <span class="math inline">\(2^n\)</span> possible values. That means the sequence is finite and ends in a cycle. Let <span class="math inline">\(j\)</span> be the smallest index such that <span class="math inline">\(x_j = x_i\)</span> for some <span class="math inline">\(i &lt; j\)</span> - <span class="math inline">\(j\)</span> must exist because there must exist a collision. Since , <span class="math inline">\(x_{j + l} = x_{i + l}\)</span> for any <span class="math inline">\(l \ge 0\)</span>.</p>
<p>Let <span class="math inline">\(N = 2^n\)</span>. From the birthday paradox, we expect the value of <span class="math inline">\(j\)</span> to be <span class="math inline">\(E[j] = \sqrt{\frac{\pi N}{2}}\)</span>, or around <span class="math inline">\(\sqrt{2^n}\)</span>.</p>
<p>Also, <span class="math inline">\(E[i] = E[j - i] = \frac 1 2 \sqrt{\frac{\pi N}{2}}\)</span>. If we assume, without loss of generality, that <span class="math inline">\(i \ne 0\)</span>, then <span class="math inline">\(H(x_{i - 1}) = H(x_{j - 1})\)</span> and <span class="math inline">\(x_{i - 1} \ne x_{j - 1}\)</span> (with very high probability) - a collision!</p>
<p>How do we actually find <span class="math inline">\(x_{i - 1], x_{j - 1}\)</span>, without using much storage?</p>
<p>If we think of the sequence of hashes is like a linked list, where <span class="math inline">\(H(x_i)\)</span> gets the next element <span class="math inline">\(x_{i + 1}\)</span>, then this simply becomes a problem analogous to finding cycles in a linked list, which we could solve using something like the tortoise-and-hare algorithm with just constant memory. However, that means a lot of wasted time unnecessarily computing hashes, and it only tells us that there is a collision, not what the collision actually is.</p>
<p>A better way we could do this is to define some easily distinguishable property of the hash values that applies to around fraction <span class="math inline">\(\theta\)</span> of all hash values, for a small value of <span class="math inline">\(\theta\)</span>. For example, the property might be &quot;the first 20 bits are 0&quot; (<span class="math inline">\(\frac 1 {2^20}\)</span> of hash values satisfy this property). Then, we only store the hash values in the sequence that satisfy this property (these hash values are called &quot;distinguished points&quot;).</p>
<p>When we encounter a distinguished point for the second time, we've found a collision somewhere behind us in the sequence - assuming there's a distinguished point between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, we must eventually encounter it again when our sequence loops around to <span class="math inline">\(x_{j}\)</span>. We can assume there's a distinguished point between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> because our <span class="math inline">\(\theta\)</span> is chosen to be large enough that there is a very high probability that there is a distinguished point in the cycle - for example, for a 32-bit hash we would expect the cycle to contain about <span class="math inline">\(\frac 1 2 2^{32} = 2^{31}\)</span> entries, so we might make our distinguishing property &quot;the first 21 bits are 0&quot;, giving an expected value of <span class="math inline">\(2^{10}\)</span> distinguished points in the cycle.</p>
<p>That does mean there's a very tiny chance the algorithm doesn't terminate, however - we can get around this by limiting the length of the path to <span class="math inline">\(2^n\)</span> and retrying. There are a lot of other edge cases too (what if the starting value has a collision in the sequence?), but they all happen with negligible probability and can be handled with relatively few operations.</p>
<p>Algorithm:</p>
<ol style="list-style-type: decimal">
<li>Randomly select a <span class="math inline">\(x_0\)</span> from <span class="math inline">\(\set{0, 1}^n\)</span>, store <span class="math inline">\(\tup{x_0, 0, \text{empty}}\)</span> in the table.</li>
<li>Let <span class="math inline">\(L = x_0\)</span> (<span class="math inline">\(L\)</span> is the most recently stored distinguished point).</li>
<li>For <span class="math inline">\(j \ge 1\)</span> do (phase one starts - finding duplicate points):
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(x_j = H(x_{j - 1})\)</span>.</li>
<li>If <span class="math inline">\(x_j\)</span> is distinguished:
<ol style="list-style-type: decimal">
<li>Store <span class="math inline">\(\tup{x_j, j, L}\)</span> into the table and let <span class="math inline">\(L = x_j\)</span>.</li>
<li>If <span class="math inline">\(x_j\)</span> was already in the table, we know <span class="math inline">\(x_i = x_j\)</span>, and stop this loop to begin phase 2 - finding the actual collision values.</li>
</ol></li>
</ol></li>
<li>Let <span class="math inline">\(a\)</span> be the index of the distinguished point right before <span class="math inline">\(i\)</span>, and <span class="math inline">\(b\)</span> be the index of the distinguished point right before <span class="math inline">\(j\)</span>. This can be looked up as the third element of tuples in the table - the values of <span class="math inline">\(L\)</span> associated with <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> respectively.</li>
<li>Let <span class="math inline">\(l_1 = i - a, l_2 = j - b\)</span>. Assume without loss of generality that <span class="math inline">\(l_1 \ge l_2\)</span>. Let <span class="math inline">\(R = l_1 - l_2\)</span> - how much longer the earlier chain is until the collision than the later chain.</li>
<li>Compute <span class="math inline">\(x_{a + 1}, \ldots, x_{a + R}\)</span>. Let <span class="math inline">\(p_1 = x_{a + R}\)</span> and <span class="math inline">\(q_1 = x_b\)</span>. Now the collision is an equal number of hashes away from <span class="math inline">\(p_1\)</span> and <span class="math inline">\(q_2\)</span>.</li>
<li>Let <span class="math inline">\(p_{k + 1} = H(p_k)\)</span> and <span class="math inline">\(q_{k + 1} = H(q_k)\)</span>. Compute <span class="math inline">\(p_k\)</span> and <span class="math inline">\(q_k\)</span> until we find a value <span class="math inline">\(k\)</span> such that <span class="math inline">\(p_k = q_k\)</span>. Then, the previous value <span class="math inline">\(p_{k - 1}\)</span> and <span class="math inline">\(q_{k - 1}\)</span> form a collision.</li>
</ol>
<p>So overall, step 3 takes around <span class="math inline">\(\sqrt{\frac{\pi N}{2}} + \frac 1 \theta\)</span> time, while the steps after it take <span class="math inline">\(\frac 3 \theta\)</span>. The memory usage is around <span class="math inline">\(\theta \sqrt{\frac{\pi N}{2}} \times 3n\)</span> bits.</p>
<h1 id="section-9">25/1/17</h1>
<p>If we have a 128-bit hash, we might choose a <span class="math inline">\(\theta = \frac 1 {2^{32}}\)</span>, for about <span class="math inline">\(2^{96}\)</span> distinguished points. With this, we would expect around <span class="math inline">\(2^{64}\)</span> operations and <span class="math inline">\(2^{41}\)</span> bits, or around 256 gibibytes - totally feasible on modern hardware. This tells us that any 128-bit hashes are simply not collision-resistant today.</p>
<p>How do we parallelize the VW algorithm, given <span class="math inline">\(m\)</span> processors? One naive way is to run the algorithm with different starting values on each processor (each with its own memory), and see which one finishes first. Turns out this uses time <span class="math inline">\(\frac{\sqrt{\frac{\pi N}{2}}}{\sqrt{m}} + \frac 4 \theta\)</span> - not very good scaling.</p>
<p>Instead, we can store all of the distinguished points from the <span class="math inline">\(m\)</span> processors in a central table - at each time unit, each processor adds a new unique hash value, until one of the distinguished points collide. This takes <span class="math inline">\(\frac{\sqrt{\pi N}{2}}{m} + \frac 4 \theta\)</span> operations, which is about as well as you can expect this algorithm to be parallelized.</p>
<p>How do we find meaningful collisions in a hash function? Suppose <span class="math inline">\(m_1\)</span> is &quot;Alice owes Bob 1000 dollars&quot; and <span class="math inline">\(m_2\)</span> is &quot;Alice owes Bob 10 dollars&quot;. Alice wants to find values <span class="math inline">\(m_1&#39;, m_2&#39;\)</span> that semantically mean the same thing as <span class="math inline">\(m_1, m_2\)</span> (e.g., &quot;Alice should give Bob $1000&quot; and &quot;Alice ought to pay Bob $10&quot;), sign <span class="math inline">\(m_1\)</span>, make Bob agree to it, and then later claim to have signed <span class="math inline">\(m_2\)</span>. After Bob agrees to it, Alice can claim to have signed <span class="math inline">\(m_2\)</span> instead, only owing 10 dollars rather than 1000 dollars. How can Alice find <span class="math inline">\(m_1&#39;, m_2&#39;\)</span> using the VW algorithm?</p>
<p>Partition <span class="math inline">\(m_1\)</span> into <span class="math inline">\(n\)</span> parts, with partitions at indices <span class="math inline">\(j_1, \ldots, j_n\)</span>. Let <span class="math inline">\(g_{m_1}(r): \set{0, 1}^n \to \set{0, 1}^*\)</span> be <span class="math inline">\(m_1\)</span> modified so that a space is inserted into <span class="math inline">\(m_1\)</span> at position <span class="math inline">\(j_i\)</span> if and only if the <span class="math inline">\(i\)</span>th bit of <span class="math inline">\(r\)</span> is 1. Note that <span class="math inline">\(g_{m_1}(r)\)</span> should have the same meaning as <span class="math inline">\(m_1\)</span>, since we just added a space somewhere. Likewise, define <span class="math inline">\(g_{m_2}(r)\)</span> for inserting spaces into <span class="math inline">\(m_2\)</span>.</p>
<p>Let <span class="math inline">\(S_0\)</span> be the elements of <span class="math inline">\(\set{0, 1}^*\)</span> that begin with 0, and <span class="math inline">\(S_1\)</span> be the elements that begin with 1. Let <span class="math inline">\(f: \set{0, 1}^n \to \set{0, 1}^n\)</span> as <span class="math inline">\(f(r) = \begin{cases} H(g_{m_1}(r)) \text{ if } r \in S_0 \\ H(g_{m_2}(r)) \text{ if } r \in S_1 \end{cases}\)</span> - the hash of a message semantically equivalent to <span class="math inline">\(m_1\)</span> if <span class="math inline">\(r\)</span> begins with 0, and the hash of a message semantically equivalent to <span class="math inline">\(m_2\)</span> if <span class="math inline">\(r\)</span> begins with 1.</p>
<p>If we run the VW algorithm on <span class="math inline">\(f\)</span> to find a colliding <span class="math inline">\(r\)</span>, we get a collision <span class="math inline">\(a, b \in \set{0, 1}^n\)</span> with <span class="math inline">\(a \ne b\)</span> and <span class="math inline">\(f(a) = f(b)\)</span>. With 50% probability, the first bit of <span class="math inline">\(a\)</span> is different from the first bit of <span class="math inline">\(b\)</span>, assuming they're drawn from a uniform distribution (we can assume this because we assume the hash function is a random function).</p>
<p>Suppose that the first bits are different - then <span class="math inline">\(a = g_{m_1}(r)\)</span> and <span class="math inline">\(b = g_{m_2}(r)\)</span>, and <span class="math inline">\(a, b\)</span> are two messages, semantically the same thing as <span class="math inline">\(m_1, m_2\)</span> respectively, that collide. If the first bits are not different, then we can just run the VW algorithm repeatedly with a different starting point until we get a collision that does have messages with two different first bits. Clearly, the running time is essentially the same for each iteration, and with a 50% probability of success, we can just run it a few times with different variants of <span class="math inline">\(g_{m_1}, g_{m_2}\)</span> until we get a meaningful collision.</p>
<h1 id="section-10">27/1/17</h1>
<p>So now we've looked at the naive hash collision finding, the VW algorithm, the parallel VW algorithm, and the meaningful collisions with the parallel VW algorithm.</p>
<p>Now let's look at general methods for constructing hash functions. <strong>Merkle's meta method</strong> is one of these.</p>
<p>Given an input of <span class="math inline">\(n + r\)</span> bits, we define a compression function <span class="math inline">\(f: \set{0, 1}^{n + r} \to \set{0, 1}^n\)</span>. We also have an IV value in <span class="math inline">\(\set{0, 1}^n\)</span>. Using these, we can use Merkle's meta method to define a hash function <span class="math inline">\(H: \set{0, 1}^* \to \set{0, 1}^n\)</span>.</p>
<p>Let <span class="math inline">\(x \in \set{0, 1}^*\)</span>. Let <span class="math inline">\(x_1 \ldots x_t\)</span> be <span class="math inline">\(x\)</span> broken into <span class="math inline">\(r\)</span>-bit blocks (the last one should be zero-padded if needed). Let <span class="math inline">\(x_{t + 1}\)</span> be the binary representation of the length of <span class="math inline">\(x\)</span> in bits (technically, this limits the length of <span class="math inline">\(x\)</span> to <span class="math inline">\(2^r\)</span>, but in practice <span class="math inline">\(2^r\)</span> is so large that we can simply pretend <span class="math inline">\(x\)</span> is unbounded in length).</p>
<p>Let <span class="math inline">\(H_0\)</span> be the IV. For <span class="math inline">\(1 \le i \le t + 1\)</span>, we do <span class="math inline">\(H_i = f(H_{i - 1}, x_i)\)</span>. Then, <span class="math inline">\(H(x) = H_{t + 1}\)</span>.</p>
<p>Merkle's theorem says that if <span class="math inline">\(f\)</span>, the compression function, is collision-resistant, then so is <span class="math inline">\(H\)</span>. This means we only have to make a fixed input size function collision-resistant, rather than an unbounded-input-size function collision-resistant. That means we should usually try to attack the compression function <span class="math inline">\(f\)</span> rather than the hash function itself.</p>
<p>This theorem can be proven using the contrapositive. Assume <span class="math inline">\(H\)</span> is not collision resistant, so we can efficiently find a collision <span class="math inline">\(\tup{x, x&#39;} \in \set{0, 1}^*\)</span>. Let <span class="math inline">\(\overline x = x_1 \ldots x_t\)</span> and <span class="math inline">\(b\)</span> be the length of <span class="math inline">\(x\)</span> in bits and <span class="math inline">\(H_1, \ldots, H_{t + 1}\)</span> be the iteration values for <span class="math inline">\(x\)</span>, and let <span class="math inline">\(\overline x&#39; = x_1&#39; \ldots x_{t&#39;}&#39;\)</span> and <span class="math inline">\(b&#39;\)</span> be the length of <span class="math inline">\(x&#39;\)</span> in bits and <span class="math inline">\(H_1&#39;, \ldots, H_{t&#39; + 1}&#39;\)</span> be the iteration values for <span class="math inline">\(x&#39;\)</span>. Clearly, if <span class="math inline">\(b \be b&#39;\)</span>, then <span class="math inline">\(x_{t + 1} \ne x_{t&#39; + 1}&#39;\)</span>, so <span class="math inline">\(f(H_t, x_{t + 1}) = f(H_t&#39;, x_{t&#39; + 1}&#39;)\)</span> and <span class="math inline">\(x_{t + 1} \ne x_{t&#39; + 1}&#39;\)</span> - a collision! Now suppose <span class="math inline">\(b = b&#39;\)</span>, so <span class="math inline">\(x_{t + 1} = x_{t + 1}&#39;\)</span> and <span class="math inline">\(t = t&#39;\)</span>. If we work backwords from the last iteration toward the first iteration, we must eventually find some <span class="math inline">\(H_i = f(H_{i - 1}, x_i)\)</span> and <span class="math inline">\(H_i&#39; = f(H_{i - 1}&#39;, x_i&#39;)\)</span> such that <span class="math inline">\(\tup{H_{i - 1}, x_i} \ne \tup{H_{i - 1}&#39;, x_i&#39;}\)</span>, since <span class="math inline">\(x \ne x&#39;\)</span> - they must differ in at least one message block. This is a collision for <span class="math inline">\(f\)</span>. So, a collision is always computationally efficient to find for <span class="math inline">\(f\)</span>. So if <span class="math inline">\(f\)</span> is collision resistant, <span class="math inline">\(H\)</span> must be as well.</p>
<h1 id="section-11">30/1/17</h1>
<p>MDx is a family of iterated hash functions, the most well-known of which are MD4 and MD5. MD4 was a 128-bit hash invented by Ron Rivest in 1990, but it had some serious flaws - in 2004 someone found collisions by hand. Pre-image is still infeasible, however.</p>
<p>MD5 is another 128-bit hash, a strengthened version of MD4. Since its invention in 1991, we've found MD5 collisions in 31 seconds in 2006 on commodity hardware, while preimages can be found in <span class="math inline">\(2^{123.4}\)</span> steps. However, MD5 is still in very wide use today.</p>
<p>SHA-1 is a 160-bit hash function invented by the NSA in 1993, and modified by the NSA again in 1994 to fix a classified weakness. In 2005, it was found that that fix increased the cost of finding collisions from <span class="math inline">\(2^{39}\)</span> to <span class="math inline">\(2^{63}\)</span>. Collisions are feasible to find today, but nobody seems to have done it yet - we still want to move away from SHA-1 though, since it's theoretically feasible to find collisions. We don't know of any pre-image/second pre-image attacks on SHA-1 that are faster than the generic attacks. In about two weeks from now, SSL will no longer consider SHA-1 hashes for server certificates valid. SHA-1 is a Merkle-style hash with <span class="math inline">\(n = 160, r = 512\)</span>. Most of the design decisions are classified, because NSA, and the hash operations themselves are rather messy.</p>
<p>In 2001 the NSA proposed SHA-2, a family of hash functions with three variants, each with different output sizes - SHA-256, SHA-384, and SHA-512. Note that SHA-2 has the same security against collisions as AES-128/AES-192/AES-256. As of this writing, no attacks stronger than the generic attacks have been found, but there are concerns remaining because the design is pretty similar to SHA-1.</p>
<p>SHA-3 is a NIST hash function competition, much like the competition that resulted in AES. Starting with 64 candidates, Keecak was selected as the winner in 2012. Keecak isn't an iterated hash function, using a sponge construction method, and it isn't very widely used in practice due to most people being fine with the SHA-2 family.</p>
<p>NIST recommends we stop using SHA-1 if possible, though it's okay for HMACs/KDFs/RNGs. SHA-2 and SHA-3 are recommended.</p>
<p>Suppose we can find a meaningless collision in an iterated hash function <span class="math inline">\(\tup{x, y}\)</span>. How can we exploit this in practice?</p>
<p>Wang proposed an attack on SHA-1 that gives us a two-block collision (two two-block-long messages that hash to the same value) that takes only around <span class="math inline">\(2^{63}\)</span> operations. Wang also proposed an attack on MD5 that gives us a one-block collision (two one-block-long messages that hash to the same value) in only <span class="math inline">\(2^{39}\)</span> operations. We've actually applied these and found real collisions in SHA-1 and MD5. How do we exploit this concretely?</p>
<p>Suppose <span class="math inline">\(\tup{c_1, c_2}\)</span> is a one-block MD5 collision (without loss of generality, assume the blocks don't contain <code>(</code> or <code>)</code>, so it can fit into a Postscript literal). Now consider the following two Postscript files:</p>
<pre><code>%!PS-Adobe-1.0
%%BoundingBox: 0 0 612 792                   
(&lt;c_1&gt;)(&lt;c_1&gt;)eq{
&lt;HARMLESS MESSAGE&gt;
}{
&lt;HARMFUL MESSAGE&gt;
}ifelse
showpage</code></pre>
<pre><code>%!PS-Adobe-1.0
%%BoundingBox: 0 0 612 792                   
(&lt;c_2&gt;)(&lt;c_1&gt;)eq{
&lt;HARMLESS MESSAGE&gt;
}{
&lt;HARMFUL MESSAGE&gt;
}ifelse
showpage</code></pre>
<p>The two files are identical except for line 3, where we have <code>&lt;c_1&gt;</code> in the first and <code>&lt;c_2&gt;</code> in the second.</p>
<p>Clearly, the first one prints out the harmless message, while the second one prints out the harmful message. However, note that the second line has been padded with spaces so that the second block starts exactly at either <code>&lt;c_1&gt;</code> in the first message, or <code>&lt;c_2&gt;</code> in the second message (MD5 uses a block size of 64 bytes, and the file is assumed to be using Windows-style CR-LF line endings).</p>
<p>Suppose <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> have the same number of blocks in an iterated hash function. Let <span class="math inline">\(F(I, x) = H_t\)</span> where <span class="math inline">\(I = H_0\)</span> and <span class="math inline">\(H_i = f(H_{i - 1}, x_i)\)</span>. Clearly, if <span class="math inline">\(F(I, x) = F(I, y)\)</span>, then <span class="math inline">\(F(I, xz) = F(I, yz)\)</span> for any string <span class="math inline">\(z\)</span>. In other words, given a collision <span class="math inline">\(\tup{x, y}\)</span>, <span class="math inline">\(\tup{xz, yz}\)</span> is also a collision for any string <span class="math inline">\(z\)</span>. This is called a <strong>length extension attack</strong>.</p>
<p>Also, if <span class="math inline">\(F(I, x) = F(I, y)\)</span>, then <span class="math inline">\(F(I, zx) = F(I, zy)\)</span> for any string <span class="math inline">\(z\)</span> that is an integer multiple of the block size long. In other words, given a collision <span class="math inline">\(\tup{x, y}\)</span>, <span class="math inline">\(\tup{zx, zy}\)</span> is also a collision for any blocks <span class="math inline">\(z\)</span>.</p>
<p>Note that each Postscript document can be made by prepending a block to one of <code>&lt;c_1&gt;</code>/<code>&lt;c_2&gt;</code>, and then appending the rest of the document. Since <code>&lt;c_1&gt;</code>/<code>&lt;c_2&gt;</code> collide, the Postscript documents themselves must also collide!</p>
<p>Suppose Alice sends Bob the first Postscript file, and asks Bob for a signature. Bob opens it in a Postscript viewer, sees the harmless message, then signs the MD5 hash of the document (because signing the whole document with public key crypto would be too unwieldy), and sends the signature to Alice. However, Alice now has a signature from Bob for the second Postscript document, which has the same MD5 hash but a different, harmful message - Alice has convinced Bob to sign something Bob didn't want to!</p>
<p>(Menezes now demonstrates an MD5 collision on a real document, where the MD5 hash of a Postscript file that results in a PDF saying &quot;John didn't leave his hat in my office&quot; collides with a Postscript file that results in a PDF saying &quot;John should be given a mark of 100 in this course&quot;.)</p>
<h1 id="section-12">1/2/17</h1>
<p>;wip: slides up to slide 192 ish, MAC schemes (a lot like the cipher block chaining scheme used for symmetric ciphers),</p>
<h1 id="section-13">3/2/17</h1>
<p>Instead, we can append the key to the message before we hash it, rather than prepending it. This ensures that the attacker can't use a length extension attack anymore, but it requires the hash function to be collision resistant in order for the MAC to secure. This is called the <strong>secret suffix method</strong>.</p>
<p>If the hash function isn't collision resistant, then we can efficiently find a collision <span class="math inline">\(\tup{x_1, x_2}\)</span>. Then <span class="math inline">\(x\)</span> ;wip: collision attack</p>
<p>To avoid the need for collision resistance in the hash function, we can use the <strong>envelope method</strong>, in which we prepend and append the key to the message before we hash it. This successfully avoids the length extension and collision attacks.</p>
<p>The <strong>Hash MAC</strong> (HMAC) is a commonly used MAC scheme that . <span class="math inline">\(H_k(x) = H(K \oplus \mathrm{opad} . H(K \oplus \mathrm{ipad} . x))\)</span>, where <span class="math inline">\(\mathrm{ipad} = 0x36, \mathrm{opad} = 0x5C\)</span> repeated for each byte of <span class="math inline">\(K\)</span>. The inner hash is just the secret prefix method, but hashing for the second time ensures that the hash can't . This can be proven to be secure if the compression function used in the iterated hash function <span class="math inline">\(H\)</span> is itself a secure MAC scheme with fixed length messages and a secret IV.</p>
<p>HMAC is used a lot in industry, as part of IPSec, SSL, and TLS. In practice, we generally use SHA-1 for the HMAC hash function, and it seems to be unaffected by the known weaknesses in SHA-1.</p>
<p>A secure symmetric encryption scheme ensures confidentiality. A secure MAC scheme like HMAC ensures authentication (data integrity and data origin authentication). If Alice needs to send Bob a message with both confidentiality and authentication, one way to do this is Alice can send Bob <span class="math inline">\(\tup{c, t} = E_{k_1}(m), H_{k_2}(m)\)</span>, where <span class="math inline">\(k_1, k_2\)</span> are secret keys pre-shared with Bob. This is called <strong>Encrypt-and-MAC</strong>. However, the issue here is that the MAC scheme isn't designed for confidentiality, only authentication, so theoretically, the HMAC might leak information about the plaintext. We still use this a lot in practice though, because most MAC schemes don't seem to leak any information about the plaintext.</p>
<p>A better way to do it would be to send <span class="math inline">\(\tup{c, t} = \tup{E_{k_1}(m), H_{k_2}(E_{k_1}(m))}\)</span> (ciphertext, tag) instead - we tag the encrypted message using the HMAC, rather than tagging the plaintext. This can be proven to be secure if the encryption and MAC scheme are secure. This is called the <strong>Encrypt-then-MAC</strong>.</p>
<p><strong>Authenticated encryption</strong> schemes try to provide both confidentiality and encryption in a more integrated package. The most common one in AES-GCM, which is faster than generic encrypt-then-MAC, as well as authentication-but-not-encrypted headers for data. It uses AES in counter mode (CTR mode - encrypting a counter using the key with AES, and then using the output of that as the CSPRNG for a stream cipher) and a custom MAC scheme, and requires the IV never be reused. One advantage of AES-GCM over something like the encrypt-then-MAC is that it's parallelizable and faster. AES-GCM outputs the IV, authenticated header, authenticated and encrypted message, and the 128-bit authentication tag.</p>
<h1 id="section-14">6/2/17</h1>
<p>AES-GCM is widely used in the real world for combined authentication and encryption, because it's fast and is proved correct by Iwata-Ohashi-Minematsu in 2012, under certain assumptions. In fact, Intel and AMD processors have special instructions to make AES-GCM implementations a lot faster.</p>
<h2 id="public-key-cryptography">Public Key Cryptography</h2>
<p>The main drawback of symmetric cryptography is the <strong>key establishment problem</strong> - how do we distribute secret keys to all the parties that need it, but nobody else?</p>
<p>One way to solve this is to distribute keys over a secure channel point-to-point, like a face to face meeting, a trusted courier, or a key embedded in a smart card. However, it's hard to obtain a secure channel, and if we already had a secure channel, we could often just use that channel to communicate instead.</p>
<p>Another way is to give the key to a trusted third party, which distributes the secret key as desired. However, finding a trusted third party is quite difficult, and it's also a single point of failure.</p>
<p>There's also the <strong>key management problem</strong> - in a network of <span class="math inline">\(n\)</span> users, each user needs one key for every other user, so there are <span class="math inline">\(O(n^2)\)</span> keys needed.</p>
<p>Also, symmetric encryption can't achieve non-repudiation, because there are always multiple parties that could have written a given message (since the key needs to be shared with other parties in order to communicate). Theoretically we could do this by sharing a key only with a trusted third party that ensures non-repudiation, but that kind of defeats the point of using cryptography for non-repudiation in the first place.</p>
<p><strong>Public key cryptography</strong> works somewhat differently. Using a public key cryptosystem, Alice and Bob first exchange authenticated (rather than secret) information, and then can communicate securely. It was first invented by Merkle, Diffie, and Hellman. It's much easier to exchange information in an authenticated way, then in a secret way. Intuitively this seems impossible, and Merkle's professor originally told him it was impossible back in 1975, but it is indeed possible.</p>
<p>The advantages of public key cryptography over symmetric cryptography are: only requiring an authenticated channel rather than a secured one, each user only has one keypair, a signed message can be verified by anyone, and signatures can achieve non-repudiation. The disadvantages are: private/public keys are usually a lot larger than symmetric cipher keys, making them harder to share in some cases, and public key cryptography is usually a lot slower.</p>
<p>Suppose Alice and Bob want to communicate securely. Alice and Bob want to establish a session key by communicating over a public, authenticated channel. We'll now describe Merkle's proof-of-concept public key cryptography idea.</p>
<p>Alice creates puzzles <span class="math inline">\(P_1, \ldots, P_N\)</span> for some large <span class="math inline">\(N\)</span>, and each puzzle takes time <span class="math inline">\(t\)</span> to solve. The solution to a given puzzle <span class="math inline">\(P_i\)</span> is the session key <span class="math inline">\(k_i\)</span> and the serial number <span class="math inline">\(n_i\)</span>, and Alice keeps track of the solutions to each generated puzzle. Alice sends all the puzzles to Bob, over the authenticated channel.</p>
<p>Then, Bob randomly selects a puzzle <span class="math inline">\(P_j\)</span>, solves it in time <span class="math inline">\(t\)</span> to obtain <span class="math inline">\(k_j\)</span> and <span class="math inline">\(n_j\)</span>, then sends <span class="math inline">\(n_j\)</span> back to Alice. Since Alice knows <span class="math inline">\(n_j\)</span>, Alice can easily look up the corresponding <span class="math inline">\(k_j\)</span>. Now, both Alice and Bob know <span class="math inline">\(k_j\)</span>, which they can now use as the session key. In contrast, Eve doesn't know which puzzle has serial number <span class="math inline">\(n_j\)</span>, so Eve must try each puzzle to see if the serial number matches. That means on average Eve must solve <span class="math inline">\(\frac N 2\)</span> puzzles, spending <span class="math inline">\(\frac{Nt}{2}\)</span> time overall. For large enough values of <span class="math inline">\(N\)</span> like <span class="math inline">\(N = 10^9\)</span>, it should become infeasible for Eve, while Bob can feasibly still solve the single puzzle.</p>
<p>One example of a Merkle puzzle is AES-encrypting the session key (128-bit) and the serial number (128-bit) (the serial number is appended to the session key twice, so we can check if the puzzle was solved correctly), with a randomly selected 40-bit string as the secret key. Then we can solve the puzzle by exhaustive key search in <span class="math inline">\(2^{40}\)</span> operations.</p>
<p>More generally, we want each communicating party <span class="math inline">\(C\)</span> to generate a key pair consisting of a public key <span class="math inline">\(P_C\)</span> and a private key <span class="math inline">\(S_C\)</span>, such that it's hard to recover $S_AC from <span class="math inline">\(P_C\)</span>, then publishes <span class="math inline">\(P_C\)</span> while keeping <span class="math inline">\(S_C\)</span> secret.</p>
<p>If A wants to communicate confidentially with B, then A obtains an authentic copy of <span class="math inline">\(P_B\)</span>, then sends B the message encrypted with <span class="math inline">\(P_B\)</span>. Bob then decrypts the message using <span class="math inline">\(S_B\)</span>, which only B knows. Since public key cryptography is so slow, we usually implement this in practice by using public key cryptography to communicate a session key (which is a fixed-length, relatively short value), and then using symmetric cryptography to encrypt the message with that session key.</p>
<p>If A wants to sign a message, A just signs the message with <span class="math inline">\(S_A\)</span>, which only A knows. To verify the signature on the message, we obtain an authentic copy of <span class="math inline">\(P_A\)</span> and verify the signature using <span class="math inline">\(P_A\)</span>. Since public key cryptography is so slow, we usually implement this in practice by hashing the message, and then using public key cryptography to sign the hash of the message (which is fixed-length, relatively short value).</p>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2017 Anthony Zhang.
</div>
<script type="text/javascript">
MathJax.Hub.Config({
  jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
</body>
</html>