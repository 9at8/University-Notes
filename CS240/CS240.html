<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CS240 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso.light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>
function highlight() { // highlight all code blocks using HighlightJS
  var code_blocks = document.getElementsByTagName("code");
  for (var i = 0; i < code_blocks.length; i++)
    hljs.highlightBlock(code_blocks[i]);
}
</script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body onload="highlight()">
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/Résumé.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="http://www.linkedin.com/pub/anthony-zhang/8b/aa5/7aa" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:azhang9@gmail.com" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.mesecons.net/">mesecons</a></li>
    <span class="divider"></span>
    <li><a href="http://www.autohotkey.net/~Uberi/">autohotkey.net</a></li>
  </ul>
<h1 id="cs240">CS240</h1>
<p>Data Structures and Data Management.</p>
<pre><code>Therese Beidl
Section 002
Email: beidl@uwaterloo.ca
Web: http://www.student.cs.uwaterloo.ca/~cs240
ISA: Joseph (Danny) Sitter
ISA Email: cs240@studennt.cs.uwaterloo.ca</code></pre>
<p><span class="math">\[
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l&#39;H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}_P)}
\]</span></p>
<p>Seciton 1 and 2 are the regular classes, and section 3 is the enhanced section and has very different content.</p>
<p>Midterm at Thurs. Feb. 26 at 4:30 PM, worth 25%. Final exam worth 50%. Must pass weighted average of exam to pass the course. 5 assignments, each worth 5%.</p>
<h1 id="section">6/1/15</h1>
<p>Assignment 0 is due on Tuesdays. Assignment 0 is due on Jan. 13. ;wip: do it</p>
<p>Suppose we have a lot of data to keep track of. We could store it in an array/list, but depending on the type of the data, this might not be the best choice. Data structures should make it easy and efficient to perform the operations we need. For example, an English dictionary probably needs to be efficiently searched, but we don't really need to care about insertion and deletion since they're so rare.</p>
<p>The best data structure for something depends on the type of data we want to store. Our goal is to have a short running time and little memory.</p>
<p>In this course we will be performing theoretical analysis, developing ideas and pseudocode (and sometimes, implementations), and analyzing them using tools like big-O notation.</p>
<p>An Abstract Data Type is the idea of describing something by what it can do, not how it does it.</p>
<p>Required background includes arrays, linked lists, strings, stacks, queues, ADTs, recursive algorithms, trees, sorting algorithms (insertion, selection, quick, merge), binary search/BSTs, arithmetic series, geometric series, harmonic series (<span class="math">\(\frac 1 1 + \ldots + \frac 1 n = \ln n\)</span>).</p>
<p>In this course, <span class="math">\(\log n\)</span> is implicitly <span class="math">\(\log_2 n\)</span> - all logarithms are base 2 unless otherwise stated.</p>
<p>A <strong>problem</strong> is a description of a general situation and the desired outcome. For example, the sorting problem is &quot;given comparable values, put them in sorted order&quot;.</p>
<p>A <strong>problem instance</strong> is a particular input to a problem, like a particular array of numbers to sort for the sorting problem.</p>
<p>A <strong>problem solution</strong> is a change/process that, given the situation of a problem instance, results in the desired outcome. For example, the sorted array of numbers for the sorting problem.</p>
<p>We <strong>solve</strong> a problem by giving the correct algorithm for it. A solution is <strong>correct</strong> if it finds a solution for every possible input that can be given.</p>
<p>An <strong>algorithm</strong> is a finite description of a process that gives an answer (a solution that is not necessarily correct) for all possible instances of a problem.</p>
<p><strong>Efficiency</strong> usually refers to an algorithm's runtime, and sometimes its memory usage. It may also refer to things specific to the problem domain, like the number of comparisons done.</p>
<p>To solve a problem:</p>
<ol style="list-style-type: decimal">
<li>Design an algorithm.</li>
<li>Write down the main idea of the algorithm in plain prose. For example, &quot;for increasing <span class="math">\(i\)</span>, make <span class="math">\(A[0 \ldots i]\)</span> sorted by inserting <span class="math">\(A[i]\)</span> into a sorted <span class="math">\(A[0 \ldots i - 1]\)</span>&quot; for the sorting problem.</li>
<li><p>Optionally, write pseudocode - code that might not be a real language, and is something like a mix between prose and code. This is a more precise way of specifying an algorithm. Any consistent, precise, and clearly understandable language will be accepted as pseudocode.</p>
<pre><code>Preconditions: an array `A[0 ... n - 1]`$.
Postconditions: `A` is sorted
for i in 1 ... n - 1:
  value = A[i]
  j = i - 1
  while j &gt;= 0 and A[j] &gt; key:
    A[j + 1] = A[j]
    j = j - 1
  A[j + 1] = value</code></pre></li>
<li>Argue/prove that it is correct.</li>
<li>We can use formal correctness proofs, but this is often excessive to convince someone an algorithm is correct. Instead, we can simply give lots of invariants and prove that the algorithm terminates.</li>
<li>For example, for the above, we would say that for the inner loop, &quot;<code>A[j + 1 ... i]</code> contains items that are bigger than <code>value</code>, and is in sorted order&quot; is an invariant.</li>
<li>It is very important to prove that it terminates, especially recursive algorithms. We simply use the standard methods specified in CS245, but we can usually just write that each call or iteration gets some smaller input, and there is some small input for which the algorithm terminates.</li>
<li>Analyze how good the algorithm is, in terms of efficiency and sometimes lower bounds.</li>
<li>For this we use time complexity/running-time analysis, memory usage analysis, and so on.</li>
<li>For example, the above code is known as Insertion Sort, which we already know to have a worst case time complexity of <span class="math">\(O(n^2)\)</span> and a best case time complexity of <span class="math">\(O(n)\)</span>.</li>
<li>Recall that formally, an algorithm being in <span class="math">\(O(f(n))\)</span> means that there exists a <span class="math">\(k &gt; 0\)</span> and <span class="math">\(m \ge 0\)</span> such that for all <span class="math">\(n &gt; m\)</span>, <span class="math">\(k \cdot f(n) &gt; T(n)\)</span> where <span class="math">\(T(n)\)</span> represents the number of constant time steps or amount of time that the algorithm needs to give an answer for an input of size <span class="math">\(n\)</span> - the running time function. This is written as <span class="math">\(T(n) \in O(f(n))\)</span>.</li>
<li><p>Repeat above steps until satisfactory algorithm is found.</p></li>
</ol>
<p>Only after this point would we implement/experiment the algorithm.</p>
<h1 id="section-1">8/1/15</h1>
<p>A <strong>timing function</strong> is a function <span class="math">\(S_p: \mathrm{Input} \to \mb{R}^+\)</span> where <span class="math">\(p\)</span> is the program we are running. For example, we can compare quicksort and mergesort by comparing <span class="math">\(S_{\text{mergesort}}(\tup{5, 6, 2, 3})\)</span> and <span class="math">\(S_{\text{quicksort}}(\tup{5, 6, 2, 3})\)</span>.</p>
<p>A timing function measures the amount of time a program takes for a given input.</p>
<p>Since computers are constantly changing and improving, comparing timing functions is not very meaningful since they will not stay consistent over differnt machines and over time as computers change. We want a machine-agnostic way to measure the amount of time a given program takes.</p>
<p>For example, Intel's core instruction set is RISC, with tons of extensions such as MMX, SSE, and FPU and GPU stuff. These add instructions such as <code>fsqrt</code> and similar. We assume that every instruction takes a finite, constant amount of time (interesting note).</p>
<p>We can instead measure the number of elementary operations, but it is difficult to define what an elementary operation actually is, and determining the exact number of elementary operations is a lot of work. For example, we might measure the number of clock cycles needed to run a program, but this would not make sense across things like RISC vs CISC machines. For example, if an architecture doesn't have a constant time division operation, we would probably need to implement one in software that would not have constant time.</p>
<p>In other words, we write our algorithms in pseudo-code, then count the number of primitive operations.</p>
<p>We now want to plot our timing function with respect to the size of the input <span class="math">\(\abs{\mathrm{Input}} \subseteq \mb{N}\)</span>. This allows us to figure out the behaviour of the function as the size of the input gets bigger. This is difficult since finding the timing function for arbitrary inputs is often difficult. Additionally, we don't necessarily care about the constants in the function output, just its behaviour on large inputs.</p>
<p>Usually we care about the worst case behaviour, to determine the worst possible behaviour in all cases. We may also be interested in the average case to see how things will perform in practice. Occasionally, we may also be interested in the best case - for example, in cryptography, we want to make sure the problem cannot be solved in less than some given amount of time.</p>
<p>The worst case behaviour is <span class="math">\(T_p(n) = \max \set{S_p(I) \middle| \abs{I} = n}\)</span>. The best case behaviour is <span class="math">\(T_p(n) = \max \set{S_p(I) \middle| \abs{I} = n}\)</span>. The average case behaviour is <span class="math">\(T_p(n) = \frac{\sum_{e \in  R} i}{\abs{R}}\)</span> where <span class="math">\(R = \set{S_p(I) \middle| \abs{I} = n}\)</span>. We can now plot these functions to get the time bounds on our program.</p>
<p>The big-O notation is used to make life easier for computer scientists trying to calculate timing functions and to make comparing functions much easier. Refer to the CS136 notes for background. The <span class="math">\(O\)</span> in <span class="math">\(O(f(x))\)</span> is actually a capital omicron, bu nowadays the O is more common.</p>
<p>Comparing Big O is analogous to ordering in <span class="math">\(\mb{R}\)</span>. Just like how <span class="math">\(x \le y\)</span>, we might write <span class="math">\(f(x) \in O(g(x))\)</span>. What we care about is the trends of the function, not the actual numbers.</p>
<p>Big-O gives an upper bound behaviour on a function (analogous to <span class="math">\(x \le y\)</span>). Big-<span class="math">\(\Omega\)</span> gives a lower bound (analogous to <span class="math">\(x \ge y\)</span>). Big-<span class="math">\(\Theta\)</span> us the exact bounds - when the Big-<span class="math">\(O\)</span> is the same as the Big-<span class="math">\(\Omega\)</span> (analogous to <span class="math">\(x = y\)</span>).</p>
<p>There is also Little-<span class="math">\(o\)</span>, which is a non-inclusive upper bound (analogous to x &lt; y), and Little-<span class="math">\(\omega\)</span>, which is a non-inclusive lower bound (analogous to <span class="math">\(x &gt; y\)</span>). For little-o, instead of <span class="math">\(\exists c &gt; 0, \exists n_0 &gt; 0, n &gt; n_0 \implies f(n) \le cg(x)\)</span>, we have <span class="math">\(\forall c &gt; 0, \exists n_0 &gt; 0, n &gt; n_0 \implies f(n) \le cg(x)\)</span>.</p>
<p>There are also incomparable functions, like one that goes up and down arbitrarily. As a result, functions can only be partially ordered.</p>
<h1 id="section-2">13/1/15</h1>
<p>Big-O does not care about the values of the functions - only about how it grow as input values get large.</p>
<p>Prove that <span class="math">\(2n^2 + 3n + 11 \in O(n^2)\)</span>:</p>
<blockquote>
<p>We want to prove that <span class="math">\(2n^2 + 3n + 11 \le cn^2\)</span> for all <span class="math">\(n &gt; n_0\)</span>.<br />Let <span class="math">\(n_0 = 10\)</span> and <span class="math">\(n \ge n_0\)</span>. Clearly <span class="math">\(2n^2 + 3n + 11 \le 2n^2 + 3n^2 + 11n^2\)</span> when <span class="math">\(n \ge 1\)</span> and <span class="math">\(2n^2 + 3n^2 + 11n^2 = 16n^2\)</span>.<br />Then 16 is a possible value for <span class="math">\(c\)</span> and <span class="math">\(2n^2 + 3n + 11 \in O(n^2)\)</span>.</p>
</blockquote>
<p><span class="math">\(O(n^2 + \log n)\)</span> is not correct since it is not fully simplified.</p>
<p>Common time complexities include <span class="math">\(\Theta(1)\)</span> (constant), <span class="math">\(\Theta(\log n)\)</span> (logarithmic), <span class="math">\(\Theta(n)\)</span> (linear), <span class="math">\(\Theta(n \log n)\)</span> (pseudo-linear), <span class="math">\(\Theta(n^2)\)</span> (quadratic), <span class="math">\(\Theta(n^3)\)</span> (cubic), <span class="math">\(\Theta(n^k)\)</span> (polynomial), <span class="math">\(\Theta(2^n)\)</span> (exponential). In the real world, everything above <span class="math">\(O(n \log n)\)</span> tends to be rather bad performance.</p>
<p>It is not always the case that an algorithm with better time complexity than another is always better in all circumstances. For example, despite insertion sort being <span class="math">\(O(n^2)\)</span> and merge sort being <span class="math">\(O(n \log n)\)</span>, we often use insertion sort when sorting smaller lists since it is faster in practice when the input is small. Many practical sorting algorithms therefore drop down into insertion sort when the input is small. This is also why most people use insertion sort when sorting things in real life - it is very fast for real-world inputs, which are usually small.</p>
<p>Let <span class="math">\(L = \lim_{n \to \infty} \frac{f(n)}{g(n)}\)</span>. If <span class="math">\(L = 0\)</span>, <span class="math">\(f(n) \in o(g(n))\)</span>. If <span class="math">\(0 &lt; L &lt; \infty\)</span>, <span class="math">\(f(n) \in \Theta(g(n))\)</span>. Otherwise, <span class="math">\(L = \infty\)</span> and <span class="math">\(f(n) \in \omega(g(n))\)</span>. This is a useful way to prove orders for functions that would otherwise be difficult to prove by first principles.</p>
<p>For example, if we want to prove that <span class="math">\(n^2 \log n \in o(n^3)\)</span>, we can do <span class="math">\(\lim_{n \to \infty} \frac{n^2 \log n}{n^3} = \lim_{n \to \infty} \frac{\log n}{n} \lH \lim_{n \to \infty} \frac{\frac 1 n}{1} = 0\)</span>, and use the fact that <span class="math">\(L = 0\)</span> to conclude that <span class="math">\(n^2 \log n \in o(n^3)\)</span>.</p>
<p>We can aso use this to prove that <span class="math">\((\log n)^a \in o(n^b)\)</span> for any <span class="math">\(a, b &gt; 0\)</span>.</p>
<p>Also, <span class="math">\(f(n) \in \Omega(g(n)) \iff g(n) \in \Omega(f(n))\)</span>, <span class="math">\(f(n) \in O(g(n)) \iff g(n) \in \Omega(f(n))\)</span>, <span class="math">\(f(n) \in o(g(n)) \iff g(n) \in \omega(f(n))\)</span>, <span class="math">\(f(n) \in \Theta(g(n)) \iff g(n) \in O(f(n)) \wedge g(n) \in \Omega(f(n))\)</span>, <span class="math">\(f(n) \in o(g(n)) \implies f(n) \in O(g(n))\)</span>, <span class="math">\(f(n) \in o(g(n)) \implies f(n) \notin \Omega(g(n))\)</span>, <span class="math">\(f(n) \in \omega(g(n)) \implies f(n) \in \Omega(g(n))\)</span>, and <span class="math">\(f(n) \in \omega(g(n)) \implies f(n) \notin O(g(n))\)</span>. We can use these to simplify order notation expressions.</p>
<p>Also, <span class="math">\(O(f(n) + g(n)) = O(\max(f(n), g(n))) = \max(O(f(n)), O(g(n)))\)</span>. Also, orders are transitive - <span class="math">\(f(n \in O(g(n))) \wedge g(n) \in O(h(n)) \implies f(n) \in O(h(n))\)</span>.</p>
<p>In our pseudocoe, we often use <span class="math">\(x \left 5\)</span> or <code>x := 5</code> to denote assignment, since <code>=</code> is ambiguous - it could potentially mean equality or assignment.</p>
<p>Math with orders works a lot like normal math: <span class="math">\(\Theta(1) \cdot (1 + \ldots + n) = \Theta(1) \cdot \frac{n^2 + n}{2} = \Theta(n^2 + n) = \Theta(n^2)\)</span>.</p>
<p><span class="math">\(\sum_{i = 1}^n i^k = \Theta(n^{k + 1})\)</span></p>
<h1 id="section-3">15/1/15</h1>
<p>A priority queue is a data structure that stores items with keys that represent the priorities that the values have. It has two operations - insertion with a given key and deletion of the item with the maximum priority.</p>
<p>There are a number of ways we could implement a priority queue - an unsorted dynamic array (amortized <span class="math">\(O(1)\)</span> insert, <span class="math">\(O(n)\)</span> deletion), a sorted dynamic array, and something known as a heap. We don't want to use sorted order, since that makes insertion slow. We also dont't want to use unsorted order, since that makes deletion slow.</p>
<p>A <strong>heap</strong> is a data structure that allows us to implement a priority queue in a very efficient way. The main idea is that we would like to know very easily what the maximum element is, so we make all the other elements follow from it.</p>
<p>The basic idea behind the heap is that it is a tree where each element keeps track of candidates that can replace them when they're deleted, as children. The maximum item would therefore be the root. When we insert, we simply insert</p>
<p>Most commonly, we use binary heaps, which is a binary tree. Recall that this is a data structure consisting of nodes and links between node, such that each node has 2 or fewer children, and 1 or fewer parents.</p>
<p>Formally, a <strong>binary max-heap</strong> is a binary tree that satisfies the structural property and the max-heap property. There are no rules about the order of children, unlike a binary search tree.</p>
<p>The <strong>structural property</strong> is that all levels except the lowest level must be completely filled. Each node must have two children, except the lowest level, where nodes can have fewer than two children but <strong>must fill up from the left</strong> - in the lowest level, the left sibling of a node must have 2 children before we can insert a child into it.</p>
<p>The <strong>max-heap property</strong> is that for any node <span class="math">\(x\)</span> in the heap, the key of <span class="math">\(x\)</span> is less than or equal to the key of the parent of <span class="math">\(x\)</span>. There is also a min-heap property where the key of <span class="math">\(x\)</span> is greater than or equal to the key of the parent of <span class="math">\(x\)</span>, used for min-heaps. In other words, the parent of any node in a heap must be bigger or equal to that node. As a result, the maximum node of a heap is always the root node.</p>
<p>Insertion into a heap is easy because we can simply do a standard tree insertion, with certain constraints to ensure it satisfies the structural property and the heap property. This operation is <span class="math">\(\Theta(\log n)\)</span> because the structural property ensures that the height of the tree is <span class="math">\(\Theta(\log n)\)</span>.</p>
<p>Also, the height of a binary heap is <span class="math">\(\log_2 n - \omega(\log n)\)</span>. The height of a tree is 1 less than the number of levels it has (1 less than the maximum depth). Levels start at 1 and increase with depth.</p>
<p>Proof:</p>
<blockquote>
<p>Let <span class="math">\(x\)</span> be a heap with <span class="math">\(n\)</span> nodes and height <span class="math">\(h\)</span>.<br />Clearly, any binary tree of height <span class="math">\(h\)</span> must have <span class="math">\(n \le 2^{h + 1} - 1\)</span>, since each level <span class="math">\(i\)</span> has less than or equal to <span class="math">\(2^{i - 1}\)</span> nodes, and the total is <span class="math">\(n \le \sum_{i = 1}^{h + 1} 2^{i - 1} \le \frac{2^{h + 1} - 1}{2 - 1}\)</span>.<br />Since <span class="math">\(n + 1 \le 2^{h + 1}\)</span>, <span class="math">\(h \ge \log(n + 1) - 1\)</span>.<br />Clearly, <span class="math">\(n \ge 2^h\)</span>, by the structural property, since the lowest level is always <span class="math">\(h + 1\)</span> so each level <span class="math">\(i\)</span> before it has exactly <span class="math">\(2^{i - 1}\)</span> nodes, and the total for all levels except the lowest is <span class="math">\(2^h - 1\)</span>. Since the lowest level has 1 or more nodes, the total is <span class="math">\(n \ge (2^h - 1) + 1\)</span>, or <span class="math">\(2^h\)</span>.</p>
</blockquote>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2014 Anthony Zhang.
</div>
<script type="text/javascript">
MathJax.Hub.Config({
  jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
</body>
</html>