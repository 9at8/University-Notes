ECE124
======

Digital circuits and systems.

    Instructor: Andrew Kennings
    Website: http://sifaka.uwaterloo.ca/~akenning/courses/ece124/

$$
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}_P)}
$$

# 5/1/15

The assignments and other course resources can be found on the course website. They will not be posted to LEARN.

Boolean Algebra
---------------

See the CS245 notes for description of Boolean algebra.

Binary functions are defined using a truth table, or a Boolean logic formula. An example of a binary function is $f = f(x, y)$. Problem with truth tables is that they're big, and hard to manipulate.

Boolean AND is represented with $x \cdot y$, $xy$, or $x \wedge y$. The schematic symbol for this operation is a rectangle with one side completely rounded into a semicircle with the output wire, and the other flat and with input wires.

Boolean OR is represented with $x + y$. The schematic symbol for this operation is a rectangle with one side completely rounded into a semicircle with the output wire, with the other side curved inward and has input wires leading into it.

Boolean NOT is represented with $\overline x$, $!x$, $x'$, or $\neg x$. The schematic symbol for this operation is a triangle with a circle on the pointed end, which has the output wire, and the input wire is on the other end.

There is also an order of operations for these operations. From highest precedence to lowest, the operators are NOT, AND, and OR.

# 7/1/15

Minterms/Maxterms
-----------------

A **minterm** is a particular Boolean expression for a particular input to an $n$-input function. The minterm is special because it is easy to construct algorithmically from a truth table.

The minterm $m_i$ of a truth table's row $i$ is the an OR expression with an operand for each function input where each operand is $x_i$ if $x_i = 1$ for that row and $\neg x_i$ if $x_i = 0$.

Given a truth table, we can construct an expression that is equivalent to the function it represents as follows:

1. Create an empty expression $m$.
2. For each row $x_0, \ldots, x_n, f$ in the truth table:
  1. Create an empty expression $m_i$.
  2. For all $1 \le i \le n$:
    1. If $x_i = 0$, let $m_i$ become $m_i \cdot \neg x_i$.
    2. If $x_i = 1$, let $m_i$ become $m_i \cdot x_i$.
  3. If and only if $f = 1$, let $m$ become $m \vee m_i$. Note that $m_i$ is true if and only if the inputs match those in the current row of the truth table.
3. Note that $m$ is true if and only if $f = 1$, since there is an $m_i$ term for all the rows in the truth table that are true, and none of them match any rows in the truth table that are not true.

Here, each $m_i$ is a minterm. $m$ is the sum of minterms/canonical sum of products, defined below.

The **canonical sum of products/sum of minterms** is when we OR all the minterms ($m_i$) that have $f = 1$ for their corresponding truth table rows, in order.

The **maxterms** of a function are the duals of the minterms - similar to the minterms, but with AND instead of OR, and $\neg x$ and $x$ where we used to have $x$ and $\neg x$.

The maxterm $M_i$ of a truth table's row $i$ is the an OR expression with an operand for each function input where each operand is $x_i$ if $x_i = 1$ for that row and $\neg x_i$ if $x_i = 0$.

The maxterm is true if and only if the inputs _do not match the inputs in the corresponding row in the truth table_. This is the opposite of a minterm being true if and only if the inputs do match the inputs.

The **canonical product of sums/product of maxterms** is when we AND all the maxterms that have $f = 0$ for their corresponding truth table rows, in order. In other words, it is an expression that ensures that the inputs do not match the first row resulting in 0, and do not match the second row resulting in 0, and so on.

The sum of minterms and product of maxterms are special because it is exactly equivalent to the original function. The term **canonical** means that they are unique - there is only one way to write it correctly.

Minterms determine when we need to turn the function on. Maxterms determine when we need to turn the function off.

A $n$-level expression is an expression that has a maximum tree depth of $n$. $xy + z$ is a 2-level expression, and when we draw the circuit, it has 2 levels of gates - the depth of the circuit tree. The level of a circuit is the length of the longest path from a circuit input to an output.

For example, if a 2-input function has the following truth table:

| x | y | f |
|:--|:--|:--|
| 0 | 0 | 1 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

The minterms are $\neg x \neg y$ and $x y$, and the maxterms are $x \neg y$ and $\neg x y$. As a result, we can write $f$ as $\neg x \neg y + x y$ (sum of minterms) or $(x + \neg y)(\neg x + y)$ (product of maxterms).

Our goal is to use the simplest possible circuits. We can choose whether to use the sum of minterms or product of maxterms, but we can also use Boolean algebra to further simplify any expression.

Boolean Algebra
---------------

Axioms of Boolean algebra:

1. Closure over operations: given $x, y \in \set{0, 1}$, $x \cdot y, x + y, \neg x \in \set{0, 1}$.
2. Operation identities: given $x \in \set{0, 1}$, $x + 0 = x$ and $x \cdot 1 = x$. $0$ is the OR identity and $1$ is the AND identity.
3. Commutativity: given $x, y \in \set{0, 1}$, $x + y = y + x$ and $x \cdot y = y \cdot x$.
4. Distributivity: $x + y \cdot z = (x + y) \cdot (x + z)$ (distributivity over OR) and $x \cdot (y + z) = x \cdot y + x \cdot z$.
5. Negation existance: given $x \in \set{0, 1}$, there must exist an element $\neg x$ such that $x + \neg x = 1$ and $x \cdot \neg x = 0$.
6. Unique elements: there must exist $x, y \in \set{0, 1}$ such that $x \ne y$.

We can now prove theorems using truth tables, or using axioms:

Additional theorems:

1. $x + x = x$ and $x \cdot x = x$
2. $x + 1 = 1$ and $x \cdot 0 = 0$
3. $\neg \neg x = x$ (double negation)
4. $x + (y + z) = (x + y) + z$ and $x \cdot (y \cdot z) = (x \cdot y) \cdot z$ (associativity)
5. $\neg (x + y) = \neg x \cdot \neg y$ and $\neg (x \cdot y) = \neg x + \neg y$ (De Morgan's Law)
6. $x + x \cdot y = x$ and $x \cdot (x + y) = x$ (adsorption)

# 9/1/15

Simplify $\overline{\overline{cd} + a} + a + cd + ab$:

> $$
\begin{align*}
\overline{\overline{cd} + a} + a + cd + ab &= \overline{\overline{c}}d\overline{a} + a + cd + ab = cd\overline{a} + a + cd + ab \\
&= cd(\overline{a} + 1) + a + ab = cd + a + ab = cd + a(1 + b) = cd + a
\end{align*}
$$  
> Note that this is still a **sum of products** (SOP), although it isn't necessarily unique. A product of sums (POS) is what we would get if we worked with maxterms. A sum of products is always a 2-level circuit.  

We can use Boolean algebra to convert the sum of minterms or product of maxterms into a simplified expression. This allows us to convert a truth table into a sinple Boolean expression.

We can also represent a sum of minterms like $m_{a_1} + \ldots + m_{a_n}$ using the shorthand notation $\sum(a_1, \ldots, a_n)$. For example, $f = m_3 + m_5 + m_6 + m_7$ can also be written as $\sum(3, 5, 6, 7)$.

Likewise, maxterms have a shorthand as well: $M_{a_1} + \ldots + M_{a_n}$ can be written as $\prod(a_1, \ldots, a_n)$.

Each logical operation has a physical cost when we build the circuit in real life. For us, each gate costs 1 unit, each gate input costs 1 unit, and the inverters at inputs are free. For example, $xy + yz$ has a 2-input OR, and two 2-input ANDs, so it has a cost of $(1 + 2) + 2 \cdot (1 + 2) = 9$.

To convert between a sum of products and a product of sums, invert it twice and apply De Morgan's laws. For example, let $f = \sum(1, 4, 7)$:

> Clearly, $f = m_1 + m_4 + m_7 = \overline{\overline{f}}$.  
> Clearly, $\overline{f} = m_0 + m_2 + m_3 + m_5 + m_6$, the minterms that are not part of the function.  
> So $f = \overline{m_0 + m_2 + m_3 + m_5 + m_6} = \overline{m_0}\overline{m_2}\overline{m_3}\overline{m_5}\overline{m_6}$, by De Morgan's laws.  
> Note that $\overline{m_i} = M_i$ - a maxterm is the negation of its corresponding minterm.  
> So $f = \overline{m_0}\overline{m_2}\overline{m_3}\overline{m_5}\overline{m_6} = M_0 M_2 M_3 M_5 M_6$, a product of sums, as required.  

# 12/1/15

Other Logic Gates
-----------------

The NAND gate is an AND gate with an inverted output, written $x \uparrow y$. The NOR gate is an OR gate with an inverted output, written $x \downarrow y$.

When we invert an input or an output, we can just put a hollow small bubble/circle inline with the wire, conventionally touching the gate.

Note that NAND and NOR are not associative, so two NAND/NOR gates chained together is different from a three-input NAND/NOR gate.

These gates are extremely useful for circuits built using technology such as CMOS. In CMOS, the cheapest construct is the NAND gate, so we tend to make other constructs in terms of NAND gates.

However, we generally want to work with normal gates like AND and OR, and convert it into NAND at the end. Since NAND and NOR are universal, any combinatorial circuit can be represented using just one of these gates.

To convert sums of products into NAND logic, simply negate the whole thing twice and apply De Morgan's law. For example, $f = a \overline b + \overline b + c = \overline{\overline f} = \overline{\overline{a \overline b} \overline{\overline a b} \overline c}$, and the final result is all NAND gates. This can also be done recursively on subexpressions. This also works for converting products of sums into NOR logic.

Alternatively, we can also just replace each individual gate with its NAND equivalent. For reference, $x + y = (x \uparrow x) \uparrow (y \uparrow y)$, $xy = (x \uparrow y) \uparrow (x \uparrow y)$, and $\overline x = x \uparrow x$.

This also works graphically. In a circuit schematic, simply insert two back-to-back inverters inline to wires, until it is possible to see NAND forms. By moving one of a pair of inserted inverters into the output for an AND gate, for example, we can replace the AND and NOT with a NAND gate.

Essentially, we first insert pairs of inverters until all gates have been converted into NAND, then remove any remaining back-to-back inverters (since they cancel each other out) and replace any remaining single inverters with their NAND forms.

# 13/1/15

Boolean XOR is represented with $x \oplus y$. The schematic symbol for this operation is an OR gate, but with the concave side having two lines.

Boolean XOR essentially is true if and only if there are an odd number of operands that are true. For two inputs this is useful as an inequality operator $\ne$.

$x \oplus y = \overline x y + x \overline y$. This pattern appears quite often in practical Boolean algebra, and so using XOR can often simplify formulas quite a bit. Plus, in technologies like CMOS, XOR can be implemented significantly cheaper than its long, SOP form, so we can save on cost too by using this.

Boolean NXOR (also known as XNOR) is simply XOR inverted. For two inputs this is useful as an equality operator $=$.

A **buffer** is a special identity gate, $f = x$, which has the same output as it does input. It has the same symbol as the inverter, but without the circle at the output.

This is useful for amplifying signals and supplying current when there are a lot of branches. Additionally, it can act as a diode (in 3-level logic) when placed in a real circuit. Plus, sometimes we use it for slowing down a signal slightly to improve timing synchronocity. Mathematically, it does not serve any purpose.

A tri-state buffer is similar, but has another input called Enable coming out of one side. When the Enable wire is high, the output is the same as the input. When enable is low, the output is disconnected from the input - the value of the output is not specified.

Tri-state buffers are useful if we want to connect multiple sources to the same destination. For example, in RAM we might have one per RAM cell, and selectively connect and disconnect the RAM cell such that only one cell is actually connected to the destination at a given time. This is important, since if we have two RAM cells connected at the same time, one with 0's and one with 1's, there would be a short circuit.

Karnaugh Maps
-------------

Karnaugh maps (K-maps) are a way of describing Boolean functions with around 5 or less inputs (for larger inputs, it becomes impractical, as the number of table cells grows with $2^n$).

K-maps are also useful because they can be used to minimise functions by graphically performing Boolean algebra.

Consider K-map for the function $f = \overline x \overline y + \overine x y + x y$:

| $y$\$x$ | 0 | 1 |
|:--------|:--|---|
| **0**   | 1 | 0 |
| **1**   | 1 | 1 |

Note that each normal box (rectangle) corresponds to a row in the truth table for the function, and each 1 in a normal box corresponds to a minterm.

Note that the bottom two are both 1. That means that the value of $x$ does not influence the bottom row, so we can draw a rectangle around the bottom two, which represents $y$.

Note that we can do the same for the leftmost row of two 1's, a rectangle around the two representing $\overline x$.

If we want to minimise a function, the goal of K-mapping is to find the smallest possible number of the largest possible rectangles that cover all the 1 boxes and do not cover any 0 boxes (floating boxes don't matter). In each step, we try to draw a rectangle that encloses as many 1's as possible without enclosing any 0's.

This implies that there may be multiple optimal minimal versions of the function, with the same cost. This is represented by multiple minimal rectangle possibilities in the table, or multiple factoring possibilities in the Boolean expression

All rectangles must have side lengths that are powers of 2.

Mathematically, when we draw a rectangle we are duplicating a term and then factoring an input out. The boxes we drew above corresponded to the operations $f = \overline x \overline y + \overline x y + xy = \overline x \overline y + \overline x y + xy + \overline x y = \overline x(\overline y + y) + y(x + \overline x) = \overline x + y$.

Basically, every rectangle duplicates and factors two terms, repeatedly for larger rectangles. This is the reason rectangles need to have dimensions that are powers of 2. Larger rectangles result in products with fewer factors. Fewer rectangles result in fewer products.

The above technique resulted in a sum of products. To get a product of sums, draw maximum rectangles that cover all 0's but no 1's. Rather than a product, each rectangle has a corresponding sum, made up of the inputs that actually matter in making the function 0. The minimized product of sums is simply the product of the sum associated with each rectangle.

Also, the sides are labelled using grey code, and the rectangles can wrap around the sides of the table.

# 14/1/15

When doing K-maps, we can read off the answer from the rectangles by looking at which variables did not change within the minterms in a given rectangle. If all the minterms in a rectangle have $x_1$ equal to 0, but all other variables may change, then the rectangle represents the term $\overline x_1$.

If we look at the table and see that no rectangles can be expanded, that means that in the Boolean expression, there is no more factoring or collapsing left to be done.

For K-maps of larger dimensions, we label the rows and columns using grey code - a binary counting system in which only one bit changes when incrementing or decrementing a value. The grey code is recursively defined. The 1-bit grey code is `grey_code(1) = [0, 1]`. The $n$-bit grey code is `grey_code[n] = map(grey_code[n - 1], lambda code: 0 .. code) + map(reversed(grey_code[n - 1]), lambda code: 1 .. code)`.

In other words, to get the next grey code, we prepend a 0 to every binary string in the current grey code, and prepend a 1 to the reversed version of the current grey code, then put these two together.

Every variable splits the output space of a function in half. Let $f(x_1, \ldots, x_n)$ be a Boolean function. Let $f_0$ represent $f(0, x_2, \ldots, x_n)$ and 

The 5-input K-map is 3-dimensional. ;wip: why?

As a result, it is difficult to visualize. Instead, what we can do is $f = \overline x f_0 + x f_1$, and then do a K-map for $f_0$ and $f_1$.