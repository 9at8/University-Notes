<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>CS245 | Anthony Zhang</title>
  <style type="text/css">
  body {
    font-family: "Segoe UI", Verdana, Arial, Helvetica, sans-serif;
    background: #fffefe;
    padding: 5em;
  }
  
  pre {
    margin-left: 2em;
  }
  
  code {
    border: solid 1px black;
    background: #665555;
    color: white;
    padding: 0.1em;
    border-radius: 0.3em;
    display: inline-block;
  }
  
  pre code {
    padding: 1em;
    border-radius: 0.5em;
  }
  
  h1 {
    font-size: 4em;
  }
  
  table {
    margin: 0 auto;
  }
  
  td, th {
    padding: 0.5em;
    border: 1px solid grey;
  }
  
  tr {
    padding:: 0;
  }
  
  blockquote {
    margin-left: 0;
    padding-left: 0.5em;
    border-left: solid 0.3em grey;
  }
  
  .figure {
    border: solid 0.1em grey;
    display: inline-block;
    padding: 1em;
    text-align: center;
  }
  
  .figure .caption {
    margin: 0;
    font-size: 80%;
  }
  
  a.button {
    display: inline-block;
    padding: 1em;
    font-family: monospace;
    color: black;
    text-decoration: none;
    border: 0.2em solid black;
    border-radius: 0.5em;
    background: white;
  }
  
  a.button:hover, a.button:focus, a.button:active {
    background: black;
    color: white;
  }
  </style>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
</head>
<body>
<a class="button" href="..">&#8666; Return to University Notes index</a>
<h1 id="cs-245">CS 245</h1>
<p>Logic and computation.</p>
<pre><code>Instructor: Daniela Maftuleac
Email: daniela.maftuleac@uwaterloo.ca
Office Hours: Tuesday 2-3pm, Wednesday 12-1pm Math Tutorial Center
Website: https://www.student.cs.uwaterloo.ca/~cs245/</code></pre>
<p><span class="math">\[
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l&#39;H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}^P)}
\]</span></p>
<p>Assignments are due at 1pm at the dropboxes on MC 4th floor, due on Thursdays, posted on Tuesdays, returned in tutorials. Remark requests must be done within a week after the marks are posted.</p>
<h2 id="logic">Logic</h2>
<p>Logic is the science of correct reasoning. It is concerned with determining whether things are true or false.</p>
<p>In <strong>symbolic logic</strong>, we use symbols to represent truth values and manipulate logical statements using certain logical rules.</p>
<p>This course deals with propositional logic, predicate logic, and program verification.</p>
<p>Prove that <span class="math">\(3 \mid (4^n + 5)\)</span> for all <span class="math">\(n \in \mb{N}\)</span>:</p>
<blockquote>
<p>Clearly, this is true for <span class="math">\(n = 0\)</span>, since <span class="math">\(3 \mid (1 + 5)\)</span>.<br />Assume for some <span class="math">\(k \ge 0\)</span> that <span class="math">\(3 \mid (4^k + 5)\)</span>.<br />So <span class="math">\(\exists p \in \mb{Z}, 3p = 4^k + 5\)</span> and <span class="math">\(4(3p) = 4(4^k + 5)\)</span>, so <span class="math">\(12p - 15 = 3(4p - 5) = 4^{k + 1} + 5\)</span>.<br />Let <span class="math">\(q = 4p - 5\)</span>. Since <span class="math">\(q \in \mb{Z}\)</span>, <span class="math">\(\exists q \in \mb{Z}, 3q = 4^{k + 1} + 5\)</span>.<br />So <span class="math">\(3 \mid 4^{k + 1} + 5\)</span>, and by induction, <span class="math">\(3 \mid 4^n + 5\)</span> for all <span class="math">\(n \in \mb{N}\)</span>.</p>
</blockquote>
<p>The idea is that with strong induction, we can use any of the previous cases to prove the inductive hypothesis.</p>
<h1 id="section">7/5/14</h1>
<h2 id="propositional-logic">Propositional Logic</h2>
<p>The language of propositions is propositional logic.</p>
<p>A proposition is a declarative statement that is either true or false. It may depend on the context, like how the proposition <span class="math">\(x \ge 5\)</span> depends on the contextual variable <span class="math">\(x\)</span>.</p>
<p>We always assume that for any proposition with its context (the situation the proposition applies in), either the proposition is true, or it is false, and it cannot be both. If a statement is false, then its negation is true.</p>
<p>Propositions must be declarative. They must make sense when we ask, &quot;is it true that PROPOSITION?&quot;. It must be assignable to either true or false.</p>
<p><strong>Simple/atomic propositions</strong> are the building blocks of <strong>compound propositions</strong>. For example, &quot;It is currently raining in Waterloo&quot; and &quot;It is currently 12 degrees Celsius in Waterloo&quot; are simple propositions, and &quot;It is either raining or 12 degrees in Waterloo&quot; is a compound proposition.</p>
<p>Atomic ropositions are the smallest possible statements that are still propositions. They cannot be divided into smaller propositions.</p>
<h3 id="expression-syntax">Expression Syntax</h3>
<p>The propositional language is known as <span class="math">\(\mathcal{L}_P\)</span> (Language of Propositions). This language contains <strong>atoms</strong>, which are lowercase Latin characters such as <span class="math">\(p\)</span>, <span class="math">\(q\)</span>, and <span class="math">\(r\)</span>, optionally with subscripts. These all belong to the set <span class="math">\(\operatorname{Atom}(\mathcal{L}_P)\)</span>, so <span class="math">\(p \in \operatorname{Atom}(\mathcal{L}_P)\)</span>.</p>
<p>There are also <strong>punctuation</strong> symbols, the round parentheses &quot;(&quot; and &quot;)&quot;, which change the precendence of subexpressions.</p>
<p>There are also <strong>connectives</strong>, which are <span class="math">\(\neg, \wedge, \vee, \rightarrow, \leftrightarrow\)</span>.</p>
<p>An <strong>expression</strong> is a finite sequence of symbols. The length of an expression is the number of symbols it contains. Expressions may not necessarily be valid, like <span class="math">\(( \vee \neg \vee (\)</span>.</p>
<p>The empty expression (containing no symbols) is denoted <span class="math">\(\emptyset\)</span>.</p>
<h3 id="expression-operations">Expression Operations</h3>
<p>Let <span class="math">\(U, V, W\)</span> be expressions. Then <span class="math">\(U\)</span> and <span class="math">\(V\)</span> are equal (<span class="math">\(U = V\)</span>) if and only if they contain the same sequence of symbols.</p>
<p>Then <span class="math">\(UV\)</span> is the concatenation of <span class="math">\(U\)</span> and <span class="math">\(V\)</span> - the expression containing the entire sequence in <span class="math">\(U\)</span>, followed by the entire sequence in <span class="math">\(V\)</span>.</p>
<p>If <span class="math">\(U = W_1 V W_2\)</span>, then <span class="math">\(V\)</span> is a <strong>segment</strong> of <span class="math">\(U\)</span> - it is a sequence of symbols that <span class="math">\(U\)</span> also contains. All sequences contain the empty expression.</p>
<p>If <span class="math">\(V\)</span> is a segment of <span class="math">\(U\)</span> and <span class="math">\(V \ne U\)</span>, then <span class="math">\(V\)</span> is a <strong>proper segment</strong> of <span class="math">\(U\)</span>.</p>
<p>If <span class="math">\(U = VW\)</span>, then <span class="math">\(V\)</span> is an <strong>initial segment</strong> and <span class="math">\(W\)</span> is a <strong>terminal segment</strong>.</p>
<h3 id="expression-validity">Expression Validity</h3>
<p>The binary (two-parameter) connectives are <span class="math">\(\wedge, \vee, \rightarrow, \leftrightarrow\)</span>. In the following, <span class="math">\(\odot\)</span> will represent any arbitrary one of these binary connectives. The only connective that is not binary is the unary <span class="math">\(\neg\)</span> connective.</p>
<p>The set of <strong>formulas</strong> is the set of all valid/well-formed expressions, and is denoted <span class="math">\(\formlp\)</span>. Given <span class="math">\(A, B \in \formlp\)</span>, we can define <span class="math">\(\formlp\)</span> as follows:</p>
<ul>
<li><span class="math">\(\operatorname{Atom}(\mathcal{L}_P) \subseteq \formlp\)</span> - all atoms are formulas.</li>
<li><span class="math">\(\neg A \in \formlp\)</span> - the negation of any formula is also a formula (the set of formulas are closed under negation).</li>
<li><span class="math">\(A \odot B \in \formlp\)</span> - binary connectives applied to two formulas are also formulas (the set of formulas is closed under all the binary connectives).</li>
</ul>
<p>Formulas are often represented using Roman capital letters.</p>
<p>Theorem 2.2.3 states the obvious consequences of the definition: all formulas of <span class="math">\(\mathcal{L}_P\)</span> are atoms, or of the form <span class="math">\(\neg A, A \wedge B, A \vee B, A \rightarrow B, A \leftrightarrow B\)</span>.</p>
<p>Let <span class="math">\(R(n)\)</span> be a property (true if the property holds for <span class="math">\(n\)</span>, false otherwise). Theorem 2.2.4 states that if <span class="math">\(\forall p \in \operatorname{Atom}(\mathcal{L}_P), R(p)\)</span> and <span class="math">\(\forall A \in \formlp, R(A) \implies R(\neg A)\)</span> and <span class="math">\(\forall A, B \in \formlp, R(A) \wedge R(B) \implies R(A \odot B)\)</span>, then <span class="math">\(\forall A \in \formlp, R(A)\)</span>.</p>
<p>In other words, if a property holds for all the forms of formulas, then it holds for all formulas.</p>
<p>The <strong>type</strong> of a formula is determined by its top-level operator. For example, <span class="math">\(\neg A\)</span> is a negation, <span class="math">\(A \wedge B\)</span> is conjunction, <span class="math">\(A \vee b\)</span> is a disjunction, <span class="math">\(A \rightarrow B\)</span> is an implication, <span class="math">\(A \leftrightarrow B\)</span> is an equivalence. According to theorem 2.3.3, all formulas must be one of these forms.</p>
<p>We want to be able to look at any expression and determine whether it is well formed. For example, <span class="math">\(\neg()\)</span> is not a well formed formula (WFF) because it is not obtainable through the rules that define an element in the set of formulas.</p>
<p>Is <span class="math">\((\neg a) \wedge (b \vee c)\)</span> well formed?</p>
<blockquote>
<p>We can first notice that this is of the form <span class="math">\(P \wedge Q\)</span>, where <span class="math">\(P = \neg a\)</span> and <span class="math">\(Q = b \vee c\)</span>. By the rules, we know that the whole thing is well formed if and only if <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> are both well formed.<br />Now we check if <span class="math">\(P\)</span> is well formed. Clearly, it is of the form <span class="math">\(\neg R\)</span>, where <span class="math">\(R = a\)</span>, and <span class="math">\(a\)</span> is an atom (which is, by definition, well formed), so by the rules, <span class="math">\(\neg a\)</span> is well formed.<br />Now we check if <span class="math">\(Q\)</span> is well formed. Clearly, it is of the form <span class="math">\(S \vee T\)</span>, where <span class="math">\(S = b\)</span> and <span class="math">\(T = c\)</span>. By the rules, <span class="math">\(Q\)</span> is well formed if and only if <span class="math">\(S\)</span> and <span class="math">\(T\)</span> are. Since they are atoms, they are both well formed by definition.<br />Since <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> are well formed, <span class="math">\(P \wedge Q\)</span> is well formed and so is <span class="math">\((\neg a) \wedge (b \vee c)\)</span>.</p>
</blockquote>
<h1 id="section-1">12/5/14</h1>
<h2 id="parse-trees">Parse Trees</h2>
<p>The other way of testing for well-formedness is by constructing a parse tree out of the symbols in the formula. The top-level operator or atom is the root node of the tree, and the operands are its children. This is repeated until all the symbols have been added to the tree. Parentheses simply change the arrangement of the nodes and are not included in the parse tree.</p>
<p>For example, the expression <span class="math">\((((\neg p) \wedge q) \rightarrow (p \wedge (q \vee (\neg r))))\)</span> has the following parse tree:</p>
<pre><code>      \implies
       /   \
      /     \
  \wedge   \wedge
   /  \     /  \
\neg   q   p  \vee
  |           /  \
  p          q  \neg
                  |
                  r</code></pre>
<p>Every parse tree is unique. The rules for a valid formula can be applied to a parse tree to test for well-formedness:</p>
<ul>
<li>Tree nodes must be either atoms or connectives.</li>
<li>If a node is an atom, it cannot have any children - if a node has children, it must be a connective.</li>
<li>If a node is the unary connective (<span class="math">\(\neg\)</span>), then it must have exactly one child.</li>
<li>If the node is a binary connective, then it must have exactly two children.</li>
<li>If a tree is empty, then it is not a well formed formula.</li>
</ul>
<p>An algorithm for testing if an expression <span class="math">\(U\)</span> is a well formed formula is given below</p>
<ol style="list-style-type: decimal">
<li>If <span class="math">\(U\)</span> is empty, produce False.</li>
<li>If <span class="math">\(U \in \operatorname{Atom}(\mathcal{L}_P)\)</span>, then produce True.</li>
<li>If the expression does not begin with a <span class="math">\((\)</span> symbol, produce False.</li>
<li>If the second symbol is <span class="math">\(\neg\)</span>, then let <span class="math">\(V\)</span> be an expression such that <span class="math">\(U = (\neg V)\)</span>. Apply this algorithm again with <span class="math">\(V\)</span> as the expression, and if it is false, produce False.</li>
<li>Otherwise (the second symbol is not <span class="math">\(\neg\)</span>), apply this algorithm again with all the symbols starting from and including the second symbol, except doing nothing in step 7. If it results in False, return False. Otherwise, let <span class="math">\(V\)</span> be the well formed formula from the second symbol to wherever the algorithm run ended. If the next symbol after this is not a binary connective, produce False. Do the formula thing again to get a well formed formula <span class="math">\(W\)</span>, or produce False.</li>
<li>If the symbol after the place <span class="math">\(W\)</span> ended is not a <span class="math">\()\)</span> symbol, produce False.</li>
<li>If the expression does not end after the <span class="math">\()\)</span> symbol, produce False.</li>
<li>Produce True.</li>
</ol>
<p>This algorithm gets applied a finite number of times, proportional to the depth of the tree.</p>
<p>The <strong>height</strong> of a parse tree is the length of the longest path from the root to a leaf.</p>
<h3 id="precedence">Precedence</h3>
<p>We now introduce a system of precedence. The logical connectives listed by priority, from highest to lowest, are <span class="math">\(\neg\)</span>, <span class="math">\(\wedge\)</span>, <span class="math">\(\vee\)</span>, <span class="math">\(\rightarrow\)</span>, and <span class="math">\(\leftrightarrow\)</span>.</p>
<p>Precedence is the idea that some connectives get higher priority than others. For example, <span class="math">\(p \vee q \wedge r\)</span> could potentially mean either <span class="math">\(((p \vee q) \wedge r)\)</span>, or <span class="math">\((p \vee (q \wedge r))\)</span>. But since <span class="math">\(\wedge\)</span> has a higher precedence than <span class="math">\(\vee\)</span>, we define <span class="math">\(p \vee q \wedge r\)</span> to mean <span class="math">\((p \vee (q \wedge r))\)</span>.</p>
<p>When there are multiple ambiguities, we start with the ones with highest precedence. For example, <span class="math">\(\neg p \wedge q \vee r\)</span> is resolved to <span class="math">\((neg p) \wedge q \vee r\)</span>, then <span class="math">\((((neg p) \wedge q) \vee r)\)</span>.</p>
<p>With this in place, we can now eliminate many of the superfluous parentheses to clean up our formulas.</p>
<p><strong>Course of values induction</strong> is a type of strong induction where the inductive hypothesis used to prove the inductive conclusion is the conjunction of all the previous cases.</p>
<p>In other words, we do course of values induction by proving a property holds for <span class="math">\(M(1)\)</span>, and then by proving that <span class="math">\(M(1) \wedge \ldots \wedge M(k) \implies M(k + 1)\)</span> for any <span class="math">\(k \ge 1\)</span>. By the principal of strong induction, <span class="math">\(M(n)\)</span> therefore holds for all <span class="math">\(n \ge 1\)</span>.</p>
<p>Sometimes we want to use induction on the height of the parse tree. This is often useful for proving things about propositional formulas, due to the recursive nature of formulas.</p>
<p>If a formula <span class="math">\(C\)</span> contains the segment <span class="math">\((\neg A)\)</span>, where <span class="math">\(A\)</span> is another formula, then <span class="math">\(A\)</span> is the <strong>scope</strong> of the <span class="math">\(\neg\)</span> within <span class="math">\(C\)</span>. The scope is the area where the <span class="math">\(\neg\)</span> applies.</p>
<p>For binary connectives, if <span class="math">\(C\)</span> contains <span class="math">\((A \odot B)\)</span> where <span class="math">\(\odot\)</span> is a binary connective, then <span class="math">\(A\)</span> and <span class="math">\(B\)</span> are the left and right scopes, respectively, of the binary connective within <span class="math">\(C\)</span>.</p>
<p>A scope is unique to the operator. Two operators cannot have the exact same scope, though the scopes themselves can be equal.</p>
<h1 id="section-2">14/5/14</h1>
<h2 id="semantics">Semantics</h2>
<p>The semantics of a language describe how we interpret should valid formulas in that language. Semantics assigns meanings to formulas.</p>
<p>Let <span class="math">\(A\)</span> and <span class="math">\(B\)</span> be formulas, representing the propositions <span class="math">\(\mathcal{A}\)</span> and <span class="math">\(\mathcal{B}\)</span>, respectively. Then <span class="math">\(\neg A\)</span> represents &quot;Not <span class="math">\(\mathcal{A}\)</span>&quot;, <span class="math">\(A \wedge B\)</span> represents &quot;<span class="math">\(\mathcal{A}\)</span> and <span class="math">\(\mathcal{B}\)</span>&quot;.</p>
<p>Semantics is formally given as functions that map each formula to a value in <span class="math">\(\set{0, 1}\)</span> (false and true). This function can be represented using a <strong>truth table</strong>.</p>
<p>The value of a formula <span class="math">\(A\)</span> given a truth valuation <span class="math">\(t\)</span> is represented <span class="math">\(A^t\)</span>, with <span class="math">\(A^t \in \set{0, 1}\)</span>. If we used conventional function notation, we might write <span class="math">\(t(A) \in \set{0, 1}\)</span>.</p>
<p><strong>Truth valuations</strong> are functions that are used to assign truth values to propositional variables. The domain is the set of propositional variables in a formula, and the range is <span class="math">\(\set{0, 1}\)</span>. If <span class="math">\(t\)</span> is a truth valuation, then <span class="math">\(A^t \in \set{0, 1}\)</span>, where <span class="math">\(A\)</span> is a propositional variable.</p>
<p>We can completely represent the truth valuation for a formula by listing out all possible values of the domain and the resulting value in the range. For <span class="math">\(n\)</span> variables, there are <span class="math">\(2^n\)</span> possible values.</p>
<p>We can define the truth valuation function <span class="math">\(t\)</span> in terms of formulas <span class="math">\(A\)</span> and <span class="math">\(B\)</span> recursively:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \in \operatorname{Atom}(\mathcal{L}_P) \implies A^t \in \set{0, 1}\)</span>.</li>
<li><span class="math">\((\neg A) = \begin{cases} 1 &amp;\text{if } A^t = 0 \\ 0 &amp;\text{otherwise} \end{cases}\)</span>.</li>
<li><span class="math">\((A \wedge B) = \begin{cases} 1 &amp;\text{if } A^t = B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}\)</span>.</li>
<li><span class="math">\((A \vee B) = \begin{cases} 1 &amp;\text{if } A^t = 1 \text{ or } B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}\)</span>.</li>
<li><span class="math">\((A \rightarrow B) = \begin{cases} 1 &amp;\text{if } A^t = 0 \text{ or } B^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}\)</span>.</li>
<li><span class="math">\((A \leftrightarrow B) = \begin{cases} 1 &amp;\text{if } A^t = B^t \\ 0 &amp;\text{otherwise} \end{cases}\)</span>.</li>
</ol>
<p>Given a set of formulas <span class="math">\(\Sigma\)</span>, <span class="math">\(\Sigma^t = \begin{cases} 1 &amp;\text{if } \forall A \in \Sigma, A^t = 1 \\ 0 &amp;\text{otherwise} \end{cases}\)</span>. In other words, a set of formulas is true in a given truth valuation if and only if all of the formulas in the set are true.</p>
<p><span class="math">\(\Sigma\)</span> is <strong>satisfiable</strong> if and only if there exists a truth valuation <span class="math">\(t\)</span> such that <span class="math">\(\Sigma^t = 1\)</span>. It this <span class="math">\(t\)</span> exists, then <span class="math">\(t\)</span> <strong>satisfies</strong> <span class="math">\(\Sigma\)</span>. Therefore, <span class="math">\(\emptyset\)</span> satisfiable by any truth valuation.</p>
<p>A truth valuation can also be called a <strong>model</strong>.</p>
<p>A <strong>tautology</strong> is a formula which is always true, so for any truth valuation <span class="math">\(t\)</span>, <span class="math">\(A^t = 1\)</span>.</p>
<p>A <strong>contradiction</strong> is a formula which is always false, so for any truth valuation <span class="math">\(t\)</span>, <span class="math">\(A^t = 0\)</span>.</p>
<p>A <strong>semantically consistent</strong> formula is one that is not a contradiction, so there exists a truth valuation <span class="math">\(t\)</span> such that <span class="math">\(A^t = 1\)</span>.</p>
<p>Satisfiability is a property of a set of formulas where there exists a truth valuation that makes every formula in the set true.</p>
<p>The negation of a tautology is always a contradiction, and only the negation of a tautology is a contradiction. Likewise, the negation of a contradiction is a tautology, and only the negation of a contradiction is a tautology.</p>
<p>Rather than writing out the entire truth table, we can simplify formulas using the following identities:</p>
<ul>
<li><span class="math">\(\neg 0 = 1, \neg 1 = 0\)</span></li>
<li><span class="math">\(A \wedge 1 = 1 \wedge A = A\)</span></li>
<li><span class="math">\(A \wedge 0 = 0 \wedge A = 0\)</span></li>
<li><span class="math">\(A \vee 1 = 1 \vee A = 1\)</span></li>
<li><span class="math">\(A \vee 0 = 0 \vee A = A\)</span></li>
<li><span class="math">\(A \rightarrow 1 = 1\)</span></li>
<li><span class="math">\(0 \rightarrow A = 1\)</span></li>
<li><span class="math">\(1 \rightarrow A = A\)</span></li>
<li><span class="math">\(A \rightarrow 0 = \neg A\)</span></li>
</ul>
<p>Show that <span class="math">\(A = ((p \wedge q \rightarrow r) \wedge (p \rightarrow q)) \rightarrow (p \rightarrow r)\)</span> is a tautology:</p>
<blockquote>
<p>Assume <span class="math">\(p^t = 0\)</span>. Then <span class="math">\(A^t = (1 \rightarrow (p \rightarrow r))^t = 1\)</span>.<br />Assume <span class="math">\(p^t = 1\)</span>. Then <span class="math">\(A^t = (((q \rightarrow r) \wedge q) \rightarrow r)^t\)</span>.<br />Assume <span class="math">\(q^t = 0\)</span>. Then <span class="math">\(A^t = 1\)</span>. Assume <span class="math">\(q^t = 1\)</span>. Then <span class="math">\(A^t = (r \rightarrow r)^t = 1\)</span>.<br />So <span class="math">\(A\)</span> is a tautology.</p>
</blockquote>
<p>Let <span class="math">\(\mathcal{A}\)</span> and <span class="math">\(\mathcal{A}_1, \ldots, \mathcal{A}_n\)</span> be propositions.</p>
<p>Deductive logic studies whether <span class="math">\(\mathcal{A}\)</span> can be deduced from <span class="math">\(\mathcal{A}_1, \ldots, \mathcal{A}_n\)</span>.</p>
<p>Let <span class="math">\(\Sigma \subseteq \formlp, A \in \formlp\)</span>.</p>
<p><span class="math">\(A\)</span> is a <strong>tautological consequence/semantic entailment</strong> of <span class="math">\(\Sigma\)</span> (written <span class="math">\(\Sigma \models A\)</span>) if and only if for all truth valuation <span class="math">\(t\)</span>, <span class="math">\(\Sigma^t = 1 \implies A^t = 1\)</span>. Also, <span class="math">\(\neg (\Sigma \models A) = \Sigma \not\models A\)</span>. We can also write out the elements of <span class="math">\(\Sigma\)</span> directly, like <span class="math">\(P_1, \ldots, P_n \models A\)</span>, which is the same as <span class="math">\(\set{P_1, \ldots, P_n} \models A\)</span>.</p>
<p>In other words, if <span class="math">\(\Sigma \models A\)</span>, then the truth of <span class="math">\(\Sigma\)</span> implies the truth of <span class="math">\(A\)</span>.</p>
<p>As a result, if <span class="math">\(\emptyset \models A\)</span>, then <span class="math">\(A\)</span> is a tautology. This is because <span class="math">\(\emptyset^t = 1\)</span> for any truth valuation <span class="math">\(t\)</span>, so <span class="math">\(A^t = 1\)</span> as well.</p>
<p>As a result of our semantic definitions of our operations, conjunction and disjunction is commutative and associative. So <span class="math">\(A \wedge B = B \wedge A, A \vee B = B \vee A, (A \wedge B) \wedge C = A \wedge (B \wedge C), (A \vee B) \vee C = A \vee (B \vee C)\)</span>.</p>
<p>Also, <span class="math">\(A_1, \ldots, A_n \models A \iff \emptyset \models A_1 \wedge \ldots \wedge A_n \rightarrow A \iff \emptyset \models A_1 \implies (A_2 \implies (\ldots (A_n \implies A) \ldots))\)</span>.</p>
<h1 id="section-3">21/5/14</h1>
<p>Note that <span class="math">\(\Sigma \implies A\)</span> is not a formula, because it cannot be created using the formula rules. It is an operator that accepts formulas as both operands.</p>
<p>It is true that <span class="math">\(\Sigma \not\models A\)</span> if there exists a truth valuation <span class="math">\(t\)</span> such that <span class="math">\(\Sigma^t = 1\)</span> and <span class="math">\(A^t = 0\)</span>.</p>
<p>If <span class="math">\(A \models B\)</span> and <span class="math">\(B \models A\)</span>, then <span class="math">\(A \equiv B\)</span>. Also, if <span class="math">\(A \equiv B\)</span> and <span class="math">\(C \equiv D\)</span>, then <span class="math">\(\neg A \equiv \neg B\)</span> and <span class="math">\(A \odot C \equiv B \odot D\)</span> where <span class="math">\(\odot\)</span> is a binary connective.</p>
<p>Also, we define <span class="math">\(\emptyset^t = 1\)</span> for any truth valuation <span class="math">\(t\)</span>.</p>
<p>If <span class="math">\(B \equiv C\)</span>, then <span class="math">\(A \equiv A&#39;\)</span> where <span class="math">\(A&#39;\)</span> is <span class="math">\(A\)</span> with any number of occurrences of <span class="math">\(B\)</span> replaced by <span class="math">\(C\)</span>. This is known as <strong>replaceability</strong>.</p>
<p>The <strong>dual</strong> of <span class="math">\(A\)</span>, which is a formula that uses only the connectives <span class="math">\(\neg, \wedge, \vee\)</span> is <span class="math">\(A&#39;\)</span>, which is <span class="math">\(A\)</span> with every <span class="math">\(\wedge\)</span> replaced by <span class="math">\(\vee\)</span>, every <span class="math">\(\vee\)</span> with <span class="math">\(\wedge\)</span>, and every atom <span class="math">\(A\)</span> with <span class="math">\(\neg A\)</span>. It is always true that <span class="math">\(A = \neg A&#39;\)</span>. This is basically application of De Morgan's laws to formulas.</p>
<p>We know that <span class="math">\(A \rightarrow B \equiv \neg A \vee B\)</span>. Because of this, <span class="math">\(\rightarrow\)</span> is <strong>definable</strong> in terms of <span class="math">\(\neg, \vee\)</span>, or <strong>reducible to</strong> <span class="math">\(\neg, \vee\)</span>.</p>
<p><span class="math">\(\neg\)</span> is a unary connective - it accepts one operand. <span class="math">\(\vee\)</span> is a binary connective - it accepts two operands. It is also possible to have ternary connectives and even connectives of arity 4 and above (arity is the number of operands).</p>
<p>Let <span class="math">\(f\)</span> be an <span class="math">\(n\)</span>-ary connective - a connective accepting <span class="math">\(n\)</span> operands. Then <span class="math">\(f A_1 \ldots A_n\)</span> is a formula where <span class="math">\(A_1, \ldots, A_n\)</span> are connected by the connective <span class="math">\(f\)</span>.</p>
<p>An <span class="math">\(n\)</span>-ary connective has <span class="math">\(2^n\)</span> possible input cases to consider. For <span class="math">\(k\)</span> possible inputs, there are <span class="math">\(2^k\)</span> possible output cases. So there are <span class="math">\(2^{2^n}\)</span> possible <span class="math">\(n\)</span>-ary connectives.</p>
<p>A set of connectives is <strong>adequate</strong> if and only if any <span class="math">\(n\)</span>-ary connective can be defined in terms of these connectives.</p>
<p>For example, <span class="math">\(\set{\wedge, \vee, \neg}\)</span> is an adequate set because the truth table for any <span class="math">\(n\)</span>-ary operator can be represented by a formula using just these connectives. This can be proven:</p>
<blockquote>
<p>Let <span class="math">\(f\)</span> be an <span class="math">\(n\)</span>-ary connective. Clearly, there are <span class="math">\(2^n\)</span> possible truth valuations <span class="math">\(t_1, \ldots, t_{2^n}\)</span> for <span class="math">\(A_1, \ldots, A_n\)</span>. Let <span class="math">\(t\)</span> be one of these truth valuations.<br />Let <span class="math">\(T(t) = T_1(t) \wedge \ldots \wedge T_n\)</span>(t) where <span class="math">\(T_i(t) = \begin{cases} A_i &amp;\text{if } A_i^t = 1 \\ \neg A_i &amp;\text{if } A_i^t = 0 \end{cases}\)</span>. For example, if <span class="math">\(A_1^t = 1, A_2^t = 0, A_3^t = 1\)</span>, then <span class="math">\(T = A_1 (\neg A_2) A_3\)</span>.<br />Clearly, <span class="math">\(T(t_i)^{t_j}\)</span> is true if and only if <span class="math">\(t_i = t_j\)</span>. In other words, <span class="math">\(T(t)\)</span> results in a formula that is true in only the truth valuation <span class="math">\(t\)</span> and no others. Let <span class="math">\(V = T(t_1) \vee \ldots \vee T(t_{2^n})\)</span>, where there is a <span class="math">\(T(i)\)</span> term if and only if <span class="math">\((f A_1, \ldots, A_n)^t = 1\)</span>.<br />Clearly, this is a formula that is true when <span class="math">\(f A_1, \ldots, A_n\)</span> is true, and false otherwise. Therefore, <span class="math">\(f A_1, \ldots, A_n = V\)</span>.<br />So any <span class="math">\(f\)</span> can be defined in terms of <span class="math">\(\set{\wedge, \vee, \neg}\)</span>, which makes it adequate.</p>
</blockquote>
<p>We usually prove sets are adequate by defining the connectives in a set that is already known to be adequate in terms of the connectives of this set. If a connective <span class="math">\(f\)</span> is definable in terms of a set of connectives <span class="math">\(A\)</span>, and every connective in that set is definable in terms of another set <span class="math">\(B\)</span>, then <span class="math">\(f\)</span> is definable in terms of <span class="math">\(B\)</span>.</p>
<p>This is because we could define <span class="math">\(f\)</span> first in terms of <span class="math">\(A\)</span>, and then define that in terms of <span class="math">\(B\)</span>.</p>
<p>For example, <span class="math">\(\set{\wedge, \neg}\)</span> is adequate because <span class="math">\(\wedge\)</span> and <span class="math">\(\neg\)</span> are already in the set, and <span class="math">\(A \vee B \equiv \neg((\neg A) \wedge (\neg B))\)</span>, so <span class="math">\(\vee\)</span> is definable in terms of <span class="math">\(\set{\wedge, \neg}\)</span>.</p>
<h1 id="section-4">26/5/14</h1>
<p>The Schroder connective is defined as <span class="math">\(A \downarrow B\)</span> where <span class="math">\(A \downarrow B \equiv \neg (A \wedge B)\)</span> - the NOR operation.</p>
<p><span class="math">\(\set{\neg, \rightarrow}\)</span> is an adequate set.</p>
<h2 id="proof-calculus">Proof Calculus</h2>
<p>We want a calculus for reasoning about propositional logic. This will allow us to simplify proofs of validity.</p>
<p>In this course we will be looking at the Hilbert and natural deduction systems for formal proof calculus.</p>
<p>Let <span class="math">\(\Sigma = \set{\alpha_1, \ldots, \alpha_n}\)</span>. This is a set of premises.</p>
<p><span class="math">\(\Sigma \models d\)</span> is the same as <span class="math">\(\forall t, \Sigma^t = 1 \implies d^t = 1\)</span>.</p>
<p><span class="math">\(\Sigma \vdash \alpha\)</span> means that <span class="math">\(\alpha\)</span> is provable or deducible from <span class="math">\(\Sigma\)</span>.</p>
<h2 id="hilbert-system">Hilbert System</h2>
<p>The <strong>Hilbert System</strong> is a deductive system over the set of propositional logic formulas.</p>
<p><span class="math">\(\Sigma \vdash_H \alpha\)</span> means that <span class="math">\(\alpha\)</span> is provable or deducible in the Hilbert system. <span class="math">\(\vdash_H A\)</span> means <span class="math">\(\emptyset \vdash_H A\)</span>.</p>
<p><span class="math">\(\Sigma\)</span> is a set of formulas known as premises, and from them we can deduce <span class="math">\(\delta\)</span> using axioms and inference rules.</p>
<p>Axioms are basically just tautologies. In this course we will only be using axioms over <span class="math">\(\set{\neg, \rightarrow}\)</span> since this set is small and results in fewer axioms:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(\phi \rightarrow (\psi \rightarrow \phi)\)</span> - basically, this is just a special case of</li>
<li><span class="math">\((\phi \rightarrow (\psi \rightarrow \xi)) \rightarrow ((\phi \rightarrow \psi) \rightarrow (\phi \rightarrow \xi))\)</span> - basically, <span class="math">\(\rightarrow\)</span> is distributive</li>
<li><span class="math">\((\neg \phi \rightarrow \neg \psi) \rightarrow (\psi \rightarrow \phi)\)</span> - basically, the contrapositive of a formula implies the formula</li>
</ol>
<p>Here, <span class="math">\(\phi, \psi, \xi\)</span> are any formulas.</p>
<p><strong>Inference rules</strong> are manipulations we can perform on formulas to obtain new formulas. In this system we have only Modus Ponens (MP): <span class="math">\(\set{\phi, \phi \rightarrow \psi} \rightarrow_H \psi\)</span>.</p>
<p>A <strong>proof</strong> is a set of formulas that includes axioms, premises, and conclusions. We start with the axioms that we know are true, so we use inference rules over the axioms and previously obtained formulas, listing out each new formula obtained, until we get the desired result.</p>
<p>For example, prove that <span class="math">\(\vdash_H A \rightarrow A\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow ((A \rightarrow A) \rightarrow A)\)</span> (Axiom 1 where <span class="math">\(\psi = A \rightarrow A\)</span>)</li>
<li><span class="math">\((A \rightarrow ((A \rightarrow A) \rightarrow A)) \rightarrow ((A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A))\)</span> (Axiom 2 where <span class="math">\(\psi = A \rightarrow A\)</span>)</li>
<li><span class="math">\((A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A)\)</span> (Modus Ponens on 1 and 2)</li>
<li><span class="math">\(A \rightarrow A\)</span> (Modus Ponens on 1 and 3)</li>
</ol>
<p>Prove that <span class="math">\(\set{A \rightarrow B, B \rightarrow C} \vdash_H A \rightarrow C\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow B\)</span> (Premise 1)</li>
<li><span class="math">\(B \rightarrow C\)</span> (Premise 2)</li>
<li><span class="math">\(((B \rightarrow C) \rightarrow (A \rightarrow (B \rightarrow C)))\)</span> (Axiom 1 where <span class="math">\(\phi = B \rightarrow C\)</span>)</li>
<li><span class="math">\(A \rightarrow (B \rightarrow C)\)</span> (Modus Ponens on 1 and 3)</li>
<li><span class="math">\((A \rightarrow (B \rightarrow C)) \rightarrow ((A \rightarrow B) \rightarrow (A \rightarrow C))\)</span> (Axiom 2)</li>
<li><span class="math">\((A \rightarrow B) \rightarrow (A \rightarrow C)\)</span> (Modus Ponens on 4 and 5)</li>
<li><span class="math">\(A \rightarrow C\)</span> (Modus Ponens on 1 and 6)</li>
</ol>
<p>The <strong>deduction theorem</strong> says that <span class="math">\(\Sigma \vdash_H A \rightarrow B\)</span> if and only if <span class="math">\(\Sigma \cup A \vdash_H B\)</span>. So <span class="math">\(\set{\alpha_1, \ldots, \alpha_n} \vdash_H \alpha\)</span> is the same as <span class="math">\(\emptyset \vdash_H (\alpha_1 \rightarrow (\ldots (alpha_n \rightarrow \alpha) \ldots))\)</span>.</p>
<p>In other words, to prove an implication, we just have to assume the antecedent and use it to prove the consequent.</p>
<h1 id="section-5">28/5/14</h1>
<p>Prove that <span class="math">\(\neg \neg A \vdash_H A\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(\neg \neg A\)</span> (Premise 1)</li>
<li><span class="math">\(\neg \neg A \rightarrow (\neg \neg \neg \neg A \rightarrow \neg \neg A)\)</span> (Axiom 1 where <span class="math">\(\psi = \neg \neg \neg \neg A\)</span>)</li>
<li><span class="math">\(\neg \neg \neg \neg A \rightarrow \neg \neg A\)</span> (Modus Ponens on 1 and 2)</li>
<li><span class="math">\((\neg (\neg \neg \neg A) \rightarrow \neg A) \rightarrow (\neg A \rightarrow \phi)\)</span> (Axiom 3 where <span class="math">\(\phi = \neg \neg \neg A\)</span>)</li>
<li><span class="math">\(\neg A \rightarrow \neg \neg \neg A\)</span> (Modus Ponens on 3 and 4)</li>
<li><span class="math">\((\neg A \rightarrow \neg \neg \neg A) \rightarrow (\neg \neg A \rightarrow A)\)</span> (Axiom 3 where <span class="math">\(\psi = \neg \neg A\)</span>)</li>
<li><span class="math">\(\neg \neg A \rightarrow A\)</span> (Modus Ponens on 5 and 6)</li>
<li><span class="math">\(A\)</span> (Modus Ponens on 1 and 7)</li>
</ol>
<p><span class="math">\(\Sigma \models \alpha\)</span> is a semantic construct. This is associated with soundness.</p>
<p><span class="math">\(\Sigma \vdash \alpha\)</span> is a syntactical construct. This is associated with completeness.</p>
<p>Formulas must be semantically entailed before it can be syntactically entailed. We need it to be semantically sound before proving it is complete.</p>
<p>Here are some rules of thumb to more easily construct proofs.</p>
<ul>
<li>Axiom 3 is often helpful in adding or remove negations, by putting the formula with the negation on one of the sides and the formula without on the other.</li>
<li>Axiom 1 is useful for getting the converse and setting up modus ponens to simplify.</li>
<li>Axiom 2 is just... just use it as a last resort.</li>
<li>General pattern is premise/axiom, modus ponens, premise/axiom, etc.</li>
<li>Remember the proofs for some more sane manipulation rules like <span class="math">\(\neg \neg A = A\)</span> and use those instead of these crazy axioms.</li>
</ul>
<h2 id="natural-deduction">Natural Deduction</h2>
<p>In natural deduction, we infer a <strong>conclusion</strong> from the <strong>premises</strong> using various <strong>proof rules</strong>.</p>
<p>Natural deduction was born out of people noticing that the Hilbert system is terribly complicated even for the simplest of proofs.</p>
<p>Let <span class="math">\(\Sigma = \set{\alpha_1, \ldots, \alpha_n}\)</span> be the set of all the premises.</p>
<p>For convenience, we define that <span class="math">\(\alpha_1, \ldots, \alpha_n\)</span> is equivalent to <span class="math">\(\set{\alpha_1, \ldots, \alpha_n}\)</span>.</p>
<p>We also define that <span class="math">\(\Sigma, \alpha\)</span> is equivalent to <span class="math">\(\Sigma \cup \set{\alpha}\)</span>, and given a set <span class="math">\(S\)</span>, then <span class="math">\(\Sigma, S\)</span> is equivalent to <span class="math">\(\Sigma, S\)</span>.</p>
<p><span class="math">\(\Sigma \vdash \alpha\)</span> is not a formula, but is a proposition.</p>
<blockquote>
<p>If the train arrives late and there are no taxis at the station, then John is late for his meeting.<br />John is not late for his meeting.<br />The train did arrive late.<br />Therefore, there were taxis at the station.</p>
</blockquote>
<p>The above can be written as follows:</p>
<blockquote>
<p>Let <span class="math">\(l\)</span> represent the train being late. Let <span class="math">\(m\)</span> represent being late to the meeting. Let <span class="math">\(t\)</span> represent there being taxis.<br />Then <span class="math">\(l \wedge \neg t \rightarrow m\)</span>, <span class="math">\(\neg m\)</span>, <span class="math">\(l\)</span>, so <span class="math">\(t\)</span>.</p>
</blockquote>
<p>The rules of deduction in ND are:</p>
<table>
<thead>
<tr class="header">
<th align="left">Name</th>
<th align="left">Symbol</th>
<th align="left">Rule</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Reflexivity</td>
<td align="left"><span class="math">\(\operatorname{Ref}\)</span></td>
<td align="left"><span class="math">\(A \vdash A\)</span></td>
<td align="left">Anything can be deduced from itself.</td>
</tr>
<tr class="even">
<td align="left">Addition of Premises</td>
<td align="left"><span class="math">\(+\)</span> with <span class="math">\(\Sigma_1 \vdash \alpha\)</span></td>
<td align="left"><span class="math">\(\Sigma_1 \vdash \alpha\)</span> implies <span class="math">\(\Sigma_1 \cup \Sigma_2 \vdash \alpha\)</span></td>
<td align="left">Premises can be freely added to valid arguments.</td>
</tr>
<tr class="odd">
<td align="left">Reflexive premises</td>
<td align="left"><span class="math">\(\epsilon\)</span></td>
<td align="left"><span class="math">\(\alpha \in \Sigma\)</span> implies <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left">Anything can be deduced if it is itself deducible.</td>
</tr>
<tr class="even">
<td align="left">Negation-introduction</td>
<td align="left"><span class="math">\(\neg+\)</span> with <span class="math">\(\Sigma, \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \alpha \vdash \neg \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma, \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \alpha \vdash \neg \psi\)</span> implies <span class="math">\(\Sigma \vdash \neg \alpha\)</span></td>
<td align="left">If <span class="math">\(\alpha\)</span> results in a contradiction, then <span class="math">\(\neg \alpha\)</span> must be true.</td>
</tr>
<tr class="odd">
<td align="left">Negation-elimination</td>
<td align="left"><span class="math">\(\neg-\)</span> with <span class="math">\(\Sigma, \neg \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \neg \alpha \vdash \neg \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma, \neg \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \neg \alpha \vdash \neg \psi\)</span> implies <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left">If <span class="math">\(\neg \alpha\)</span> results in a contradiction, then <span class="math">\(\alpha\)</span> must be true.</td>
</tr>
<tr class="even">
<td align="left">Conjunction-introduction</td>
<td align="left"><span class="math">\(\wedge+\)</span> with <span class="math">\(\Sigma \vdash \alpha\)</span> and <span class="math">\(\Sigma \vdash \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha\)</span> and <span class="math">\(\Sigma \vdash \psi\)</span> implies <span class="math">\(\Sigma \vdash \alpha \wedge \psi\)</span></td>
<td align="left">If something implies two things individually, then it implies both together.</td>
</tr>
<tr class="odd">
<td align="left">Conjunction-elimination</td>
<td align="left"><span class="math">\(\wedge-\)</span> with <span class="math">\(\Sigma \vdash \alpha \wedge \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha \wedge \psi\)</span> implies <span class="math">\(\Sigma \vdash \alpha\)</span> and <span class="math">\(\Sigma \vdash \psi\)</span></td>
<td align="left">If two things both follow from the premises, each one follows individually.</td>
</tr>
<tr class="even">
<td align="left">Implication-introduction</td>
<td align="left"><span class="math">\(\rightarrow+\)</span> with <span class="math">\(\Sigma, \alpha \vdash \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma, \alpha \vdash \psi\)</span> implies <span class="math">\(\Sigma \vdash \alpha \rightarrow \psi\)</span></td>
<td align="left">If <span class="math">\(\psi\)</span> can be deduced from <span class="math">\(\alpha\)</span>, then <span class="math">\(\alpha \rightarrow \psi\)</span>.</td>
</tr>
<tr class="odd">
<td align="left">Implication-elimination</td>
<td align="left"><span class="math">\(\rightarrow-\)</span> with <span class="math">\(\Sigma \vdash \alpha \rightarrow \psi\)</span> and <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha \rightarrow \psi\)</span> and <span class="math">\(\Sigma \vdash \alpha\)</span> implies <span class="math">\(\Sigma \vdash \psi\)</span></td>
<td align="left">If something implies something else and that thing is true, then so is the other.</td>
</tr>
<tr class="even">
<td align="left">Disjunction-introduction</td>
<td align="left"><span class="math">\(\vee+\)</span> with <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha\)</span> implies <span class="math">\(\Sigma \vdash \alpha \vee \psi\)</span> and <span class="math">\(\Sigma \vdash \psi \vee \alpha\)</span></td>
<td align="left">Something deducible implies that it or something else is deducible.</td>
</tr>
<tr class="odd">
<td align="left">Disjunction-elimination</td>
<td align="left"><span class="math">\(\vee-\)</span> with <span class="math">\(\Sigma, \alpha_1 \vdash \psi\)</span> and <span class="math">\(\Sigma, \alpha_2 \vdash \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma, \alpha_1 \vdash \psi\)</span> and <span class="math">\(\Sigma, \alpha_2 \vdash \psi\)</span> implies <span class="math">\(\Sigma, \alpha_1 \vee \alpha_2 \vdash \psi\)</span></td>
<td align="left">If two things individually imply another, then either implies it.</td>
</tr>
<tr class="even">
<td align="left">Double-implication-introduction</td>
<td align="left"><span class="math">\(\leftrightarrow+\)</span> with <span class="math">\(\Sigma, \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \psi \vdash \alpha\)</span></td>
<td align="left"><span class="math">\(\Sigma, \alpha \vdash \psi\)</span> and <span class="math">\(\Sigma, \psi \vdash \alpha\)</span> implies <span class="math">\(\Sigma \vdash \alpha \leftrightarrow \psi\)</span></td>
<td align="left">If one thing implies another and the other implies it, they are equivalent.</td>
</tr>
<tr class="odd">
<td align="left">Double-implication-elimination 1</td>
<td align="left"><span class="math">\(\leftrightarrow-\)</span> with <span class="math">\(\Sigma \vdash \alpha \leftrightarrow \alpha\)</span> and <span class="math">\(\Sigma \vdash \psi\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha \leftrightarrow \psi\)</span> and <span class="math">\(\Sigma \vdash \alpha\)</span> implies <span class="math">\(\Sigma \vdash \psi\)</span></td>
<td align="left">If two things are equivalent and the first is deducible, so is the second.</td>
</tr>
<tr class="even">
<td align="left">Double-implication-elimination 2</td>
<td align="left"><span class="math">\(\leftrightarrow-\)</span> with <span class="math">\(\Sigma \vdash \alpha \leftrightarrow \psi\)</span> and <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left"><span class="math">\(\Sigma \vdash \alpha \leftrightarrow \psi\)</span> and <span class="math">\(\Sigma \vdash \psi\)</span> implies <span class="math">\(\Sigma \vdash \alpha\)</span></td>
<td align="left">If two things are equivalent and the second is deducible, so is the first.</td>
</tr>
<tr class="odd">
<td align="left">Transitivity of deducibility</td>
<td align="left"><span class="math">\(\operatorname{Tr}\)</span> with <span class="math">\(\Sigma_1 \vdash \Sigma_2\)</span> and <span class="math">\(\Sigma_2 \vdash \Sigma_3\)</span></td>
<td align="left"><span class="math">\(\Sigma_1 \vdash \Sigma_2\)</span> and <span class="math">\(\Sigma_2 \vdash \Sigma_3\)</span> implies <span class="math">\(\Sigma_1 \vdash \Sigma_3\)</span></td>
<td align="left">If one thing implies a second, which implies a third, then the first implies the last.</td>
</tr>
</tbody>
</table>
<p>Prove the <span class="math">\(\epsilon\)</span> rule from the basic rules <span class="math">\(\operatorname{Ref}, +\)</span>:</p>
<blockquote>
<p>Let <span class="math">\(A = \Sigma \setminus \set{\alpha}\)</span>.<br />Clearly, <span class="math">\(\alpha \implies \alpha\)</span> by <span class="math">\(\operatorname{Ref}\)</span> (step 1).<br />So <span class="math">\(\set{\alpha} \cup A \vdash \alpha\)</span> by <span class="math">\(+\)</span> with step 1 (step 2).<br />Since <span class="math">\(\set{\alpha} \cup A = \Sigma\)</span>, <span class="math">\(\Sigma \vdash \alpha\)</span> (step 3, conclusion).</p>
</blockquote>
<p>Prove that <span class="math">\(\neg \neg p \vdash p\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(\neg \neg p, \neg p \vdash \neg \neg p\)</span> (<span class="math">\(\epsilon\)</span>).</li>
<li><span class="math">\(\neg \neg p, \neg p \vdash \neg p\)</span> (<span class="math">\(\epsilon\)</span>).</li>
<li><span class="math">\(\neg \neg p \vdash p\)</span> (<span class="math">\(\neg-\)</span>).</li>
</ol>
<p>Note that implication-introduction and implication-elimination is very similar to the deduction theorem.</p>
<p>Prove that <span class="math">\(A \rightarrow B, B \rightarrow C \vdash A \rightarrow C\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash A \rightarrow B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash B\)</span> (<span class="math">\(\rightarrow-\)</span> with step 1 and 2)</li>
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash B \rightarrow C\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash C\)</span> (<span class="math">\(\rightarrow-\)</span> with step 3 and 4)</li>
<li><span class="math">\(A \rightarrow B, B \rightarrow C \vdash A \rightarrow C\)</span> (<span class="math">\(\rightarrow+\)</span> with step 5)</li>
</ol>
<h1 id="section-6">2/6/14</h1>
<p>If a system is sound and complete, then arguments can be proved if and only if they are valid.</p>
<p>We can write <span class="math">\(A, B \vdash C\)</span> as <span class="math">\(\frac{A \qquad B}{C}\)</span>. This is known as <strong>inference notation</strong>.</p>
<h3 id="formal-proofs">Formal Proofs</h3>
<p>A <strong>formal proof</strong> for <span class="math">\(\Sigma_k \vdash \alpha_k\)</span> is simply a sequence of the natural deduction rules - <span class="math">\(\Sigma_1 \vdash \alpha_1, \ldots, \Sigma_k \vdash \alpha_k\)</span>. If this is the case, then <span class="math">\(\alpha_n\)</span> is <strong>formally deducible</strong> from <span class="math">\(\Sigma_n\)</span> - it can be proven from those premises.</p>
<p>Note that <span class="math">\(\Sigma \vdash \alpha\)</span> is very different from <span class="math">\(\Sigma \models \alpha\)</span> - the former deals purely with syntax, while the latter deals with semantics - what the symbols actually mean.</p>
<p>Negation-introduction (<span class="math">\(\neg+\)</span>) is also called <strong>contradiction</strong> or <strong>reductio ad absurdum</strong>. It is usually the rule we use when we want to prove by contradiction, and is very similar to negation-elimination (<span class="math">\(\neg-\)</span>).</p>
<p>Prove that <span class="math">\(p \vdash \neg \neg p\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(p, \neg p \vdash p\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(p, \neg p \vdash \neg p\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(p \vdash \neg \neg p\)</span> (reductio ad absurdum with step 1 and 2)</li>
</ol>
<p>In formal proofs, we usually start off by stating premises (also called assumptions), and then adding rules and modifying results until we arrive at the conclusion of the proof. The conclusion of the proof is the thing we are trying to prove.</p>
<p>The proof format we have been using so far is in something known as <strong>line/sequent/turnstile notation</strong>. The <span class="math">\(\vdash\)</span> symbol is a sequent or turnstile, with all premises before it and all conclusions after.</p>
<p>In <strong>box notation</strong>, we write assumptions, and then we draw a box that contains it, the box acts like a &quot;scope&quot; in which the assumptions hold and we can directly write the deduced thing. Inside the box we can directly write the resulting formulas without writing the <span class="math">\(\alpha_1, \ldots, \alpha_n \vdash\)</span> before it. Scopes can nest, and this saves a lot of rewriting of premises.</p>
<p>Alternatively, we might indent the values instead of drawing a box around them. For example, the previous proof that <span class="math">\(A \rightarrow B, B \rightarrow C \vdash A \rightarrow C\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow B, B \rightarrow C\)</span> (assumption)</li>
<li>The following is indented or drawn in a box:
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow B, B \rightarrow C, A\)</span> (assumption)</li>
<li><span class="math">\(A \rightarrow B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(B\)</span> (<span class="math">\(\rightarrow-\)</span> with step 2.2 and 2.3)</li>
<li><span class="math">\(B \rightarrow C\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(C\)</span> (<span class="math">\(\rightarrow-\)</span> with step 2.4 and 2.5)</li>
</ol></li>
<li><span class="math">\(A \rightarrow C\)</span> (<span class="math">\(\rightarrow+\)</span> with step 2.6):</li>
</ol>
<p>When we begin a box or indentation, we insert an assumption. When we close a box, we remove the assumption. This ability to insert and remove asumptions keeps our proofs clean and organized.</p>
<p>Boxes or indentations can nest, and have lexical scope - when we have a box inside a box, we can use any statements above it, even if it is in a parent box. Outside of a box, we cannot use any of the resulting formulas directly - they are always attached to their assumptions. For example, in the above example we could not state <span class="math">\(C\)</span> in step 3, but we could use <span class="math">\(A \rightarrow B, B \rightarrow C, A \vdash C\)</span> in the <span class="math">\(\rightarrow+\)</span> rule.</p>
<p>A box is often closed when we arrive at a conclusion using a rule such as <span class="math">\(\neg-\)</span>, <span class="math">\(\rightarrow+\)</span>, or <span class="math">\(\vee-\)</span>. Usages of <span class="math">\(\neg-\)</span> and <span class="math">\(\rightarrow+\)</span> are usually found right after a box closes. <span class="math">\(\vee-\)</span> is usually found after two boxes.</p>
<p>All boxes must be closed by the end of the argument. Otherwise, there are extra premises and the proof is not yet complete.</p>
<p>Elimination rules turn two statements into one. Introduction rules introduce new statements, or turn one statement into two.</p>
<h1 id="section-7">4/6/14</h1>
<h2 id="soundnesscompleteness">Soundness/Completeness</h2>
<p><strong>Soundness</strong> is a property of a deductive system where it is impossible to prove any invalid arguments.</p>
<p><strong>Completeness</strong> is a property of a deductive system where it is always possible to prove valid arguments.</p>
<p>The <strong>soundness theorem</strong> states that if something is provable, then it is valid - <span class="math">\(\Sigma \vdash \alpha\)</span> implies that <span class="math">\(\Sigma \models \alpha\)</span>.</p>
<p>In practice, we prove soundness by using the contrapositive: by proving that <span class="math">\(\Sigma \not\models \alpha\)</span> implies <span class="math">\(\Sigma \not\vdash \alpha\)</span>.</p>
<p>If <span class="math">\(A \vdash B\)</span> and <span class="math">\(B \vdash C\)</span>, then <span class="math">\(A \vdash C\)</span>.</p>
<p>In other words, if <span class="math">\(\Sigma&#39; = \set{A_1, \ldots, A_n}\)</span> and <span class="math">\(\Sigma \vdash A_1, \ldots, \Sigma \vdash A_n\)</span> and <span class="math">\(\Sigma&#39; \vdash \alpha\)</span>, then <span class="math">\(\Sigma \vdash \alpha\)</span></p>
<p>Proof:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A_1, \ldots, A_n \vdash \alpha\)</span> (Premise)</li>
<li><span class="math">\(A_1, \ldots, A_{n - 1} \vdash A_n \rightarrow \alpha\)</span> (<span class="math">\(\rightarrow\)</span>+)</li>
<li><span class="math">\(\vdash A_1 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)\)</span></li>
<li><span class="math">\(\Sigma \vdash A_1 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)\)</span></li>
<li><span class="math">\(\Sigma \vdash A_1\)</span> (premise)</li>
<li><span class="math">\(\Sigma \vdash A_2 \rightarrow (\ldots (A_n \rightarrow \alpha) \ldots)\)</span></li>
<li><span class="math">\(\Sigma \vdash \alpha\)</span></li>
</ol>
<p>The proof rules of Natural Deduction are purely syntactic - they only shuffle symbols around without considering what they mean. Now we connect it with the actual semantics.</p>
<p>Soundness of natural deduction means that formal proofs demonstrate tautological consequences - <span class="math">\(\Sigma \vdash \alpha\)</span> implies that <span class="math">\(\Sigma \models \alpha\)</span>. In other words, every proof should be a valid argument.</p>
<p>Completeness of natural deduction means that tautological consequences are provable using natural deduction - <span class="math">\(\Sigma \models \alpha\)</span> implies that <span class="math">\(\Sigma \vdash \alpha\)</span>. In other words, every valid argument should have a proof.</p>
<p>Basically, anything provable by truth tables can also be proven using the ND rules.</p>
<p>Since ND is sound and complete, <span class="math">\(\Sigma \models \alpha\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha\)</span>.</p>
<p>Also, <span class="math">\(\rightarrow\)</span> does not have an associative property, so <span class="math">\((A \rightarrow B) \rightarrow C\)</span> is not the same as <span class="math">\(A \rightarrow (B \rightarrow C)\)</span>.</p>
<h1 id="section-8">9/6/14</h1>
<h3 id="natural-deduction-1">Natural Deduction</h3>
<p>Soundness and completeness is rather intuitive. For example, it is obvious that if <span class="math">\(p\)</span> and <span class="math">\(q\)</span> are true, then <span class="math">\(p\)</span> is also true, so <span class="math">\(p \wedge q \models p\)</span>. In ND, this is represented using the <span class="math">\(\wedge-\)</span> rule, which states <span class="math">\(p \wedge q \vdash p\)</span>.</p>
<p>When we want to prove that two formulas are tautologically equivalent, we can either use a truth table, or write a formal proof.</p>
<p>A <strong>sound</strong> formula is one where its proof, <span class="math">\(\Sigma \vdash \alpha\)</span>, implies <span class="math">\(\Sigma \models \alpha\)</span>.</p>
<p>We can prove the soundness theorem for ND using strong induction over the length of the proof:</p>
<blockquote>
<p>Let <span class="math">\(n\)</span> be the length of the proof in steps.<br />Clearly, if <span class="math">\(n = 1\)</span>, then the proof must have the form <span class="math">\(\Sigma, \alpha \vdash \alpha\)</span> (<span class="math">\(\epsilon\)</span>), since this is the only rule that can prove something in one step.<br />Clearly, <span class="math">\(\Sigma, \phi \models \phi\)</span> because anything is a tautological consequence of itself.<br />Assume for some <span class="math">\(k \ge 1\)</span> that all proofs of length <span class="math">\(k\)</span> or less are sound - the inductive hypothesis.<br />Then a proof of length <span class="math">\(k + 1\)</span> has the steps <span class="math">\(\alpha_1, \ldots, \alpha_k, \phi\)</span>, with rules associated with each step.<br />Clearly, <span class="math">\(\alpha_1, \ldots, \alpha_k\)</span> is sound, by the inductive hypothesis.<br />We want to prove that <span class="math">\(\alpha_1, \ldots, \alpha_k, \phi\)</span> is also sound.<br />Clearly, <span class="math">\(\phi\)</span> is the result of applying the ND rules. So each rule is a possible case and we need to check each rule to verify that the proof of length <span class="math">\(k + 1\)</span> is sound.<br />Assume the last rule is <span class="math">\(\wedge+\)</span>. Then <span class="math">\(\phi\)</span> is of the form <span class="math">\(\alpha_i \wedge \alpha_j\)</span> where <span class="math">\(i &lt; k, j &lt; k\)</span>.<br />Then there must be sound proofs of <span class="math">\(\alpha_i\)</span> and <span class="math">\(\alpha_j\)</span>, by the inductive hypothesis.<br />So <span class="math">\(\Sigma_i \models \alpha_i\)</span> and <span class="math">\(\Sigma_j \models \alpha_j\)</span>.<br />By a truth table, <span class="math">\(\Sigma \models \alpha_i \wedge \alpha_j\)</span>, so <span class="math">\(\phi\)</span> is sound.<br />We can use this technique to verify this for every ND rule.<br />Therefore, <span class="math">\(\Sigma \vdash \phi\)</span> is always sound - it always implies <span class="math">\(\Sigma \models \phi\)</span>.</p>
</blockquote>
<p><strong>Syntactical consistency</strong> is a property of sets of formulas <span class="math">\(\Sigma \subseteq \formlp\)</span> where there does not exist <span class="math">\(\alpha \in \Sigma\)</span> such that <span class="math">\(\Sigma \vdash \alpha\)</span> and <span class="math">\(\Sigma \vdash \neg \alpha\)</span> at the same time - that it not possible to derive a contradiction from the premises.</p>
<p>This is not to be confused with semantic consistency, which applies only to formulas.</p>
<p>A set of formulas <span class="math">\(\Sigma \subseteq \formlp\)</span> is <strong>maximally consistent</strong> if and only if <span class="math">\(\Sigma\)</span> is consistent and any <span class="math">\(\alpha \in \formlp \setminus \Sigma\)</span>, <span class="math">\(\Sigma \cup \set{\alpha}\)</span> is inconsistent. In other words, it is the largest possible set of consistent formulas.</p>
<p>There are multiple possible maximally consistent sets.</p>
<p>If <span class="math">\(\Sigma\)</span> is maximally consistent:</p>
<ul>
<li><span class="math">\(p \in \Sigma\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha\)</span>.</li>
<li><span class="math">\(\alpha \wedge \phi \in \Sigma\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha\)</span> and <span class="math">\(\Sigma \vdash \phi\)</span>.</li>
<li><span class="math">\(\alpha \vee \phi \in \Sigma\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha\)</span> or <span class="math">\(\Sigma \vdash \phi\)</span>.</li>
<li><span class="math">\(\alpha \rightarrow \phi \in \Sigma\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha \implies \Sigma \vdash \phi\)</span>.</li>
<li><span class="math">\(\alpha \leftrightarrow \phi \in \Sigma\)</span> if and only if <span class="math">\(\Sigma \vdash \alpha \iff \Sigma \vdash \phi\)</span>.</li>
</ul>
<p>We can prove the completeness theorem for ND by proving the contrapositive:</p>
<blockquote>
<p>We want to prove <span class="math">\(\Sigma \not\vdash \phi \implies \Sigma \not\models \phi\)</span>.<br />Assume <span class="math">\(\Sigma \not\vdash \phi\)</span>.<br />Then <span class="math">\(\Sigma \cup \set{\neg \alpha}\)</span> is syntactically consistent, because there is no way that <span class="math">\(\Sigma \vdash \alpha\)</span> or <span class="math">\(\Sigma \vdash \neg \phi\)</span> for any <span class="math">\(\phi \in \Sigma\)</span>.<br />So there exists a truth valuation <span class="math">\(t\)</span> such that <span class="math">\(\Sigma^t = 1 \wedge (\neg \phi)^t = 1\)</span>.<br />So <span class="math">\(\Sigma \not\models \phi\)</span>.</p>
</blockquote>
<p>The <strong>Lindenbaum Lemma</strong> says that any consistent set of formulas can be extended into a maximally consistent set.</p>
<h1 id="section-9">11/6/14</h1>
<p>Soundness theorem: <span class="math">\(\Sigma \vdash \alpha \implies \Sigma \models \alpha\)</span>.</p>
<p>Completeness theorem: <span class="math">\(\Sigma \models \alpha \implies \Sigma \vdash \alpha\)</span>, and its contrapositive <span class="math">\(\Sigma \not\vdash \alpha \implies \Sigma \not\models \alpha\)</span>.</p>
<p>Soundness: <span class="math">\(\Sigma\)</span> is satisfiable implies <span class="math">\(\Sigma\)</span> is sound.</p>
<p>Completeness: <span class="math">\(\Sigma\)</span> is sound implies <span class="math">\(\Sigma\)</span> is satisfiable.</p>
<p>Logical connectives:</p>
<ul>
<li><span class="math">\(\neg p\)</span> - not <span class="math">\(p\)</span>, <span class="math">\(p\)</span> does not hold, it is not the case that <span class="math">\(p\)</span>, <span class="math">\(p\)</span> is false</li>
<li><span class="math">\(p \wedge q\)</span> - <span class="math">\(p\)</span> and <span class="math">\(q\)</span>, <span class="math">\(p\)</span> but <span class="math">\(q\)</span>, not only <span class="math">\(p\)</span> but <span class="math">\(q\)</span>, <span class="math">\(p\)</span> while <span class="math">\(q\)</span>, <span class="math">\(p\)</span> despite <span class="math">\(q\)</span>, <span class="math">\(p\)</span> yet <span class="math">\(q\)</span>, <span class="math">\(p\)</span> although <span class="math">\(q\)</span></li>
<li><span class="math">\(p \vee q\)</span> - <span class="math">\(p\)</span> or <span class="math">\(q\)</span>, <span class="math">\(p\)</span> or <span class="math">\(q\)</span> or both, <span class="math">\(p\)</span> and/or q, <span class="math">\(p\)</span> unless <span class="math">\(q\)</span></li>
<li><span class="math">\(p \rightarrow q\)</span> - if <span class="math">\(p\)</span> then <span class="math">\(q\)</span>, <span class="math">\(q\)</span> if <span class="math">\(p\)</span>, <span class="math">\(p\)</span> only if <span class="math">\(q\)</span>, <span class="math">\(q\)</span> when <span class="math">\(p\)</span>, <span class="math">\(p\)</span> is sufficient for <span class="math">\(q\)</span>, <span class="math">\(q\)</span> is necessary for <span class="math">\(p\)</span>, <span class="math">\(p\)</span> implies <span class="math">\(q\)</span></li>
<li><span class="math">\(p \leftrightarrow q\)</span> - <span class="math">\(p\)</span> if and only if <span class="math">\(q\)</span> (<span class="math">\(p\)</span> iff <span class="math">\(q\)</span>), <span class="math">\(p\)</span> is necessary and sufficient for <span class="math">\(q\)</span>, <span class="math">\(p\)</span> exactly if <span class="math">\(q\)</span>, <span class="math">\(p\)</span> is equivalent to <span class="math">\(q\)</span></li>
</ul>
<p>Tips and tricks for proofs:</p>
<ul>
<li>Natural deduction:
<ul>
<li>If you want to prove an implication <span class="math">\(A \rightarrow B\)</span>, then assume <span class="math">\(A\)</span> and show B, and use <span class="math">\(\rightarrow+\)</span>.</li>
<li>If you have something to prove with a different connective, then look at the corresponding introduction rule for that connective and try to show those premises.</li>
<li>As a rule of thumb, when you have something you want to show and can't see how to get it, use proof by contradiction: assume the negation of what you want to show, derive a contradiction, and then use <span class="math">\(\neg-\)</span> to remove the negation on what you wanted to show.</li>
<li>The turnstile and box notations both have their own advantages.</li>
</ul></li>
<li>Hilbert deduction:
<ul>
<li>Think about the problem in high-level steps. For example, if you have proven <span class="math">\(\neg \neg p\)</span> then a high-level step would be to conclude that <span class="math">\(p\)</span>, and figure out how to express this high level step in lower level terms later.</li>
<li>The deduction theorem is one of the most powerful high-level steps for rewriting something you want to show in an easier form.</li>
</ul></li>
</ul>
<p>Prove <span class="math">\(\neg A \vee \neg B \vdash \neg (A \wedge B)\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(\neg A, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg \neg (A \wedge B)\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg A, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg (A \wedge B)\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg A, \neg \neg (A \wedge B) \vdash A \wedge B\)</span> (<span class="math">\(\neg-\)</span> with 1, 2)</li>
<li><span class="math">\(\neg A, \neg \neg (A \wedge B) \vdash A\)</span> (<span class="math">\(\wedge-\)</span> with 3)</li>
<li><span class="math">\(\neg A, \neg \neg (A \wedge B) \vdash \neg A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg A \vdash \neg (A \wedge B)\)</span> (<span class="math">\(\neg-\)</span> 4, 5)</li>
<li><span class="math">\(\neg B, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg \neg (A \wedge B)\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg B, \neg \neg (A \wedge B), \neg (A \wedge B) \vdash \neg (A \wedge B)\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg B, \neg \neg (A \wedge B) \vdash A \wedge B\)</span> (<span class="math">\(\neg-\)</span> with 7, 8)</li>
<li><span class="math">\(\neg B, \neg \neg (A \wedge B) \vdash B\)</span> (<span class="math">\(\wedge-\)</span> with 9)</li>
<li><span class="math">\(\neg B, \neg \neg (A \wedge B) \vdash \neg B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg B \vdash \neg (A \wedge B)\)</span> (<span class="math">\(\neg-\)</span> with 10, 11)</li>
<li><span class="math">\(\neg A \vee \neg B \vdash \neg (A \wedge B)\)</span> (<span class="math">\(\vee+\)</span> with 6, 12)</li>
</ol>
<p>Prove <span class="math">\(\neg (A \wedge B) \vdash \neg A \vee \neg B\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(\neg (A \wedge B), \neg \neg A, \neg A \vdash \neg \neg A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg (A \wedge B), \neg \neg A, \neg A \vdash \neg A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg (A \wedge B), \neg \neg A \vdash A\)</span> (<span class="math">\(\neg-\)</span> with 1, 2)</li>
<li><span class="math">\(\neg (A \wedge B), \neg \neg B, \neg B \vdash \neg \neg B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg (A \wedge B), \neg \neg B, \neg B \vdash \neg B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(\neg (A \wedge B), \neg \neg B \vdash B\)</span> (<span class="math">\(\neg-\)</span> with 4, 5) ;wip</li>
</ol>
<p>Prove <span class="math">\(A \rightarrow B \vdash \neg B \rightarrow \neg A\)</span>:</p>
<ol style="list-style-type: decimal">
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A, \neg A \vdash \neg \neg A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A, \neg A \vdash \neg A\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A \vdash A\)</span> (<span class="math">\(\neg-\)</span> with 1, 2)</li>
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A \vdash A \rightarrow B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A \vdash B\)</span> (<span class="math">\(\rightarrow-\)</span> with 3, 4)</li>
<li><span class="math">\(A \rightarrow B, \neg B, \neg \neg A \vdash \neg B\)</span> (<span class="math">\(\epsilon\)</span>)</li>
<li><span class="math">\(A \rightarrow B, \neg B \vdash \neg A\)</span> (<span class="math">\(\neg-\)</span>)</li>
<li><span class="math">\(A \rightarrow B \vdash \neg B \rightarrow \neg A\)</span> (<span class="math">\(\rightarrow+\)</span> with 7)</li>
</ol>
<h1 id="section-10">16/6/14</h1>
<h2 id="predicate-logic">Predicate Logic</h2>
<p>Predicate logic is also known as <strong>first order logic</strong>.</p>
<p>Predicate logic is like propositional logic, but extended with quantifiers, variables, predicates, functions, constants, and more.</p>
<p>An ordered pair is an object that contains two objects <span class="math">\(a\)</span> and <span class="math">\(b\)</span>, represented by <span class="math">\(\tup{a, b}\)</span>, which, unlike sets, preserves the order of <span class="math">\(a\)</span> and <span class="math">\(b\)</span> (which one goes first). Two ordered pairs <span class="math">\(\tup{a, b}\)</span> and <span class="math">\(\tup{c, d}\)</span> are equal if and only if <span class="math">\(a = c\)</span> and <span class="math">\(b = d\)</span>.</p>
<p>This can be extended into the <strong>tuple</strong> object - an <span class="math">\(n\)</span>-tuple is an object that stores objects <span class="math">\(a_1, \ldots, a_n\)</span>, preserving order, and is represented <span class="math">\(\tup{a_1, \ldots, a_n}\)</span>. Again, <span class="math">\(\tup{a_1, \ldots, a_n} = \tup{b_1, \ldots, b_n}\)</span> if and only if <span class="math">\(a_i = b_i, 1 \le i \le n\)</span>.</p>
<h3 id="relations">Relations</h3>
<p>An <span class="math">\(n\)</span>-ary relation of <span class="math">\(S\)</span> is <span class="math">\(R = \set{\tup{x_1, \ldots, x_n} \middle| x_1, \ldots, x_n \in S, f(x_1, \ldots, x_n)}\)</span> for some boolean function <span class="math">\(f(x_1, \ldots, x_n)\)</span>.</p>
<p>For example, <span class="math">\(\le\)</span> is a binary relation over <span class="math">\(\mb{N}\)</span> where <span class="math">\(R = \set{\tup{a, b} \middle| a, b \in \mb{N}, a \le n}\)</span>. It is the set of all pairs of values where the first value is less than or equal to the second.</p>
<p>A ternary relation over <span class="math">\(\mb{N}\)</span> might be <span class="math">\(R = \set{\tup{x, y, z} \middle| x + y &lt; z, x, y, z \in \mb{N}}\)</span>.</p>
<p>It is always true that any <span class="math">\(n\)</span>-ary relation <span class="math">\(R\)</span> over <span class="math">\(S\)</span> is a subset of <span class="math">\(S^n\)</span>.</p>
<p>Equality is a special binary relation <span class="math">\(R = \set{\tup{x, y} \middle| x, y \in S, x = y} = \set{\tup{x, x} \middel| x \in S}\)</span>.</p>
<p>The Boolean value <span class="math">\(\tup{x, y} \in R\)</span> for a binary relation can also be written <span class="math">\(x R y\)</span>.</p>
<p><span class="math">\(R\)</span> is <strong>reflexive</strong> over <span class="math">\(S\)</span> if and only if <span class="math">\(\forall x \in S, x R x\)</span>.</p>
<p><span class="math">\(R\)</span> is <strong>symmetric</strong> over <span class="math">\(S\)</span> if and only if <span class="math">\(\forall x, y \in S, x R y \implies y R x\)</span>.</p>
<p><span class="math">\(R\)</span> is <strong>transitive</strong> over <span class="math">\(S\)</span> if and only if <span class="math">\(\forall x, y, z \in S, x R y \wedge y R z \implies x R z\)</span>.</p>
<p>If <span class="math">\(R\)</span> is all three, then <span class="math">\(R\)</span> is an equivalence relation. Examples of equivalence relations include <span class="math">\(=\)</span> and <span class="math">\(\equiv \pmod{36}\)</span>.</p>
<p>The <span class="math">\(R\)</span>-equivalence class of <span class="math">\(x\)</span> is <span class="math">\(\overline x = \set{y \in S \middle| x R y}\)</span>. It is the set of all elements of <span class="math">\(S\)</span> that satisfy <span class="math">\(x R y\)</span> and is therefore a subset of <span class="math">\(S\)</span>.</p>
<h3 id="functions">Functions</h3>
<p>A <strong>function/mapping</strong> <span class="math">\(f\)</span> is a set of ordered pairs where <span class="math">\(\tup{x, y} \in f \wedge \tup{x, z} \implies y = z\)</span>. In other words, it is a set of tuples with no duplicates.</p>
<p>The <strong>domain</strong> of <span class="math">\(f\)</span> is <span class="math">\(\operatorname{dom}(f) = \set{x \middle| \tup{x, y} \in f}\)</span>.</p>
<p>The <strong>range</strong> of <span class="math">\(f\)</span> is <span class="math">\(\operatorname{ran}(f) = \set{y \middle| \tup{x, y} \in f}\)</span>.</p>
<p>If <span class="math">\(\exists y, \tup{x, y} \in f\)</span>, then <span class="math">\(f(x) = y\)</span>. If <span class="math">\(\operatorname{dom}(f) = S\)</span> and <span class="math">\(\operatorname{ran}(f) \subseteq T\)</span> for some sets <span class="math">\(S\)</span> and <span class="math">\(T\)</span>, then <span class="math">\(f: S \to T\)</span> (<span class="math">\(f\)</span> is a function from <span class="math">\(S\)</span> to <span class="math">\(T\)</span>). Similarly, we can define <span class="math">\(n\)</span>-ary functions like <span class="math">\(g: S_1, S_2, S_3 \to T\)</span>.</p>
<p>If <span class="math">\(R\)</span> is an <span class="math">\(n\)</span>-ary relation and <span class="math">\(S&#39; \subseteq S\)</span>, then the <strong>restriction</strong> of <span class="math">\(R\)</span> to <span class="math">\(S&#39;\)</span> is <span class="math">\(R \cap S&#39;^n\)</span>. Basically, it is a restriction of the possible input and output values that are allowed. If <span class="math">\(R\)</span> is a function, this is written <span class="math">\(R \mid S&#39;: S&#39; \to T\)</span> - the restriction restricts the allowed x-values.</p>
<p><span class="math">\(f\)</span> is <strong>onto/surjective</strong> if <span class="math">\(\operatorname{ran}(f) = T\)</span> - if the image is the same as the codomain. In other words, the output of the function is all the possible output values in <span class="math">\(T\)</span>, or every possible output value has a corresponding input value.</p>
<p>Basically, every unique <span class="math">\(y \in T\)</span> has a (not necessarily unique) <span class="math">\(x \in S\)</span> such that <span class="math">\(f(x) = y\)</span>.</p>
<p><span class="math">\(f\)</span> is <strong>one-to-one/injective</strong> if <span class="math">\(f(x) = f(y) \implies x = y\)</span> - if every output value has a unique input value. In other words, every possible input value has a unique output value.</p>
<p>Basically, if <span class="math">\(x_1, x_2 \in S\)</span> and <span class="math">\(x_1 \ne x_2\)</span>, then <span class="math">\(f(x_1) \ne f(x_2)\)</span>.</p>
<p>If <span class="math">\(f\)</span> is both, then <span class="math">\(f\)</span> is a bijection and is <strong>bijective</strong> - every output value has one and only one input value, and every input value has one and only one output value. A bijection maps every element of <span class="math">\(S\)</span> to a unique element of <span class="math">\(T\)</span> and vice versa.</p>
<h1 id="section-11">18/6/14</h1>
<p>Two sets <span class="math">\(S, T\)</span> are <strong>equipotent</strong> if and only if there exists a bijection from <span class="math">\(S\)</span> to <span class="math">\(T\)</span>. This is denoted <span class="math">\(S \sim T\)</span>.</p>
<p>If and only if <span class="math">\(S \sim T\)</span>, then <span class="math">\(\abs{S} = \abs{T}\)</span>. A set <span class="math">\(S\)</span> is <strong>countably infinite</strong> if <span class="math">\(\abs{S} = \abs{\mb{N}}\)</span> - if we can construct a bijection between it and the set of all natural numbers. <span class="math">\(S\)</span> is <strong>countable</strong> if it is finite, or countably infinite - if <span class="math">\(\abs{S} \le \abs{\mb{N}}\)</span>.</p>
<p>We can prove a set is countably infinite by showing that there is a bijection between it and <span class="math">\(\mb{N}\)</span>, and we prove a set is countable by either proving it is finite or showing the bijection exists.</p>
<p>We can prove a set <span class="math">\(S\)</span> is not countable by proving that the bijection cannot exist.</p>
<p>Prove that the set of integers is countable:</p>
<blockquote>
<p>Clearly, there are more integers than natural numbers. However, they are both infinite, and infinite sets work in funny ways.<br />Even though there is a bijection between a subset of <span class="math">\(\mb{Z}\)</span> and <span class="math">\(\mb{N}\)</span>, it is actually still possible to define a bijective <span class="math">\(f: \mb{Z} \to \mb{N}\)</span>.<br />Let <span class="math">\(f(z) = \begin{cases} 1 - 2z &amp;\text{if } x \le 0 \\ 2z &amp;\text{if }x &gt; 0 \end{cases}\)</span>.<br />This is a bijection because we can find the inverse, <span class="math">\(f^{-1}(n) = \begin{cases} \frac{1 - n}{2} &amp;\text{if } 2 \mid n \\  \frac n 2 &amp;\text{if } 2 \nmid n \end{cases}\)</span>.<br />So the set of integers is countable.</p>
</blockquote>
<p>A countable set is one where we can enumerate or count the elements - we can assign a natural number to each element in the set.</p>
<p>Any subset of a countable set is countable. The union of countably many countable sets is also countable:</p>
<blockquote>
<p>Let <span class="math">\(S_1 \cup \ldots \cup S_n \cup \ldots\)</span> be a union of countably many countable sets.<br />Let <span class="math">\(S_i = \set{a_{i, 1}, \ldots, a_{i, m}, \ldots}\)</span>.<br />Then <span class="math">\(S_1 \cup \ldots \cup S_n \cup \ldots = \set{a_{1, 1}, a_{1, 2}, a_{2, 1}, a_{1, 3}, a_{2, 2}, a_{3, 1}, a_{1, 4}, a_{2, 3}, a_{3, 2}, a_{4, 1}, \ldots}\)</span> - ordered increasing by <span class="math">\(n + m\)</span> and then by <span class="math">\(n\)</span>.<br />Let <span class="math">\(f: S_1 \cup \ldots \cup S_n \cup \ldots \to \mb{N}\)</span> be defined as <span class="math">\(f(a_{n, m}) = \frac 1 2 (n + m - 1)(n + m - 2) + n = \frac 1 2 (n + m - 1)(n + m - 2) + n = n^2 + m^2 + 2nm - 3n - 3m + 2\)</span>.<br />This is called the diagonalization argument. It can also be used to prove that rational numbers are countable (by making <span class="math">\(n, m\)</span> the numerator and denominator) and similar things.</p>
</blockquote>
<p>The Cartesian product of a finite amount of countable sets is also a countable set. Also, the set of finite sets all containing only elements in a particular countable set is countable.</p>
<hr>
<p>Copyright 2013 Anthony Zhang</p>
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>.
<script type="text/javascript">
MathJax.Hub.Config({
  jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
</body>
</html>