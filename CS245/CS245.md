CS 245
======

Logic and computation.

    Instructor: Daniela Maftuleac
    Email: daniela.maftuleac@uwaterloo.ca
    Office Hours: Tuesday 2-3pm, Wednesday 12-1pm Math Tutorial Center
    Website: https://www.student.cs.uwaterloo.ca/~cs245/

$$
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}_P)}
$$

Assignments are due at 1pm at the dropboxes on MC 4th floor, due on thursdays, posted on tuesdays, returned in tutorials. Remark requests must be done within a week after the marks are posted.

Logic
-----

Logic is the science of correct reasoning.  It is concerned with determining whether things are true or false.

In **symbolic logic**, we use symbols to represent truth values and manipulate logical statements using certain logical rules.

This course deals with propositional logic, predicate logic, and program verification.

Prove that $3 \mid (4^n + 5)$ for all $n \in \mb{N}$:

> Clearly, this is true for $n = 0$, since $3 \mid (1 + 5)$.  
> Assume for some $k \ge 0$ that $3 \mid (4^k + 5)$.  
> So $\exists p \in \mb{Z}, 3p = 4^k + 5$ and $4(3p) = 4(4^k + 5)$, so $12p - 15 = 3(4p - 5) = 4^{k + 1} + 5$.  
> Let $q = 4p - 5$. Since $q \in \mb{Z}$, $\exists q \in \mb{Z}, 3q = 4^{k + 1} + 5$.  
> So $3 \mid 4^{k + 1} + 5$, and by induction, $3 \mid 4^n + 5$ for all $n \in \mb{N}$.  

The idea is that with strong induction, we can use any of the previous cases to prove the inductive hypothesis.

# 7/5/14

;wip: do assignment 1

Propositional Logic
-------------------

The language of propositions is propositional logic.

A proposition is a declarative statement that is either true or false. It may depend on the context, like how the proposition $x \ge 5$ depends on the contextual variable $x$.

We always assume that for any proposition with its context (the situation the proposition applies in), either the proposition is true, or it is false, and it cannot be both. If a statement is false, then its negation is true.

Propositions must be declarative. They must make sense when we ask, "is it true that PROPOSITION?". It must be assignable to either true or false.

**Simple/atomic propositions** are the building blocks of **compound propositions**. For example, "It is currently raining in Waterloo" and "It is currently 12 degrees Celsius in Waterloo" are simple propositions, and "It is either raining or 12 degrees in Waterloo" is a compound proposition.

Atomic ropositions are the smallest possible statements that are still propositions. They cannot be divided into smaller propositions.

### Expression Syntax

The propositional language is known as $\mathcal{L}_P$. This language contains **atoms**, which are lowercase Latin characters such as $p$, $q$, and $r$, optionally with subscripts. These all belong to the set $\operatorname{Atom}(\mathcal{L}_P)$, so $p \in \operatorname{Atom}(\mathcal{L}_P)$.

There are also **punctuation** symbols, the round parentheses "(" and ")", which change the precendence of subexpressions.

There are also **connectives**, which are $\neg, \wedge, \vee, \rightarrow, \leftrightarrow$.

An **expression** is a finite sequence of symbols. The length of an expression is the number of symbols it contains. Expressions may not necessarily be valid, like $( \vee \neg \vee ($.

The empty expression (containing no symbols) is denoted $\emptyset$.

### Expression Operations

Let $U, V, W$ be expressions. Then $U$ and $V$ are equal ($U = V$) if and only if they contain the same sequence of symbols.

Then $UV$ is the concatenation of $U$ and $V$ - the expression containing the entire sequence in $U$, followed by the entire sequence in $V$.

If $U = W_1 V W_2$, then $V$ is a **segment** of $U$ - it is a sequence of symbols that $U$ also contains. All sequences contain the empty expression.

If $V$ is a segment of $U$ and $V \ne U$, then $V$ is a **proper segment** of $U$.

If $U = VW$, then $V$ is an **initial segment** and $W$ is a **terminal segment**.

### Expression Validity

The binary (two-parameter) connectives are $\wedge, \vee, \rightarrow, \leftrightarrow$. In the following, $\odot$ will represent any arbitrary one of these binary connectives. The only connective that is not binary is the unary $\neg$ connective.

The set of **formulas** is the set of all valid/well-formed expressions, and is denoted $\formlp$. Given $A, B \in \formlp$, we can define $\formlp$ as follows:

* $\operatorname{Atom}(\mathcal{L}_P) \subseteq \formlp$ - all atoms are formulas.
* $\neg A \in \formlp$ - the negation of any formula is also a formula (the set of formulas are closed under negation).
* $A \odot B \in \formlp$ - binary connectives applied to two formulas are also formulas (the set of formulas is closed under all the binary connectives).

Formulas are often represented using Roman capital letters.

Theorem 2.2.3 states the obvious consequences of the definition: all formulas of $\mathcal{L}_P$ are atoms, or of the form $\neg A, A \wedge B, A \vee B, A \rightarrow B, A \leftrightarrow B$.

Let $R(n)$ be a property (true if the property holds for $n$, false otherwise). Theorem 2.2.4 states that if $\forall p \in \operatorname{Atom}(\mathcal{L}_P), R(p)$ and $\forall A \in \formlp, R(A) \implies R(\neg A)$ and $\forall A, B \in \formlp, R(A) \wedge R(B) \implies R(A \odot B)$, then $\forall A \in \formlp, R(A)$.

In other words, if a property holds for all the forms of formulas, then it holds for all formulas.

The **type** of a formula is determined by its top-level operator. For example, $\neg A$ is a negation, $A \wedge B$ is conjunction, $A \vee b$ is a disjunction, $A \rightarrow B$ is an implication, $A \leftrightarrow B$ is an equivalence. According to theorem 2.3.3, all formulas must be one of these forms.

We want to be able to look at any expression and determine whether it is well formed. For example, $\neg()$ is not a well formed formula (WFF) because it is not obtainable through the rules that define an element in the set of formulas.

Is $(\neg a) \wedge (b \vee c)$ well formed?

> We can first notice that this is of the form $P \wedge Q$, where $P = \neg a$ and $Q = b \vee c$. By the rules, we know that the whole thing is well formed if and only if $P$ and $Q$ are both well formed.  
> Now we check if $P$ is well formed. Clearly, it is of the form $\neg R$, where $R = a$, and $a$ is an atom (which is, by definition, well formed), so by the rules, $\neg a$ is well formed.  
> Now we check if $Q$ is well formed. Clearly, it is of the form $S \vee T$, where $S = b$ and $T = c$. By the rules, $Q$ is well formed if and only if $S$ and $T$ are. Since they are atoms, they are both well formed by definition.  
> Since $P$ and $Q$ are well formed, $P \wedge Q$ is well formed and so is $(\neg a) \wedge (b \vee c)$.  

# 12/5/14

Parse Trees
-----------

The other way of testing for well-formedness is by constructing a parse tree out of the symbols in the formula. The top-level operator or atom is the root node of the tree, and the operands are its children. This is repeated until all the symbols have been added to the tree. Parentheses simply change the arrangement of the nodes and are not included in the parse tree.

For example, the expression $(((\neg p) \wedge q) \rightarrow (p \wedge (q \vee (\neg r))))$ has the following parse tree:

          \implies
           /   \
          /     \
      \wedge   \wedge
       /  \     /  \
    \neg   q   p  \vee
      |           /  \
      p          q  \neg
                      |
                      r

Every parse tree is unique. The rules for a valid formula can be applied to a parse tree to test for well-formedness:

* Tree nodes must be either atoms or connectives.
* If a node is an atom, it cannot have any children - if a node has children, it must be a connective.
* If a node is the unary connective ($\neg$), then it must have exactly one child.
* If the node is a binary connective, then it must have exactly two children.
* If a tree is empty, then it is not a well formed formula.

An algorithm for testing if an expression $U$ is a well formed formula is given below

1. If $U$ is empty, produce False.
2. If $U \in \operatorname{Atom}(\mathcal{L}_P)$, then produce True.
3. If the expression does not begin with a $($ symbol, produce False.
4. If the second symbol is $\neg$, then let $V$ be an expression such that $U = (\neg V)$. Apply this algorithm again with $V$ as the expression, and if it is false, produce False.
5. Otherwise (the second symbol is not $\neg$), apply this algorithm again with all the symbols starting from and including the second symbol, except doing nothing in step 7. If it results in False, return False. Otherwise, let $V$ be the well formed formula from the second symbol to wherever the algorithm run ended. If the next symbol after this is not a binary connective, produce False. Do the formula thing again to get a well formed formula $W$, or produce False.
6. If the symbol after the place $W$ ended is not a $)$ symbol, produce False.
7. If the expression does not end after the $)$ symbol, produce False.
8. Produce True.

This algorithm gets applied a finite number of times, proportional to the depth of the tree.

The **height** of a parse tree is the length of the longest path from the root to a leaf.

### Precedence

We now introduce a system of precedence. The logical connectives listed by priority, from highest to lowest, are $\neg$, $\wedge$, $\vee$, $\rightarrow$, and $\leftrightarrow$.

Precedence is the idea that some connectives get higher priority than others. For example, $p \vee q \wedge r$ could potentially mean either $((p \vee q) \wedge r)$, or $(p \vee (q \wedge r))$. But since $\wedge$ has a higher precedence than $\vee$, we define $p \vee q \wedge r$ to mean $(p \vee (q \wedge r))$.

When there are multiple ambiguities, we start with the ones with highest precedence. For example, $\neg p \wedge q \vee r$ is resolved to $(neg p) \wedge q \vee r$, then $(((neg p) \wedge q) \vee r)$.

With this in place, we can now eliminate many of the superfluous parentheses to clean up our formulas.

**Course of values induction** is a type of strong induction where the inductive hypothesis used to prove the inductive conclusion is the conjunction of all the previous cases.

In other words, we do course of values induction by proving a property holds for $M(1)$, and then by proving that $M(1) \wedge \ldots \wedge M(k) \implies M(k + 1)$ for any $k \ge 1$. By the principal of strong induction, $M(n)$ therefore holds for all $n \ge 1$.

Sometimes we want to use induction on the height of the parse tree. This is often useful for proving things about propositional formulas, due to the recursive nature of formulas.

If a formula $C$ contains the segment $(\neg A)$, where $A$ is another formula, then $A$ is the **scope** of the $\neg$ within $C$. The scope is the area where the $\neg$ applies.

For binary connectives, if $C$ contains $(A \odot B)$ where $\odot$ is a binary connective, then $A$ and $B$ are the left and right scopes, respectively, of the binary connective within $C$.

A scope is unique to the operator. Two operators cannot have the exact same scope, though the scopes themselves can be equal.

# 14/5/14

Semantics
---------

The semantics of a language describe how we interpret should valid formulas in that language. Semantics assigns meanings to formulas.

Let $A$ and $B$ be formulas, representing the propositions $\mathcal{A}$ and $\mathcal{B}$, respectively. Then $\neg A$ represents "Not $\mathcal{A}$", $A \wedge B$ represents "$\mathcal{A}$ and $\mathcal{B}$".

Semantics is formally given as functions that map each formula to a value in $\set{0, 1}$ (false and true). This function can be represented using a **truth table**.

The value of a formula $A$ given a truth valuation $t$ is represented $A^t$, with $A^t \in \set{0, 1}$. If we used conventional function notation, we might write $t(A) \in \set{0, 1}$.

**Truth valuations** are functions that are used to assign truth values to propositional variables. The domain is the set of propositional variables in a formula, and the range is $\set{0, 1}$. If $t$ is a truth valuation, then $A^t \in \set{0, 1}$, where $A$ is a propositional variable.

We can completely represent the truth valuation for a formula by listing out all possible values of the domain and the resulting value in the range. For $n$ variables, there are $2^n$ possible values.

We can define the truth valuation function $t$ in terms of formulas $A$ and $B$ recursively:

1. $A \in \operatorname{Atom}(\mathcal{L}_P) \implies A^t \in \set{0, 1}$.
2. $(\neg A) = \begin{cases} 1 &\text{if } A^t = 0 \\ 0 &\text{otherwise} \end{cases}$.
3. $(A \wedge B) = \begin{cases} 1 &\text{if } A^t = B^t = 0 \\ 0 &\text{otherwise} \end{cases}$.
4. $(A \vee B) = \begin{cases} 1 &\text{if } A^t = 0 \text{ or } B^t = 0 \\ 0 &\text{otherwise} \end{cases}$.
5. $(A \rightarrow B) = \begin{cases} 1 &\text{if } A^t = 0 \text{ or } B^t = 1 \\ 0 &\text{otherwise} \end{cases}$.
6. $(A \leftrightarrow B) = \begin{cases} 1 &\text{if } A^t = B^t \\ 0 &\text{otherwise} \end{cases}$.

Given a set of formulas $\Sigma$, $\Sigma^t = \begin{cases} 1 &\text{if } \forall A \in \Sigma, A^t = 1 \\ 0 &\text{otherwise} \end{cases}$. In other words, a set of formulas is true in a given truth valuation if and only if all of the formulas in the set are true.

$\Sigma$ is **satisfiable** if and only if there exists a truth valuation $t$ such that $\Sigma^t = 1$. It this $t$ exists, then $t$ **satisfies** $\Sigma$. Therefore, $\emptyset$ satisfiable by any truth valuation.

A **tautology** is a formula which is always true, so for any truth valuation $t$, $A^t = 1$.

A **contradiction** is a formula which is always false, so for any truth valuation $t$, $A^t = 0$.

A **consistent** formula is one that is not a contradiction, so there exists a truth valuation $t$ such that $A^t = 1$.

Rather than writing out the entire truth table, we can simplify formulas using the following identities:

* $\neg 0 = 1, \neg 1 = 0$
* $A \wedge 1 = 1 \wedge A = A$
* $A \wedge 0 = 0 \wedge A = 0$
* $A \vee 1 = 1 \vee A = 1$
* $A \vee 0 = 0 \vee A = A$
* $A \rightarrow 1 = 1$
* $0 \rightarrow A = 1$
* $1 \rightarrow A = A$
* $A \rightarrow 0 = \neg A$

Show that $A = ((p \wedge q \rightarrow r) \wedge (p \rightarrow q)) \rightarrow (p \rightarrow r)$ is a tautology:

> Assume $p^t = 0$. Then $A^t = (1 \rightarrow (p \rightarrow r))^t = 1$.  
> Assume $p^t = 1$. Then $A^t = (((q \rightarrow r) \wedge q) \rightarrow r)^t$.  
> Assume $q^t = 0$. Then $A^t = 1$. Assume $q^t = 1$. Then $A^t = (r \rightarrow r)^t = 1$.  
> So $A$ is a tautology.  

Let $\mathcal{A}$ and $\mathcal{A}_1, \ldots, \mathcal{A}_n$ be propositions.

Deductive logic studies whether $\mathcal{A}$ can be deduced from $\mathcal{A}_1, \ldots, \mathcal{A}_n$.

Let $\Sigma \subseteq \formlp, A \in \formlp$.

$A$ is a **tautological consequence/semantic entailment** of $\Sigma$ (written $\Sigma \models A$) if and only if for all truth valuation $t$, $\Sigma^t = 1 \implies A^t = 1$. Also, $\neg (\Sigma \models A) = \Sigma \not\models A$. We can also write out the elements of $\Sigma$ directly, like $P_1, \ldots, P_n \models A$, which is the same as $\set{P_1, \ldots, P_n} \models A$.

In other words, if $\Sigma \models A$, then the truth of $\Sigma$ implies the truth of $A$.

As a result, if $\emptyset \models A$, then $A$ is a tautology. This is because $\emptyset^t = 1$ for any truth valuation $t$, so $A^t = 1$ as well.

As a result of our semantic definitions of our operations, conjunction and disjunction is commutative and associative. So $A \wedge B = B \wedge A, A \vee B = B \vee A, (A \wedge B) \wedge C = A \wedge (B \wedge C), (A \vee B) \vee C = A \vee (B \vee C)$.

Also, $A_1, \ldots, A_n \models A \iff \emptyset \models A_1 \wedge \ldots \wedge A_n \rightarrow A \iff \emptyset \models A_1 \implies (A_2 \implies (\ldots (A_n \implies A) \ldots))$.

# 21/5/14

Note that $\Sigma \implies A$ is not a formula, because it cannot be created using the formula rules. It is an operator that accepts formulas as both operands.

It is true that $\Sigma \not\models A$ if there exists a truth valuation $t$ such that $\Sigma^t = 1$ and $A^t = 0$.

If $A \models B$ and $B \models A$, then $A \equiv B$. Also, if $A \equiv B$ and $C \equiv D$, then $\neg A \equiv \neg B$ and $A \odot C \equiv B \odot D$ where $\odot$ is a binary connective.

Also, we define $\emptyset^t = 1$ for any truth valuation $t$.

If $B \equiv C$, then $A \equiv A'$ where $A'$ is $A$ with any number of occurrences of $B$ replaced by $C$. This is known as **replacability**.

The **dual** of $A$, which is a formula that uses only the connectives $\neg, \wedge, \vee$ is $A'$, which is $A$ with every $\wedge$ replaced by $\vee$, every $\vee$ with $\wedge$, and every atom $A$ with $\neg A$. It is always true that $A = \neg A'$. This is basically application of De Morgan's laws to formulas.

We know that $A \rightarrow B \equiv \neg A \vee B$. Because of this, $\rightarrow$ is **definable** in terms of $\neg, \vee$, or **reducible to** $\neg, \vee$.

$\neg$ is a unary connective - it accepts one operand. $\vee$ is a binary connective - it accepts two operands. It is also possible to have ternary connectives and even connectives of arity 4 and above (arity is the number of operands).

Let $f$ be an $n$-ary connective - a connective accepting $n$ operands. Then $f A_1 \ldots A_n$ is a formula where $A_1, \ldots, A_n$ are connected by the connective $f$.

An $n$-ary connective has $2^n$ possible input cases to consider. For $k$ possible inputs, there are $2^k$ possible output cases. So there are $2^{2^n}$ possible $n$-ary connectives.

A set of connectives is **adequate** if and only if any $n$-ary connective can be defined in terms of these connectives.

For example, $\set{\wedge, \vee, \neg}$ is an adequate set because the truth table for any $n$-ary operator can be represented by a formula using just these connectives. This can be proven:

> Let $f$ be an $n$-ary connective. Clearly, there are $2^n$ possible truth valuations $t_1, \ldots, t_{2^n}$ for $A_1, \ldots, A_n$. Let $t$ be one of these truth valuations.  
> Let $T(t) = T_1(t) \wedge \ldots \wedge T_n$(t) where $T_i(t) = \begin{cases} A_i &\text{if } A_i^t = 1 \\ \neg A_i &\text{if } A_i^t = 0 \end{cases}$. For example, if $A_1^t = 1, A_2^t = 0, A_3^t = 1$, then $T = A_1 (\neg A_2) A_3$.  
> Clearly, $T(t_i)^{t_j}$ is true if and only if $t_i = t_j$. In other words, $T(t)$ results in a formula that is true in only the truth valuation $t$ and no others.
> Let $V = T(t_1) \vee \ldots \vee T(t_{2^n})$, where there is a $T(i)$ term if and only if $(f A_1, \ldots, A_n)^t = 1$.  
> Clearly, this is a formula that is true when $f A_1, \ldots, A_n$ is true, and false otherwise. Therefore, $f A_1, \ldots, A_n = V$.  
> So any $f$ can be defined in terms of $\set{\wedge, \vee, \neg}$, which makes it adequate.  

We usually prove sets are adequate by defining the connectives in a set that is already known to be adequate in terms of the connectives of this set. If a connective $f$ is definable in terms of a set of connectives $A$, and every connective in that set is definable in terms of another set $B$, then $f$ is definable in terms of $B$.

This is because we could define $f$ first in terms of $A$, and then define that in terms of $B$.

For example, $\set{\wedge, \neg}$ is adequate because $\wedge$ and $\neg$ are already in the set, and $A \vee B \equiv \neg((\neg A) \wedge (\neg B))$, so $\vee$ is definable in terms of $\set{\wedge, \neg}$.

# 26/5/14

The Schroder connective is defined as $A \downarrow B$ where $A \downarrow B \equiv \neg (A \wedge B)$ - the NAND operation.

$\set{\neg, \rightarrow}$ is an adequate set.

Proof Calculus
--------------

We want a calculus for reasoning about propositional logic. This will allow us to simplify proofs of validity.

In this course we will be looking at the Hilbert and natural deduction systems for formal proof calculus.

### Hilbert System

The **Hilbert System** is a deductive system over the set of propositional logic formulas.

$\Sigma \models d$ is the same as $\forall t, \Sigma^t = 1 \implies d^t = 1$.

$\Sigma \vdash \alpha$ means that $\alpha$ is provable or deducible from $\Sigma$. $\Sigma \vdash_H \alpha$ means that $\alpha$ is provable or deducible in the Hilbert system. $\vdash_H A$ means $\emptyset \vdash_H A$.

$\Sigma$ is a set of formulas known as premises, and from them we can deduce $\delta$ using axioms and inference rules.

Axioms are basically just tautologies. In this course we will only be using axioms over $\set{\neg, \rightarrow}$ since this set is small and results in fewer axioms:

1. $\phi \rightarrow (\psi \rightarrow \phi)$ - basically, this is just a special case of 
2. $(\phi \rightarrow (\psi \rightarrow \xi)) \rightarrow ((\phi \rightarrow \psi) \rightarrow (\phi \rightarrow \xi))$ - basically, $\rightarrow$ is distributive
3. $(\neg \phi \rightarrow \neg \psi) \rightarrow (\psi \rightarrow \phi)$ - basically, the contrapositive of a formula implies the formula

Here, $\phi, psi, \xi$ are any formulas.

**Inference rules** are manipulations we can perform on formulas to obtain new formulas. In this system we have only Modus Ponens (MP): $\set{\phi, \phi \rightarrow \psi} \rightarrow_H \psi$.

A **proof** is a set of formulas that includes axioms, premises, and conclusions. We start with the axioms that we know are true, so we use inference rules over the axioms and previously obtained formulas, listing out each new formula obtained, until we get the desired result.

For example, prove that $\vdash_H A \rightarrow A$:

1. $A \rightarrow ((A \rightarrow A) \rightarrow A)$ (Axiom 1 where $\psi = A \rightarrow A$)
2. $(A \rightarrow ((A \rightarrow A) \rightarrow A)) \rightarrow ((A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A))$ (Axiom 2 where $\psi = A \rightarrow A$)
3. $(A \rightarrow (A \rightarrow A)) \rightarrow (A \rightarrow A)$ (Modus Ponens on 1 and 2)
4. $A \rightarrow A$ (Modus Ponens on 1 and 3)

Prove that $\set{A \rightarrow B, B \rightarrow C} \vdash_H A \rightarrow C$:

1. $A \rightarrow B$ (Premise 1)
2. $B \rightarrow C$ (Premise 2)
3. $((B \rightarrow C) \rightarrow (A \rightarrow (B \rightarrow C)))$ (Axiom 1 where $\phi = A \rightarrow B$)
4. $A \rightarrow (B \rightarrow C)$ (Modus Ponens on 1 and 3)
5. $(A \rightarrow (B \rightarrow C)) \rightarrow ((A \rightarrow B) \rightarrow (A \rightarrow C))$ (Axiom 2)
6. $(A \rightarrow B) \rightarrow (A \rightarrow C)$ (Modus Ponens on 4 and 5)
7. $A \rightarrow C$ (Modus Ponens on 1 and 6)

The **deduction theorem** says that $\Sigma \vdash_H A \rightarrow B$ if and only if $\Sigma \cup A \vdash_H B$. So $\set{\alpha_1, \ldots, \alpha_n} \vdash_H \alpha$ is the same as $\emptyset \vdash_H (\alpha_1 \rightarrow (\ldots (alpha_n \rightarrow \alpha) \ldots))$.

# 28/5/14

Prove that $\neg \neg A \vdash_H A$:

1. $\neg \neg A$ (Premise 1)
2. $\neg \neg A \rightarrow (\neg \neg \neg \neg A \rightarrow \neg \neg A)$ (Axiom 1 where $\psi = \neg \neg \neg \neg A$)
3. $\neg \neg \neg \neg A \rightarrow \neg \neg A$ (Modus Ponens on 1 and 2)
4. $(\neg (\neg \neg \neg A) \rightarrow \neg A) \rightarrow (\neg A \rightarrow \phi)$ (Axiom 3 where $\phi = \neg \neg \neg A$)
5. $\neg A \rightarrow \neg \neg \neg A$ (Modus Ponens on 3 and 4)
6. $(\neg A \rightarrow \neg \neg \neg A) \rightarrow (\neg \neg A \rightarrow A)$ (Axiom 3 where $\psi = \neg \neg A$)
7. $\neg \neg A \rightarrow A$ (Modus Ponens on 5 and 6)
8. $A$ (Modus Ponens on 1 and 7)

$\Sigma \models \alpha$ is a semantic construct. We use this to prove soundness.

$\Sigma \vdash \alpha$ is a syntactical construct. We use this to prove completeness.

Formulas must be semantically entailed before it can be syntactically entailed. We need it to be semantically sound before proving it is complete.

Here are some rules of thumb to more easily construct proofs.

* ;wip

### Natural Deduction

Using proof rules, we infer a conclusion from the premises.

;wip: finish this
;wip: box notation for proofs by contradiction - draw a box around statements starting from the assumption up to and including the contradiction.