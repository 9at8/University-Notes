CS348
=====

Introduction to Database Management.

    Edward Chan
    Section 002
    epfchan@uwaterloo.ca
    Office Hours: Monday, Wednesday 12:30 PM-1:15 PM, DC2338

$$
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}^P)}
$$

# 14/9/15

Databases, data modelling, and relational algebra, in theory and in practice.

Assignments are due before 1 PM on their respective due dates. No late assignments. Midterm on November 6, 4:30 PM-6 PM.

# 16/9/15

Elements of Databases
---------------------

Databases are needed to manage data because we want to store and retrieve it in increasingly elaborate ways. Data is stored information.

The goal of data management is to model part of the real world in a way that is practically useful. We want to do this efficiently and accurately, and hiding irrelevant details so we can concentrate on the common properties of the set (abstraction).

**Intension** of data is the definition of data, like the definition of employee records. **Extension** of data is the actual instances of the data, such as the set of employee records - it changes with the state of the world. In databases, the intension of data is the **database schema**. and the extension of data are the actual records in the database.

A database management system (DBMS) dictates how data is organized and accessed - the structure of the data. A DBMS also exposes interfaces to store, retrieve, and update data efficiently. A modern DBMS must handle concurrent operations, ensure integrity (database constraints, such as a column being unique or a superset of another), enforce security (access control), and support versioning and recovery (ensuring data can be restored after failures such as hard drive crashes and data corruption).

# 18/9/15

Consider a banking app. The following code might be used for a transfer:

    read source account
    subtract amount to transfer
    write source account
    read target account
    add amount to transfer
    write target account

This is a very poor way of going about data management. For example, if a system failure occurs right after `write source account`, the amount to transfer is simply lost, and the system is left in an inconsistent state. Additionally, if the source account has an amount transferred into it between `read source amount` and `write source amount`, that transfer is lost. In this case, we want the entire thing to happen as a unit, so it either goes through successfully, or if there is a system failure, it doesn't happen at all - it should be **atomic**.

Logical files are those seen by application programmers, such as database tables. Physical files are those seen by system programmers, such as the actual files organized by the database.

The goal of the modern DBMS is to make the data and the applications that use it more independent. This allows us to do things like swapping out the physical storage without changing any applications, or adding and removing indicese.

DBMSs can require people like operators (data entry, machine operators), system developers, and database administrators. DBMSs also have associated procedures such as what to do in case of failures and how to use the interfaces

DBMSs have a 3-level architecture - the external level (the application programs and views), the conceptual level (the conceptual schema/data model), and the internal level (data storage, OS, hardware).

DBMSs also have various language interfaces, such as **data definition language** (DDL), which is used for defining schemas. The DDL is compiled into a system catalog, which is essentially just schema metadata. There is also the **data manipulation language**, which is the instructions from the application that allows data to be manipulated, and the **query language**, which allows data to be manipulated.

A **data model** is the logical organization of data. On top of the data model, we define **operations** to manipulate it, and constraints to ensure data integrity and enforce logical restrictions. The **entity-relational model** is the most common data model.

Objects in DBMSs can be stored by value or by reference. Storing by reference supports everything storing by value does, but can also have multiple entries reference the same object.

# 21/9/15

An **entity** is an object that has properties and can be uniquely identified. An **entity set** is a set of entities with similar properties - an extension. An **entity type** is an abstraction over an entity set - an intension. An attribute is a property of an entity, and an attribute value is an instance of an attribute. Attributes can be single-valued or multi-valued (such as arrays of other values), and simple (primitive) or composite (contains other simple/composite values). The **domain** is the set of all possible attribute values.

A **relationship** is an association between multiple entities. An $n$-ary relationship associates $n$ entities with each other. A **relationship set** is a set of similar relationships, such as those containing common entities - an extension. A **relationship type** is an abstraction over a relationship set - the intension, like WORKS_IN_DEPARTMENT in an employee databse.

Relationship and entity types can have attributes too.

When designing databases, we need to determine the functional requirements and the database requirements. Using these, we figure out the database interface (the transaction specification) and schema, and then implement the application program and set up the DBMS.

Contraints and Relationships
----------------------------

A **candidate key** is a minimal set of attributes (least possible number of attributes) of an entity type that uniquely identifies each entity in its entity set. For example, a collection of students might have student number or social insurance number as candidate key.

A **primary key** is a candidate key that is chosen (as part of the design) as the main way to identify entities in an entity set. Primary keys can be added to any entity type, but are always optional. These **key constraints** apply to entity types.

An **entity-relation diagram** represents entity types and relationship types using a flowchart-like diagram:

* Entity types are represented with labelled rectangles.
* Entity attributes are represented with ellipses, connected to entity types with lines.
    * Attributes that are part of the primary key, if there is one, have underlined labels.
* Relationships are labelled diamonds, connected to the entity types they act over with lines.
    * The cardinality is specified by labelling each of the two lines from the diamond with `(MIN_ENTITIES, MAX_ENTITIES)`. For example, a relationship between department and employee might have labels `(0, *)` for the department side, and `(1, 1)` for the employee side - departments can have any number of employees, while an employe always has just one department.
* Relationships and attributes should not be redundant - a relationship or attribute is reduntant if its removal doesn't change the meaning of the information.
    * For example, an attribute of an employee type that represents the department is redundant if there is also a relationship that associates employee entities with departments.
    * For example, a relationship between department and classes is redundant if there is already a department-student relationship and a student-classes relationship - we could get the same information as a department-class relationship by going through the department-student and student-classes relationship.

Entity-relationship diagrams often get cluttered by attribute ellipses. We can avoid this by not drawing attribute ellipses, and then also including a list with entries of the form `ENTITY_TYPE (ATTRIBUTE1, ATTRIBUTE2, ...)` to list out the entities. As before, primary key attributes are underlined in this list.

# 23/9/15

For example, for a school application we might have entity types STUDENT, PROGRAM, and CLASS. Relationships might include a STUDENT instance being ENROLLED_IN multiple CLASS entities, or a STUDENT instance MAJORED_IN a PROGRAM entity.

The **cardinality** of a relationship type restricts the number of each entity type that can be in that relationhip type. For example, for binary relationships (relationships between two entity types), common cardinalities are 1:1 (one to one, 1 of each entity type per relationship), 1:N (one to many, one or more of one entity type per each of the other), and N:M (many to many, any number of either entity type). These **cardinality constraints** apply to relationship types. The cardinality, essentially, retricts the number of relationships an entity can can participate in.

The **existance constraint** constrains whether an entity can exist independently of something else. For example, a department should not exist if there are no employees in it. Since a department is always associated with an employee. An entity type is **totally dependent** on another if every entity of the first is always associated with at least one of the second - the first cannot exist without the second.

Relationship Types
------------------

An **is-a** relationship represents subclass entity types inheriting from a superclass entity type, and is drawn in entity-relationship diagrams as a down-pointing triangle labelled "ISA". The superclass entity type is connected by a line, above the triangle, and the subclass entity types are connected by lines below it. Also, attributes of the superclass are inherited by subclasses.

A **generalization** is when multiple related entity types are combined into a single, more general entity type. In ERDs, we make the new generalized entity type, and then add an is-a relationship between the specialized entity types and the new general entity type.

# 25/9/15

A **specialization** is when a single general entity type is broken down into multiple, more specific entity types. In ERDs, we make the new specialized entity types, and then add an is-a relationship between these new entity types and the general entity type.

An **aggregation** is when a relationship between multiple entities is itself treated like an entity type, like having relationships between that relationship and other entity types. In ERDs, we draw these as a box around the entire relationship diamond and any entity types it relates together.

For example, suppose a school offers courses, and students can enquire into offered courses, we can model this using a school entity type, related with a course entity type with a "OFFERS" relationship, and a student entity type. Here, we could have a "ENQUIRES_ABOUT" relationship between students, schools, and courses, but this rather cumberome. Instead, we can use aggregation - we treat the OFFERS relationship like an entity, and relate students to "OFFERS" using an "ENQUIRES_ABOUT" relationship.

# 28/9/15

Databases are often too large to fit in main memory. Therefore, they are generally stored on disk drives or SSDs.

Disk drives have disk packs (disks on a spindle), which have multiple platters (disks), each with many concentric tracks (circles). Tracks are divided into equally sized pages/blocks/sectors (chunks), each of which stores around 512 bytes to 4 kilobytes. The tracks with corresponding radii on each platter form a cylinder.

The disk pack is rotated at a constant speed (typically thousands of RPM), and read/write heads move back and forth over the disks to read/write the data. The blocks on each track have the track number (the cylinder in which the block resides), surface number (which platter the block is on), and block number within the track. Blocks are the unit of transfer and are uniquely identified by these 3 values.

To perform a read/write a block on a disk drive, the read/write head has to seek to the right track, wait for the disk to spin around to the right track, and then perform the read/write until done. As this is a mechanical process, this can take multiple milliseconds - two orders of magnitude greater than CPU operations.

As a result of the mechanical aspects of disk drives, it's a good idea to put related data close together on the same track, in order to avoid seek times and rotational delay when reading related information - this is known as **clustering**. We also try to cache recently used values (and marking modified cache entires as dirty to write them back later), in order to avoid disk operations entirely when possible.

Solid state drives are a lot better, with access times around 150 nanoseconds, but are still very slow relative to the CPU.

A **file** is a sequence of records (fixed or variable length). Each record is stored on at most one block. The blocks storing records can be contiguous (side by side in memory), linked (blocks point to their neighbors), or indexed (a separate mapping is maintained for where certain data is located).

An **ordered/sequential** file has its records sorted by a particular attribute, the **ordering field**. This allows us to find records very fast using binary search, but it also slows down insertions - one common pattern is to accumulate records to insert in an overflow file, and merge it in periodically.

An **index** is extra information added to a file to provide faster accesses at the cost of slower writes. The index is generally a separate file, so there is a data file and an index file.

Indices are built on a particular set of attributes, called the **search key**. A **primary index** is one built on the primary key alone, and any other is a **secondary index**. An **ordered** index keeps the search key in sorted order, while an **unordered** index does not.

Indices are generally implemented using B+ trees. These are very good for range queries, and can easily be inserted into or removed from.

# 30/9/15

B+ trees are similar to the B trees introduced in CS240, but with a few important differences:

* The interior nodes do not contain values, only ranges for its children.
* The leaf nodes are linked to their adjacent siblings, forming a doubly linked list of leaf nodes that makes in-order traversal very easy.

The index is a useful concept because it is independent of the data itself - we can manage indices without touching the data at all.

Although indices make data access faster, they also take up additional space, and slow down data insertion/deletion, as we also have to manage structures like th B+ tree.

The B+ tree represents data as the leaf nodes of a tree in **data blocks**, each of which can contain multiple entries (these are generally pages on the disk). Entries within a data block contain the key and a reference/pointer to a record in the database, and are sorted by their key.

The interior nodes of the tree, the **index blocks**, contain references to other blocks for each range they contain.

Each index block will have a lot of ranges, generally around 70 or more. Each block is limited only by the size of disk pages, and we try to fill the pages as much as possible to minimise the number of page accesses - the most expensive operation. Also, index blocks are cached as much as possible, especially the upper levels, in order to avoid the first few page accesses.

A B+ tree of order $m$ is a search tree in which all leaves are on the same level. Every interior node has between $\floor{\frac {m - 1} 2}$ and $m - 1$ keys sorted in asecending order (except the root, which can have between 1 and $m - 1$), and has children for each range between its keys - for keys $k_1, \ldots, k_n$, we have ranges $(-\infty, k_1], (k_1, k_2], \ldots, (k_{n - 1}, k_n], (k_n, \infty)$. Leaf nodes have between $\floor{\frac d 2}$ and $d$ records, where $d$ is a positive integer.

The constraint on the number of keys in each node ensures that the tree's leaf level is always at least half full, to minimise the height of the tree.

# 2/10/15

Suppose we want to insert a record into a B+ tree. First, we search for the leaf node we want to insert into, and then insert it.

If a leaf node overflows (has more than $d$ keys), we split the records into two new, roughly equally sized data nodes (the left size is 0 or 1 more than the right size), then add a key to the parent index node for the largest value of the left side. This can cause the parent node to overflow as well.

If an index node overflows (has more than $m - 1$ keys), we split the keys into two new, roughly equally sized index nodes (the left side is 0 or 1 more than the right size), where the middle key of the original index node (or the key right after the middle of the key list) is moved into the parent index node. This can cause the parent node to overflow as well.

Suppose we want to delete a record from a B+ tree. First, we search for the leaf node we want to delete from, ad then delete it.

If a leaf node underflows (has less than $\floor{\frac d 2}$ keys), we check its neighbor - if the neighbor has $\floor{\frac d 2}$ keys, we merge the leaf node with its neighbor. Otherwise, we redistribute records from the neighbor into this leaf node so they have roughly the same amount (at this point, neither is underflowing). This can cause the parent node to underflow as well if we end up merging (merging is only done if redistribution isn't possible).

If an index node underflows (has less than $\floor{m 2}$ keys), we also check its neighbor - if the neighbor has $\floor{\frac m 2}$ keys, we merge the index node with its neighbor. Otherwise, we redistribute keys from the neighbor into this index node, like with leaf nodes. This can cause the parent node to underflow as well if we end up merging (merging is only done if redistribution isn't possible).

# 5/10/15

The B+ trees we have seen so far are only for the primary key indices. For multiple indices, things get a lot more complicated.

The Relational Model
--------------------

Modern DBMS use the **relational model**, based on relational algebra and first order logic. Models have the structural components, contraint components, and the operational components. These DBMSs became possible to implement a few decades ago, replacing earlier heirarchical models.

In relational models, the main idea is that all the information is represented using **flat relations**, which allows us to specify the structure of the data declaratively.

The **relational schema** represents relations that we want to model.

We can represent a **relation** $R$ over $n$ attributes as a set of $n$-tuples $\tup{a_1, \ldots, a_n} \in D_1 \times \ldots \times D_n$. $\tup{a_1, \ldots, a_n}$, where $D_1, \ldots, D_n$ are the **domains**, sets of simple, single-valued attributes - $D_i$ is the set of all values of attribute $i$. In other words, relations are sets of tuples of attributes.

Attributes may also have a `null` value, which means that the value of the attribute is actually unknown.

If the relation is in $D_1 \times \ldots \times D_n$, then it is on $n$ sets and $n$ is the degree of the relation.

In DBMSs, all relations are represented as flat tables, where the columns are the attributes $D_1, \ldots, D_n$, and the rows are the instances of the relation. Note that there is no concept of entities here - relations represent both entity-relational entities and entity-relational relations.

The intension of a relation is the relational schema, and the intension of the database isthe database schema $R = \set{R_1, \ldots, R_k}$. The extension of a relation is the set of possible tuples $\tup{a_1, \ldots, a_n}$.

# 7/10/15

By the **closed world assumption** (if something is true, then we know it's true), relations are complete - if things are related to each other, then we also know that they are related to each other.

### Converting ERDs to relational schemas

We have several heuristics for converting ERDs to relational schemas, but there isn't always a good way to.

When there is a one to many relation between doctors (`Doctor(DOCTOR_ID, ...)` in the ERD) and hospitals (`Hospital(HOSPITAL_ID, ...)` in the ERD), we might represent doctors in the relational schema as `Doctor(DOCTOR_ID, HOSPITAL_ID, ...)` - we added an attribute to doctors that specifies which hospital they work in, to represent this one-to-many relation. In general, when we have a many-to-one or one-to-one relation, we can add an attribute to one of the objects identifying the instance of the other object it's associated with.

When there is a many to many relation between students (`Student(STUDENT_ID, ...)`) and courses (`Course(COURSE_ID)`), we might add a new table for the relation `Taking(STUDENT_ID, COURSE_ID)`. In general, when we have a many-to-many relation, we can add a new table that associates them with each other, where the primary key is chosen from the attributes of the entity types it relates.

A **strong entity type** is one that has a primary key, while a **weak entity type** does not. Strong entity types dominate weak entity types when connected by a relationship. Strong entity types are directly translated to tables where the columns are their attributes. Weak entity types result in tables with their attributes as well, but also include the primary key of entity types that dominate it and the attributes of its relationships.



For specialization (is-a relationships), we have separate tables for the subclasses, and the superclass doesn't need a table. Also, the inherited attributes are written explicitly.

For aggregation, we create a separate table for the relationship if it doesn't exist, where the primary key is the primary key for the relationship.

### Constraints

Constraints limit the form of the data that can exist within the DBMS. Some constraints are inherent, such as the fact that there cannot be any duplicate rows, and how the prmary key, if it exists, cannot contain null values.

There are also other types of constraints:

* Domain constraints limit the values attributes can have to an explicit set of values.
* Primary key constraints limit the attributes used to identify rows.
* Foreign key constraints limit attribute values to valid references to other attributes.
    * In the above example, there would be a foreign key constraint on `Doctor` ensuring that its `HOSPITAL_ID` attribute is always a valid hospital ID, that there is a corresponding `Hospital` with that `HOSPITAL_ID` value.
    * Tuples in the relation containing the foreign key (the **referencing/child relation**) must have their foreign key attributes be the primary key of another relation (the **referenced/parent relation**), or null.
    * The DBMS only has to check whether the referenced record exists when inserting a new tuple into the child, or deleting a tuple from the parent.

# 9/10/15

Table definitions have the following form:

    "CREATE TABLE " <TABLE NAME> "("
        <COLUMN DEFINITION 1> ","
        <COLUMN DEFINITION 2> ","
        <...>
        <TABLE CONSTRAINT 1> ","
        <TABLE CONSTRAINT 2> ","
        <...>
    ");"

Table contraints take the following form:

    ["CONSTRAINT " <CONSTRAINT NAME>] (
        "UNIQUE" "(" <COLUMN 1> "," <COLUMN 2> "," <...> ")" |
        "PRIMARY KEY" "(" <COLUMN 1> "," <COLUMN 2> "," <...> ")" |
        "FOREIGN KEY" "(" <COLUMN 1> "," <COLUMN 2> "," <...> ")" "REFERENCES" <TABLE NAME> "(" <COLUMN> ")" ["ON" ("UPDATE" | "DELETE") ("SET NULL" | "NO ACTION" | "CASCADE" | SET DEFAULT)] |
    )

The `SET NULL` foreign key option sets broken references to null - when we delete the parent instance, the child reference becomes null. The `NO ACTION` option prevents the addition or deletion in the first place. The `CASCASE` option also deletes the child record when the referenced parent record is deleted. The `SET DEFAULT` option causes child reference's foreign key attribute to fall back to the default value set for the column.

Relational Algebra
------------------

**Operations** are functions of relations - they accept and return relations/tables. The basic operations are union ($A \cup B$), difference ($\setminus$), Cartesian product ($\times$), projection ($\pi$), selection ($\pi$), and renaming ($\rho$).

Relational algebra is the formal basis for modern relational models. It is the basis of SQL, the language used to query DBMSs. Relational algebra is important because it has the closure quality - operands and the results of operations are both in the set of relations.

Union of $A$ and $B$ is simply the set of those tuples that are in $A$ or $B$. Difference of $A$ and $B$ is simply the set of those tuples that are in $A$ but not $B$.

# 14/10/15

A **union** or **difference** of two relational schemes $R, S$ is the set union/difference of those sets. These are written as $R \cup S$ and $R - S$.

A **projection** of a relation scheme $R$ is a permutation of a subset of every tuple in $R$ - a table where the columns are the $R$'s columns rearranged or removed. This is written as $\pi_{A_{i_1}, \ldots, A_{i_m}}: R[A_1, \ldots, A_n] \to A_{i_1} \times \ldots \times A_{i_m}$.

Note that the resulting table for a projection may have duplicate records if $A_{i_1}, \ldots, A_{i_m}$ is not a candidate key.

A **selection** of a relation scheme $R$ is the set of tuples in $R$ that satisfy a boolean condition $F$ (where the expression allows attributes, constants, $\le, \ge, <, >, =, \ne, \wedge, \vee, \neg$ operators, and parentheses). This is written as $\sigma(R) = \set{t \in R \middle| F(t)}$.

The **Cartesian product** of two relational schemes $R, S$ is the set of all possible tuples formed by concatenating a tuple in $R$ with a tuple in $S$ - each tuple in $R$ prepended to each tuple in $S$. This is written as $R \times S$, and results in $\abs{R} \abs{S}$ tuples, which can be a lot if both relation schemes were large.

A **rename** of a relation scheme $R$ allows us to rename relation schemes and their attributes. This is written as $\rho_{S[B_1, \ldots, B_n]}(R[A_1, \ldots, A_n])$, which renames $R[A_1, \ldots, A_n]$ to $S[B_1, \ldots, B_n]$.

Basically, projection is a rearrangement of columns, selection is a filter for records, Cartesian product is a combination of records, and rename is simply a renaming.

A **relational algebra expression** is a finite expression of the following form:

* A variable or constant.
* $E_1 \cup E_2$, $E_1 - E_2$, $E_1 \times E_2$, $\sigma_F(E_1), \pi_S(E_1), \rho_S(E_1)$ where $E_1, E_2$ are relational algebra expressions.
* Other convenience operators, like $R * S = \sigma_{R \theta S}(R \times S)$, where $\theta$ is a comparison operator like $\ne$ or $\ge$ (a $\theta$-join).

Any language that provides at least the retrival power of relational algebra expressions is **relationally complete**. Relational algebra is a useful notation since we can analyze it using first order logic techniques, and allows analysis independent of the DBMS.

Relational queries are a subset of all computable queries, and represent real-world querying needs pretty well.