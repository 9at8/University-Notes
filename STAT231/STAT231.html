<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <title>STAT231 | Anthony Zhang</title>
  <link rel="stylesheet" href="../css/base.css" type="text/css">
  <link rel="stylesheet" href="../css/note.css" type="text/css">
  <link rel="stylesheet" href="../highlight/styles/default.css">
  <link rel="stylesheet" href="../highlight/styles/paraiso.light.css">
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body onload="highlight()">
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-68271407-1', 'auto');
    ga('send', 'pageview');

  </script>
  <h1>Lecture Notes by <a href="/">Anthony Zhang</a>.</h1>
  <ul class="site_links">
    <li><a href="/blog/" class="page">blog</a></li>
    <span class="divider"></span>
    <li><a href="http://uberi.github.io/University-Notes" class="page">notes</a></li>
    <span class="divider"></span>
    <li><a href="/resume.pdf" class="page">résumé</a></li>
    <span class="divider"></span>
    <li><a href="https://github.com/Uberi" class="contact">github</a></li>
    <span class="divider"></span>
    <li><a href="http://www.linkedin.com/pub/anthony-zhang/8b/aa5/7aa" class="contact">linkedin</a></li>
    <span class="divider"></span>
    <li><a href="mailto:azhang9@gmail.com" class="contact">email</a></li>
    <span class="divider"></span>
    <li><a href="https://www.facebook.com/anthony.zhang.user" class="contact">facebook</a></li>
    <span class="divider"></span>
    <li><a href="https://twitter.com/anthony926535" class="contact">twitter</a></li>
    <span class="divider"></span>
    <li><a href="/anthony-zhang.asc" class="info">GPG key</a></li>
  </ul>
<p><span class="math">\[
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1 \right\rceil}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}^P)}
\]</span></p>
<h1 id="stat231">STAT231</h1>
<p>Statistics.</p>
<pre><code>Surya Banerjee
Email: suryabanerje@gmail.com
Office Hours: Fridays 9am-11am, M3 2017, phone extension 39120</code></pre>
<h1 id="section">2/5/16</h1>
<p>There are 3 tutorial tests, 2 midterms, and a final exam.</p>
<p>In STAT230, we were given information about the population, and wanted to find the chance of a sample happening. In STAT231, we will be learning about the opposite - given information about a sample of the population, what can we figure out about the population? Where STAT230 asks, &quot;given 100 fair coin tosses, what is the probability of getting 60 heads?&quot;, STAT231 asks, &quot;if we toss a coin 100 times and get 60 heads, what can we say about the fairness of the coin?&quot;.</p>
<p>The Challenger space shuttle disaster occurred due to a failed O-ring. However, the right data analysis could have presented this tragedy - there was already enough data available to find this problem, but it wasn't looked at in the right way. Statistics can help prevent this sort of error.</p>
<p>Kansas weather reports, in a study, were found to be accurate about 85% of the time in predicting rain. However, if they just said &quot;it's not going to rain&quot;, they would be right 90% of the time. Likewise, ESPN pundits were found to correctly predict the results of games about 48% of the time. Statistics can help us evaluate which analysts and predictors are believable.</p>
<p>Statistics also allows us to evaluate relationships between two things. For example, does smoking cause lung cancer, or does lung cancer cause smoking? Are they related at all?</p>
<h2 id="statistical-data">Statistical data</h2>
<p>There are two main types of data:</p>
<ul>
<li><strong>Numeric data</strong>, like a grade or a width. Numerical data can be:
<ul>
<li><strong>Discrete</strong> - an element of a countably large set. For example, the number of pennies in a set of coins.</li>
<li><strong>Continuous</strong> - a measure, like height or weight.</li>
</ul></li>
<li><strong>Categorical data</strong> (area of study, name, etc.). Categorical data can be:
<ul>
<li><strong>Binary</strong> - falling into two categories.</li>
<li><strong>Ordinal</strong> - there are categories, but there is an underlying order to the data. For example, colors are categorical data, but they have an underlying order on the EM spectrum.</li>
</ul></li>
</ul>
<p>A <strong>transformation</strong> is a function over a variable. A <strong>linear transformation</strong> is one of the form <span class="math inline">\(y = mx = b\)</span>. A linear transformation is also known as an <strong>affine transformation</strong>.</p>
<p>A <strong>coding</strong> is a transformation that converts categorical data to numerical data. For example, colors can be assigned numbers, like 0 for red, 1 for orange, and so on.</p>
<h3 id="summaries">Summaries</h3>
<p>We often want to extract important information about a data set to find its properties. When we do so, we extract <strong>data summaries</strong>. We can do this <strong>numerically</strong> (like finding the mean, stddev, median, etc.) or <strong>graphically</strong> (like making a scatter plot). Numerical summaries tell us about certain fundamental properties of data sets, while graphical summaries tell us the shape of the data.</p>
<p>Common numerical summaries we care about are:</p>
<ul>
<li>The centre of the data, or <strong>central tendency</strong>:
<ul>
<li>The <strong>sample mean/arithmetic mean</strong>: for a variable <span class="math inline">\(y\)</span>, the sample mean is denoted <span class="math inline">\(\overline y = \frac 1 n \sum_{i = 0}^n y_i\)</span>.
<ul>
<li>The nice thing about this is that the sum of the deviations from the mean is always 0, so <span class="math inline">\(\sum (y_i - \overline y) = 0\)</span>.</li>
<li>Under an affine transformation <span class="math inline">\(y_i = ax_i + b\)</span>, <span class="math inline">\(\overline y = a \overline x + b\)</span> - the mean can simply be transformed as well.</li>
</ul></li>
<li>The <strong>geometric mean</strong> is better for logarithmically distributed data: for a variable <span class="math inline">\(y\)</span>, the geometric mean is denoted <span class="math inline">\(\overline y = \left(\prod_{i = 0}^n y_i\right)^{\frac 1 n}\)</span>.</li>
<li>The <strong>harmonic mean</strong> is rarely useful, and is the reciprocal of the arithmetic mean of the reciprocals of a variable.</li>
<li>The average is usually the one value that, if applied in the problem's situation, is equivalent to applying all the original values.</li>
<li>The <strong>median</strong> is the middle-most observation, or the sample mean of the middlemost observations if there are multiple. Essentially, we arrange the dataset in ascending order, and then pick the middle one.
<ul>
<li>The advantage of medians is that they are less sensitive to outliers than summaries like the sample mean.</li>
<li>The concept of the median can be extended to <strong>quartiles</strong> and <strong>percentiles</strong>. While the median is the value such that 50% of the dataset is below and 50% is above it, the quartiles and percentiles are a different fraction.</li>
<li>The first quartile is a value for which 25% of the data is below that value, while the second quartile is 50%, the third 75%, and the fourth 100%.</li>
<li>The first percentile is a value for which 1% of the data is below that value, while the second percentile is 2%, the third 3%, and so on.</li>
</ul></li>
<li>The <strong>mode</strong> is the observation or observations that occur most often (a dataset can have more than 1 mode). This is often more useful for categorical data, or discrete numerical data with only a few possibilities.</li>
</ul></li>
<li>The volatility, or <strong>dispersion</strong>:
<ul>
<li>The <strong>range of a dataset</strong> is two numbers - the minimum value of the dataset, and the maximum value. This can also be thought of as the zeroth and fourth quartile values.</li>
<li>The <strong>interquartile range</strong> (IQR) is the range of the middle 50% of the dataset - the first quartile value and third quartile value.</li>
<li>The <strong>sample variance</strong> is defined as <span class="math inline">\(s^2 = \frac{1}{n - 1} \sum_{i = 0}^n \right(y_i - \overline y\right)^2\)</span>. Note that the variance is <span class="math inline">\(s^2\)</span>, not <span class="math inline">\(s\)</span>. Also, the variance of a dataset <span class="math inline">\(x = \set{x_1, \ldots, x_n}\)</span>
<ul>
<li>This is almost, but not quite, the average of the squared deviation from the mean.</li>
<li>Basically, this measures how much the data is spread out from the mean.</li>
<li>There's a good reason to divide by <span class="math inline">\(n - 1\)</span> rather than <span class="math inline">\(n\)</span>, but we'll cover that later on.</li>
<li>Under an affine transformation <span class="math inline">\(y_i = ax_i + b\)</span>, <span class="math inline">\(s_y^2 = a^2 s_x^2\)</span> - the squared factor applies to the variance, but not the variance.</li>
<li>Another useful formula for the sample variance is <span class="math inline">\(s^2 = \frac 1 {n - 1} \sum y_i^2 - n(\overline y)^2\)</span></li>
</ul></li>
<li>The <strong>standard deviation</strong> is the positive square root of the sample variance, denoted <span class="math inline">\(s\)</span>.
<ul>
<li>Why do we square the deviations rather than just adding them up like <span class="math inline">\(\sum_{i = 0}^n (y_i - \overline y)\)</span>? The negative deviations and positive deviations would cancel each other out; squaring the values ensures that the standard deviation accumulates to a non-negative value.</li>
<li>Why do we square the deviations rather than adding their absolute values like <span class="math inline">\(\sum_{i = 0}^n \abs{y_i - \overline y}\)</span>? While the absolute value function would still represent variance (the given formula is called the <strong>mean absolute deviation</strong>), it's harder to work with since it's not differentiable. Also, the squared deviation is affected by outliers quadratically while the absolute deviation is only affected linearly, so taking its square root later would give unintuitive results.</li>
<li>Under an affine transformation <span class="math inline">\(y_i = ax_i + b\)</span>, <span class="math inline">\(s_y = a s_x\)</span> - the factor applies to the standard deviation, but not the intercept (this trivially follows from the formula for the sample variance).</li>
</ul></li>
<li>The <strong>mean absolute deviation</strong> is defined as $$</li>
</ul></li>
<li>How fat the tails are, or <strong>kurtosis</strong> (this can also be viewed at the frequency of extreme obserations).</li>
<li>How symmetric the data is about some point or axis, or <strong>symmetry</strong>.</li>
</ul>
<p>Suppose we have $100 in a bank account, with 4% interest the first year, 8% the second, and 12% the third. What is the average interest rate?</p>
<blockquote>
<p>Although it would seem at first glance to be 8%, the arithmetic mean doesn't represent the actual average here. The average interest rate is the single rate such that, after those 3 years, we would have the same interest gains as we did with this bank account.<br />
Let's denote this rate as <span class="math inline">\(x\)</span>. Then according to the interest formula, <span class="math inline">\(100(1 + x)^3 = 100 \cdot 1.04 \cdot 1.08 \cdot 1.12\)</span>.<br />
So <span class="math inline">\((1 + x)^3 = 1.257984\)</span> and <span class="math inline">\(x = 0.0795059\)</span>, or about 0.795%.<br />
As it turns out, this is basically the same thing as the geometric mean of the interest rates. In this case, we use the geometric mean since the interest is defined in terms of an enponential function of <span class="math inline">\(n\)</span>.</p>
</blockquote>
<p>A car drives from A to B at 40 km/h, and immediately drives back at 60 km/h. What is the average speed of the car?</p>
<blockquote>
<p>Although it would seem at first glance to be 50 km/h, this is not the case, since the car takes less time driving back since it's going faster.<br />
Let's denote the distance between A and B as <span class="math inline">\(x\)</span>, in km. Then the trip from A to B took <span class="math inline">\(\frac{x}{40}\)</span> hours, and the trip back took <span class="math inline">\(\frac{x}{60}\)</span> hours.<br />
Since the total time taken is <span class="math inline">\(\frac{x}{40} + \frac{x}{60}\)</span>, the average speed is <span class="math inline">\(\frac{40\frac{x}{40} + 60\frac{x}{60}}{\frac{x}{40} + \frac{x}{60}} = \frac{2}{\frac{1}{40} + \frac{1}{60}}\)</span>, or 48 km/h.<br />
As it turns out, this is the same thing as the harmonic mean of the speeds.</p>
</blockquote>
<h1 id="section-1">4/5/16</h1>
<p>To find a percentile <span class="math inline">\(\beta\)</span>, we sort the observations from low to high, and then take the value at the 1-indexed position <span class="math inline">\(\beta(n + 1)\)</span> (or the sample mean of the two values closest to the 1-indexed position <span class="math inline">\(\beta(n + 1)\)</span>).</p>
<p>The average/central tendency isn't always the only thing we care about. Suppose you flip a coin <span class="math inline">\(n\)</span> times before a heads appears. If you are paid <span class="math inline">\(2^n\)</span> dollars for doing so, at what price would you pay to play this game?</p>
<blockquote>
<p>Note that a head comes up on the first trial with 1/2 probability, paying out 2 dollars, on the second trial with 1/4 probability, paying out 4 dollars, and so on.<br />
So the expected value is <span class="math inline">\(\sum_{i = 1}^\infty i \frac 1 i = \infty\)</span> - the expected value is infinity!<br />
However, most people wouldn't even pay 40 dollars to play - it seems like risk/variability is also an important factor in deciding whether to play. This is called St. Peter's Paradox.</p>
</blockquote>
<p>Suppose we have a dataset <span class="math inline">\(x = \set{x_1, \ldots, x_n}\)</span>. Suppose we know one observation with value <span class="math inline">\(k\)</span> is unreliable, and we want to discard it from <span class="math inline">\(x\)</span>. Can we find the new mean and variance?</p>
<blockquote>
<p>Let <span class="math inline">\(y = \set{y_1, \ldots, y_{n - 1}}\)</span> be the dataset with the unreliable observation removed.<br />
Clearly, <span class="math inline">\(\sum y_i = \sum x_i - k\)</span>, since we removed only that one element, and since <span class="math inline">\(\sum x_i = n \overline x\)</span>, <span class="math inline">\(\sum y_i = \sum x_i - k\)</span>.<br />
So the sample mean is <span class="math inline">\(\overline y = \frac{\sum x_i - k}{n - 1}\)</span>.<br />
To find the variance, we can use the alternate form of the variance formula, so <span class="math inline">\(s_y^2 = \frac 1 {(n - 1) - 1} \sum y_i^2 - (n - 1)(\overline y)^2\)</span>.<br />
Clearly, <span class="math inline">\(\sum y_i^2 = \sum x_i^2 - k^2\)</span> and we already know <span class="math inline">\(\overline y\)</span> from the step above.<br />
So <span class="math inline">\(s_y^2 = \frac{1}{n - 2} \left(\sum x_i^2 - k^2\right) - \frac{\left(\sum x_i - k\right)^2}{n - 1}\)</span>.<br />
This same technique can be used to calculate the mean and variance of a dataset after adding or removing any number of items to it, without looking at the existing elements of the dataset.</p>
</blockquote>
<p>When you have a dataset with sample mean <span class="math inline">\(\overline x\)</span> and remove an item with value <span class="math inline">\(\overline x\)</span>, the mean stays the same, while the variance increases or stays the same.</p>
<p>The batting champion of a baseball season is the player with the highest batting average (probability of hitting the ball in each attempt, times 1000). However, although there have been 13 people with a batting average above 400 before 1941, there have been none after that year. Why does this happen?</p>
<p>In every sport, players have gotten better, absolutely speaking, over time - it doesn't seem like batters are actually getting worse. However, better pitchers, fielders, and managers can make a batter's job a lot harder.</p>
<p>We can actually test this by looking at the batting average for individual average batters over their careers. As it turns out, the average batter's batting average stays about the same over their career. However, the variance in the average player's ball hitting rate shrinks over their careers. Since the average is lower than 400, the shrinking variances mean that the tails in the batting average distribution shrink as well (causing fewer 400+ batting averages). When we become more consistent at hitting the ball at the average rate, that means there are fewer low-performers, but also fewer high-performers.</p>
<div class="license">
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a> This work by <a xmlns:cc="http://creativecommons.org/ns#" href="https://uberi.github.io/" property="cc:attributionName" rel="cc:attributionURL">Anthony Zhang</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  Copyright 2013-2014 Anthony Zhang.
</div>
<script type="text/javascript">
MathJax.Hub.Config({
  jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
  }
});
</script>
</body>
</html>