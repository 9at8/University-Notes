CS246
=====

Object-oriented development.

    Instructor: Nomair Naeem
    Office: DC 3548 (lab, by appointment), room B
    Email: nanaeem@uwaterloo.ca
    Website: https://www.student.cs.uwaterloo.ca/~cs246/
    TA: Richard Wallace, cs246@student.cs.uwaterloo.ca

$$
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}
\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}_P)}
$$

# 6/5/14

Five assignments, final assignment is worth more. Each assignment has two due dates - the first one we submit test cases, and the second is a week later and we submit code.

;wip: do assignment 0

This course focuses on object oriented programming and the tools and techniques of software development, with a specific focus on C++.

Linux Shell
-----------

The shell is an interface to the computer. The two main categories are graphical or command-line.

Graphical interfaces are easy to use, but makes it difficult to do complex tasks. They are available on almost every OS.

The command line accepts commands that are typed at the prompt. Windows has a DOS shell, while UNIX has a command line shell. It is possible to do more complex tasks with a command prompt, but it also has poor discoverability and a steep learning curve.

The first shell is Bourne shell, and then Cshell (and its descendent, Turbo shell) and Korn shell came along. Finally, there is Bourne Again Shell, or BASH. Bash is what we use in this course.

We can tell if a shell is Bash by the presence of the `$` before the input prompt. `echo $0` should print out the type of prompt, like "bash" or "sh".

# 8/5/14

Filesystem
----------

The Linux filesystem consists of programs, code, and data.

There are files and directories. Directories can contain other directories and files. The filesystem is similar to a tree. However, directories are simply another type of file.

Within a directory, filenames must be unique. Filenames are case sensitive. For example, we can have `/bin` and `/usr/bin`.

The filesystem is often thought of as a tree, where nodes represent files. A standard Linux installation will usually have the following structure:

* `/`
    * `bin`
        * `bash`
		* `ls`
		* `...`
	* `etc`
		* `shells`
		* `...`
	* `home`
		* `ahzhang`
			* `USER_FILES_GO_HERE`
		* `OTHER_USERS_GO_HERE`
	* `usr`
		* `bin`
		* `include`
		* `share`

### Relative/Absolute Paths

`/` is always the **root directory**. All paths must be relative to some reference path.

When we have a path relative to a fixed directory such as `/` or `/home`, this is an **absolute path**. For example, `/home/ahzhang/DropBox/School/Schedule.png`, or `~/DropBox/School/Schedule.png`.

Any other path is a **relative path**. What it actually is the path to depends on what it is relative to. For example, `bin/bash` could represent `/bin` or `/usr/bin`. How the path is resolved depends on the current/working directory.

The **current/working directory** is always available, and is the directory that all relative paths are relative to. For example, if the current working directory is `/home/ahzhang/DropBox/School`, then the relative path `Schedule.png` will resolve to `/home/ahzhang/DropBox/School/Schedule.png`.

The `pwd` (present working directory) command will display the current directory.

The `cd DIRECTORY_GOES_HERE` (change directory) command will change the current directory to `DIRECTORY_GOES_HERE`.

`.` is a special directory that always represents the current directory.

For example, `cd .` changes the current directory to the current directory, which does nothing.

`..` is a special directory that always represents the parent of the current directory.

For example, to change the current directory to the grandparent of the current directoy, we can use `cd ../..`.

`~` is a special directory that always represents the current user's home directory, like `/home/ahzhang`. This is an absolute path because it does not depend on the current directory.

For example, `cd ~` will change the current directory to the current directory. In fact, this is used so often that `cd` by itself will do the same as `cd ~`.

Also, `cd -` will change the current directory back to the last current directory - to the directory before we changed it with `cd DIRECTORY_GOES_HERE`.

`~USER_ID_GOES_HERE` is a special directory that always represents the home directory of the user `USER_ID_GOES_HERE`. This works as long as the referenced user has given permission to access it. This is an absolute path because it does not depend on the current directory.

Linux does not enforce the concept of file extensions. It is still followed by convention, however, since it is convenient.

### Globs

The `ls PATTERN_GOES_HERE` command will list the contents of `PATTERN_GOES_HERE`, or if not specified, then it lists the contents of the current directory.

It simply shows a list of information about the files in the directory.

This command does not show certain files - **dotfiles**. These are simply files/directories that have names that begin with a `.`. This is a convention that allows for somewhat hidden files, which are useful for things like configuration.

To show these files anyways, we can use `ls -a PATTERN_GOES_HERE`, which works the same way but also shows dotfiles.

The parameter given to `ls` does not have to simply be a path. It also supports **wildcards**. Wildcard patterns are known as **globbing patterns** or **globs**. In globs, `*` means match any one file or directory name, and `?` means match any one character of a file or directory name.

For example, `ls *.txt` lists all the text files in the current directory, and `ls pictures-??-??-??-*` matches all files of the form `pictures-TWO_DIGIT_NUMBER-TWO_DIGIT_NUMBER-TWO_DIGIT_NUMBER-ANYTHING`.

When we have a globbing pattern, the shell itself actually does the matching, not the command (like `ls`). The shell matches all the files, then passes all the matched files on the command line. The advantage of this approach is that each command does not have to implement globbing itself.

Globs are matched relative to the current directory.

Also, `rm PATTERN_GOES_HERE` removes all files matching `PATTERN_GOES_HERE`.

We can even do things like `echo *.txt`, which will print out all the text files in the current directory. Hwoever, to literally print `*.txt`, we simply use quotes, like `echo '*.txt'` or `echo "*.txt"`.

Also, globbing patterns do not work inside quotes - they must appear directly.

### File Operations

Also, if a command is taking too long, then we can use `Ctrl + C` to kill it. This is often written as `^C`. There is also `Ctrl + D`, which sends the end-of-file symbol to the program, which allows it to gracefully terminate.

The `cat PATTERN_GOES_HERE` (concatenate) command is an extremely commonly used command that simply prints out the contents of all given files.

If the pattern is not specified, so we used `cat`, then the input is taken from the standard input. If we type some words, they will be pritned out again at the standard output. This continues until we stop the command using `^D` or similar. This mode is useful if we can capture the output somewhere.

All files given to `cat` are concatenated together. Running `cat A.txt B.txt` outputs the value of both files right after one another.

### Input/Output Redirection

The `COMMAND>FILE` operator redirects the standard output of `COMMAND` into the file `FILE`, overwriting any existing contents of the file. For example, `cat > entered_text.txt` allows the user to type in some text and have it saved to `entered_text.txt`

The `COMMAND<FILE` operator redirects the standard input of `COMMAND` to the file `FILE`, so it is almost as if it was typed directly as input. For example, `cat < input.txt` will display the contents of `input.txt` on the screen.

`cat FILE` is exactly equivalent to `cat < FILE`.

The `wc FILE` command counts the number of lines, words, or characters in a given file, or in the standard output if not specified. For example, `wc test.txt` gives `LINE_COUNT WORD_COUNT CHARACTER_COUNT FILE`.

However, `wc < FILE` gives `LINE_COUNT WORD_COUNT CHARACTER_COUNT` - there is no `FILE` in the output since it is simply given from the standard input.

Every process has a standard input (stdin) and output (stdout) - the default place to get input and print output. The standard input is usually connected to the keyboard and the standard output is usually connected to the screen.

Input redirection changes stdin, and output redirection changed stdout.

Standard output is **buffered** - characters to be sent to the output are stored up until there is a large enough amount to send to the screen. This sending process is known as **flushing** the buffer.

Every process also has a standard error (stderr) - the default place to print out errors. This is intended to avoid cluttering the output. Also, stderr is not buffered - all errors will show up right away, not whenever the buffers are flushed.

We can redirect stderr using `2>`, in a way similar to `>`.

We can also do all types of redirection at the same time: `cat < input.txt > output.txt 2> error.txt` reads the contents of `input.txt` and then writes it to `output.txt`, and any errors are written to `error.txt`.

There are also **pipes**, which allow the output of one program to become the input of another. `COMMAND_A|COMMAND_B` connects the stdout of `COMMAND_A` to the stdin of `COMMAND_B`.

# 13/5/14

The `head -NUMBER_OF_LINES FILE` command will read the first `NUMBER_OF_LINES` lines from `FILE`. If `FILE` is not specified, the lines are read from stdin.

So if we wanted to get the number of words in the first 20 lines of `sample.txt`, we might use `cat sample.txt | head -20 | wc -w` or simply `head -20 sample.txt | wc -w`.

The `uniq` command removes duplicate lines, but **only if they occur next to each other** - only adjacent duplicates are removed. It is therefore often used together with the `sort` command, which sorts its input by lines.

It is also possible to send the output of a program as a parameter to another program, using the backquotes/backticks notation. For example, `echo "Today is \`date\` and I am \`whoami\`"` might display something like `Today is Tue May 13 08:50:24 EDT 2014 and I am Anthony`.

The shell will first evaluate the command in the backquotes, substitute its output for it, and then execute the original command. This works even if the parameter is inside quotes, as in the example above. An alternative syntax is `$(COMMAND)` instead of `\`COMMAND\``, which is slightly easier to read. This is often used to format strings.

We now want to search inside text files. For this we can use `grep PATTERN FILE` or `egrep PATTERN FILE` (recommended, equivalent to `grep -E`). This prints out every line in `FILE` that contains `PATTERN`. Here, `PATTERN` is an extended regular expression. If `FILE` is not specified, input is taken from the standard input.

### Regular Expressions

Regular expressions are concise ways to express a set of strings, which may possibly be arbitrarily large. For example, `a?b?c?` denotes the set containing the strings "", "c", "b", "bc", "a", "ac", "ab", and "abc".

Regular expressions consist of characters and operators. Characters like "e" and "5" simply denote themselves in the set. Operators like `*` modify strings with operations like "zero or more of the preceding".

For example, `a*` matches zero or more "a" instances, like "" and "aaaaaaaaaaaaaaaaaaaaaaaaa". It denotes the set of all strings consisting entirely of "a" and the empty string.

So to match either "CS246" or "cs246", we might use `egrep "CS246|cs246"` (the quotes are necessary because otherwise it is a pipe), or simply `egrep "(CS|cs)246"`. Alternatively, to do it without case sensitivity we might use `egrep [cC][sS]246`. The `[...]` operation is called a character class, and matches one of the characters inside it. Also, the `[^...]` matches anything that is not one of the characters inside it.

`?` means "zero or one of the preceding". So `egrep (abc)?d?` matches "", "abc", "d", and "abcd". `*` means "zero or more of the preceding", while `+` means "one or more of the preceding".

`{A, B}` means "between `A` and `B` inclusive of the preceding". If `B` is blank, then it is assumed to be infinity. Clearly, `?
 is equivalent to `{0, 1}` and `+` is equivalent to `{1,}`.
 
`.` means "any character". For example, `egrep ...` will match any three characters. `^` matches the beginning of a line, and `$` matches the end.

For example, to list all files in the current directory with exactly one "a", we might use `ls | egrep "^[^a]*a[^a]*$"`.

# 15/5/14

Permissions
-----------

`ls -l` displays more information about files, such as the owner and permissions.

For example, `ls -l` might give `-rwxr--r-- 1 nanaeem staff 11K 2014-05-12 20:27 index.shtml`.

`2014-05-12 20:27` is the last date/time the file was modified. `11K` is the file size, `staff` is the group, `nanaeem` is the owner, `1` (the first one) is the number of links, `rwxr--r--` is the permissions, and `-` (the first one) is the file type (`d` for directory, `-` for file).

Groups facilitate sharing of files. Every file belongs to one group, and users can belong to multiple groups (this can be listed using the `groups` command). To share files, all involved users must be in the same group.

The permissions are simply 3 groups of 3 letters, with 9 letters in total. Each letter is either `-` or an alphabetical character, and represents a binary bit. The groups are:

1. User bits: three bits that determine what permissions the owner of the file has
2. Group bits: three bits that determine what permissions the members of the file's group has.
3. Other bits: three bits that determine what permissions everyone else has.

The first letter (bit) of each group is the read bit, and is `r` if set, or `-` otherwise. If set, we would be able to read the file, or if it is a directory, we can list its contents.

The second letter (bit) of each group is the write bit, and is `w` if set, or `-` otherwise. If set, we would be able to modify the file contents, or if it is a directory, we can add or remove files.

The third letter (bit) of each group is the execute bit, and is `x` if set, or `` otherwise. If set, we would be able to execute the file like a program, or if it is a directory, we can navigate into it, like with `cd`.

So if a file has execute but not read permissions, then we could go into it but not list its contents. But if we happen to know one of the file paths, we can still access that file by path.

### Changing Permissions

Only the owner of a file can change its permissions. It is not possible to give this ability to anyone else, and it is always possible for the owner to change permissions.

We do this using the `chmod MODE FILE`. `MODE` is a string of the form `OWNERSHIP_CLASS OPERATOR PERMISSIONS`, with no spaces.

`OWNERSHIP_CLASS` is the set of bits to apply the operations to. This value can be `u` for the user/owner bits, `g` for the group bits, `o` for the other bits, and `a` for all bits.

`OPERATOR` is an operation to perform with the permissions. This value can be `+` for adding a permission, `-` for removing a permission, or `=` to clear all the permissions and add the new one (set the permissions exactly).

`PERMISSIONS` is simply the permissions to be modified. This value is a string consisting of the characters `r` for read, `w` for write, and `x` for execute.

`FILE` is the file that the permission changes should apply to.

For example `chmod o+r sample.txt` gives the owner permission to read `sample.txt`.

Shell Scripting
---------------

### Variables

In Bash, we can set variables using things like `x=1` or `x=" a b c "`. It is important that **there are no spaces around the equal sign**. If there are, the shell would interpret the `x` or `1` as a command.

We can display the value of the variable using something like `echo $x`.

When we want to set a variable's value, we simply write the variable name.

When we want to get the value of the variable, we prefix it with a `$`, like `$x`. It is good practice to enclose the name with curly brackets: `${x}`. This can 

Variables are expanded by the shell before the current command is executed. Variables are expanded when they appear directly, or inside double quotes. Inside single quotes, variables are not expanded. For example, `echo $VAR` and `echo "$VAR"` print out the value of `VAR`, but `echo '$VAR'` will literally print out, "$VAR".

One of the most commonly used shell variables is `PATH`. This variable is a colon-separated list of paths that are searched in order when trying to execute a file. For example, if we execute `ls`, the shell will go through the paths specified in `PATH` one by one, looking for the `ls` program. If found, it stops searching, and otherwise an error is raised. This is essentially the list of places we should search for when we try to run a program specified by a relative path.

### Scripts

Bash scripts are files that contain a sequence of Bash commands that can be executed as a program.

For example, if we want to print out the date, current user, and current directory, we might write in the `script` file:

    #!/bin/bash
	date
	whoami
	pwd

The `#!/bin/bash` specifies that this file should be run with the `/bin/bash` program. `#` is often called "hash" and `!` is often called "bang", so this type of line is often called the hashbang or shebang. This must be the first line and should not have any spaces before it.

Single-line comments are begun with `#`, which causes the rest of the line to be ignored. Therefore, the shebang line is actually just a comment to Bash.

Often the current directory is not in the `PATH` variable. That means that if we try to run `script` Bash will not find it in `PATH` and will not run the script. Instead, we often specify a full path using `./script`, which is a fully given path - there is no need to search through `PATH` to resolve it because it is explicitly stated to be in the current directory. It is also possible to add `.` to the `PATH` variable to be able to directly run programs from the current directory.

A shell script must have execute permissions to be run. This can be done using something like `chmod a+x script`

Shell scripts can read command line arguments using the special shell variables `$1`, `$2`, and etc., where `$0` contains the command line itself, "script".

For example, a shell script that checks if a word is in a dictionary can be written with a hashbang and `egrep "^$1$" /usr/share/dict/words`.

`/dev/null` is a file that can be written to, but simply discards whatever is written. Redirecting output to `/dev/null` means we are discarding the output.

If we want to check something like whether `egrep` matched something, we can use the exit code. The **exit code** is the value that we returned from the `main` function in C programs.

By convention, 0 indicates success, and a non-zero value indicates some sort of failure. In Bash, the last exit code given by a program is stored in the special shell variable `$?`.

In the above example, `egrep` gives exit code 1 if no matches were found and 0 otherwise:

    egrep "^$1$" /usr/share/dict/words
    if [ $? -eq 0 ]; then
        echo Not a good password
    else
        echo Maybe a good password
    fi

The spaces between `[`, `$?`, `-eq`, `0`, and `]` are all required. The body must be on its own line.

`$#` is another special shell variable, which always contains the number of command line arguments passed in. It is 0 if none were given - the `$0` variable does not count.

`if` is a Bash construct that takes the form `if PROGRAM; then BODY else BODY fi`. The first body is executed if the status code is 0, and otherwise the second one is executed.

In our example, the status code is compared against 0, and a different message is displayed depending on whether the comparison succeeded. We could also use `if egrep "^$1$" /usr/share/dict/words; then` instead since the exit code follows the right pattern.

The general pattern is as follows, with zero or any number of `elif` statements:

    if [ CONDITION ]; then
        BODY
    elif [ CONDITION ]; then
        BODY
    else
        BODY
    fi

When we used it in the form above, we actually executed the `[` program with the value of `$?`, `-eq`, and `0`, which sets the exit code to 0 if the expression evaluates to true (`$?` is equal to `0`), or 1 otherwise. This happens to work very well with the `if` construct.

`-eq` is an operator for comparing integers. To compare strings, we can use `==` or `=`.

We can have as many `elif` statements as we need.

A `while` loop statement has a similar form to an `if` statement. The following prints out all the numbers from 1 to its first command line argument, inclusive:

    x=1
    while [ $x -le $1 ]; do
        echo $x
        x=$((x+1))
    done

`$((...))` performs arithmetic by evaluating `...` as an expression.

Functions in Bash have the following form:

    usage() {
        echo "Usage: $0 [[password]]"
    }

We often want to validate user input to ensure that we are working with valid data. We can do that by having something like the following near the beginning of the script:

    if [ $# -ne 1 ]; then
        usage
        exit 1
    fi

# 20/5/14

A `for` loop statement iterates over a given series. It has the following form:

    for name in *.cpp; do
        mv $name ${name%cpp}cc
    done

Here, `name` is the name of the variable to store the current item in the series. The `*.cpp` is a globbing pattern that gets expanded into a series. `${name%cpp}` means the ending `cpp` should be removed.

The basic form is `for x in a b c ...; do statements; done`. This executes `statements` for each value of `a b c ...`, where `x` stores the current value.

To iterate over words in a file, we can use `for word in $(cat $file)`.

When we have a variable with a space in it, like `x="a b c"`, when we do something like `cat $x` we are actually passing in 3 arguments, `a`, `b`, and `c`. When we want to handle user input, it is usually a good idea to put the input variables in double quotes. In the above example, we change it to `cat "$x"` and it will attempt to read the file "a b c".

Testing
-------

The goal of testing is to improve code quality. Testing is the process of trying various inputs on a program to catch errors in the output and verify seemingly correct programs are actually correct.

It is recommended that we write tests before beginning the coding process.

Guidelines for functional testing (testing the functionality of a program):

* Aim to have tests that check every different control flow path.
* Check ranges of inputs, like typical negative/positive values.
* Check boundaries at the edge of ranges, such as 0 and big numbers for integers, and also check combinations of boundaries, like testing the boundaries of two inputs at once.

Regression testing is testing used to detect regressions - old bugs reintroduced into the code. We basically rerun all the old test cases again on the new code to ensure the new code does not break the old code.

Basic C++
---------

Invented by Bjarne Stroustrup (Byarne Stroostrup) in the 1980s, intended to bring some object oriented features into C.

C++ is based in C first and foremost. Many valid C programs are also valid C++ programs. This course will assume a level of proficiency developed with C over the course of CS136.

The current standard is C++11, which was introduced in 2011 and added many sophisticated language constructs like anonymous functions. However, support is not perfect, and C++03 is still widely used.

C++ source files often have the `*.cc` or `*.cpp` extension.

A basic C++ program might look like the following:

    #include <iostream> // we do not have to specify the .h extension for header files
    using namespace std; // this puts the std namespace into the global namespace, so std::cout is the same as cout; without this line we have to use std::cout and std::endl
    int main() { // the main function must be declared to return an integer, and for this funciton only it is not required to actually use a `return` statement (defaults to `return 0`)
        cout << "Hello, world!" << endl;
    }

The syntax is similar to C. `cout` is the standard output stream, and `endl` is a constant representing the end of line (a newline on Linux, and a carriage return with a newline on Windows).

The `iostream` library has 3 main input/output (I/O) objects: `cout` representing standard output, `cerr` representing standard error, and `cin` representing standard input.

The `<<` is an output operator - the "put to" operator. It sends the right operand to the stream specified by the left operand, producing the stream again. For example, `cout << x` puts `x` to stdout.

The `>>` is an input operator - the "get from" operator. It reads data from the stream specified by the left operand into the right operand, producing the stream again. For example, `cin >> x` gets `x` from stdin.

`stdio.h` and such are still available, but should not be used because C++ has its own equivalent functionality and libraries. Marmoset will be forbidding these libraries from being used.

### Compiling

We will be using g++, the equivalent of GCC for C++. A typical invocation might look like `g++ myprogram.cpp -o output`, where `myprogram.cpp` is the name of the source file and `output` is the executable (if not specified, defaults to `a.out`).

The following is a program that takes two numbers and adds them:

    #include <iostream>
    int main() {
        int x, y;
        cin >> x >> y;
        cout << x + y << endl;
    }

Note that `cin` waits for an integer because the right side is an integer. This is an example of overloading. `cin` will always ignore whitespace and newlines when doing this.

### Input/Output

If we type in some invalid input like `4 potato` to the above program or give an EOF, the variables are either uninitialized or set to 0 or other behaviour.

# 22/5/14

How do we check if the input given was invalid - if the read was successful? `cin.fail()` is true if and only if the most recent read failed (invalid or EOF). Likewise, `cin.eof()` is true if and only if the most recent read got to the end of the input.

We must attempt to do the reading, and if it fails, then we handle the error condition. Also, if there is an error, the failure flag stays set until we acknowledge it, and until then all subsequent reads do nothing. Upon error, the stream is not advanced and a second read will try to read the same thing.

Program that reads integers and prints them until a non-integer or EOF is encountered:

    #include <iostream>
    using namespace std;
    int main() {
        int i;
        while (true) {
            cin >> i;
            if (cin.fail()) break;
            cout << i << endl;
        }
    }

When we say `if (!cin)`, `cin` is implicitly converted into a `void*`, and is truthy if the last read was successful and falsy otherwise. `if (cin)` is equivalent to `if (!cin.fail())`.

Also, `std::cin >> i` evaluates to `std::cin`, which allows us to do things like `cin >> x >> y`. This technique is known as **cascading**. The same thing works with the `<<` operator as well, which we saw in the `cout << i << endl` line.

Note that `a >> b` is also the right bit-shift operator, equivalent to `\floor{\frac a {2^b}}`. This operator **behaes differently depending on its operands**. If the left side is an IStream such as `std::cin`, it acts as the input operator, and if the left side is an int, it acts as a right bit-shift.

With this in mind, we can have the following shorter version:

    #include <iostream>
    using namespace std;
    int main() {
        int i;
        while (cin >> i) cout << i << endl;
    }

Another one that ignores non-integers and echos integers until encountering EOF:

    // the `#include <iostream>` and `using namespace std;` are implicit for brevity
    int main() {
        int i;
        while (true) {
            if (cin >> i) cout << i << endl;
            else {
                if (cin.eof()) break;
                cin.clear(); // acknowedge that the previous read failed and reset cin so we can read again
                cin.ignore(); // ignore the next input (character) so we don't read the same invalid value over and over again
            }
        }
    }

### Strings

In C++, strings are significantly easier to use than in C. We use the type `std::string`, and literals are denoted with double quotes (`"string"`):

    int main() {
        std::string s;
        std::cin << s;
        std::cout << s << endl;
    }

When we try to read a string from stdin, it first ignores all leading whitespace, stores non-whitespace characters in the variable, and stops at the first whitespace character encountered. As a result, it will only read one word at a time.

To actually get the entire line, we can use `getline(cin, s)`. The type of data and the exact reading/writing behavior of `cin` or `cout` depends on the type of the right operand of `>>`.

However, if we wanted to use format specifiers (like those accepted by `printf` in C), like printing out integers in hexadecimal or octal, we can I/O Manipulators.

I/O Manipulators look like `std::cout << std::hex`. This does not print anything, but it changes the behaviour of `cout` so that it prints integers out in hexadecimal. Likewise, `std::cout << std::dec` changes `cout` to print integers out in decimal again. There are many other manipulators but these are one of the most common ones.

The advantage of using streams for things like `cin` and `cout` is that it abstracts more than just stdin and stdout. All the behaviour associated with stdin and stdout can also be used to other stream-like data such as a file or even on a network connection.

To use file streams, we must have `#include <fstream>` to have the file stream functionality. It provides `ifstream` for input file streams and `ofstream` for output file streams. The following prompts the user for a word and writes it to a file:

    #include <iostream>
    #include <fstream>
    using namespace std;
    int main() {
        ifstream f("test.txt"); // declare an `ifstream` initialized with "test.txt"
        string s;
        f << "Word: " << endl;
        cin >> s;
        f << s << endl;
    }

Note that we didn't have to close the file - C++ automatically closes it after we are done using it.

Also, `str.length()` gets the length of the string `str`.

# 27/5/14

In C++, when we have a function that accepts arguments, we can also make an argument optional, and give it a default value when none is specified:

    // default values can be given in the declaration or definition
    void printSuiteFile(int max, string filename = "suite.txt") { // arbitrary numbers of optional parameters can appear after the required parameters
        ifstream suite(filename.c_str()); // we have to convert it to a C style string because that's the only thing `ifstream` accepts
    }
    int main() {
        printSuiteFile(5); // no argument specified, default value used
        printSuiteFile(3, "something.txt"); // "something.txt" specified, default value ignored
    }

**Function overloading** allows us to have functions with multiple definitions, each with unique signatures. C++ will look at the different signatures, and match each function call with the right definition:

    int negate(int a) { return -a; }
    bool negate(bool a) { return !a; }
    negate(5); // calls the first one
    negate(true); // calls the second one

The signatures are matched based on the function name, the number of arguments, and the type of the arguments. There can only be one definition for a given combination of function name and argument types. Notice that the signature does not include the return type - a signature is something like `f(int x)`, not `int f(int x)`.

It is also possible to do **operator overloading**. For example, `cin >> INTEGER_VAR` reads an integer while `cin >> STRING_VAR` reads a string - the `>>` operator is overloaded to read input from streams, as well as the right bit shift operator on integers.

A declaration asserts the existance of an entity. A definition is the actual implementation of an entity. A definition must necessarily require a declaration. Declarations can be repeated as many times as we want, but there can only be one definition per entity.

Strings
-------

We can also do I/O on strings using streams, using the `sstream` library:

    #include <sstream>
    int main() {
        std::string value = "2 5";
        istringstream input(value); // string reader
        ostringstream output; // string writer
        output << "Enter a number between " << low << " and " << high;
        int low, high; input >> low, input >> high;
        std::string result = output.str();
    }

Note that we didn't have to use `clear` on the output stream, because although the failure flag was raised, we are simply making new streams every iteration of the loop.

The string writer is useful for formatting text and converting numbers to strings. The string reader is useful for converting strings to numbers. When using string readers, it is important that we handle EOF.

In C, strings were null-terminated char arrays that we had to do memory management on manually and were prone to buffer overruns. In C++, strings are part of the standard library, manage their own memory, and are much less prone to buffer overruns.

Consider `string s = "hello";`. `"hello"` is simply a char array with a null terminator, while `string` is a C++ string. C++ implicitly converts C-style strings into C++ strings (instances of `std::string`).

However, C++ strings are not implicitly converted into C style strings. This becomes necessary for things like `ifstream`, which only accepts a C string for the file name. We can explicitly convert the C++ string into C style using `s.c_str()`.

In C, we used `strcmp(a, b)` to compare strings, while `a == b` only compared pointers. In C++, we can simply use `a == b` or `a != b` to compare strings.

We can also still use the `s[i]` notation that we can use in C. To concatenate two strings, we can use `a + b` instead of `strcat(a, b)`.

# 29/5/14

The reason structure declarations need a semicolon at the end is because we can actually declare variables right after:

    struct Node {
        int data;
        Node *next; // the `struct` is not necessary
        // ...
    } node_var1, node_var2, *pointer_to_node;
    // now `node_var1`, `node_var2`, and `pointer_to_node` are defined
    Node node_var3;

In C++, we can also simply write `Node` instead of `struct Node` in all contexts, except the declaration itself.

When we read type declarations, we start from the identifier and work outwards. For example, `int * const p` is a constant pointer to an integer, and `const int *p` is a pointer to a constant integer.

When we use an operator like `A << B`, this is calling a function called `operator<<` with two arguments `A` and `B`.

    void inc1(int n) { n ++; }
    void inc2(int *n) { (*n) ++; }
    void inc3(int &n) { n ++; } // here, `n` is a reference to `x`, because `x` is now being passed by reference
    int main() {
        int x = 5;
        inc1(x); // this does nothing because the argument is passed by value
        inc2(&x); // this works because we are passing an address by value, but requires special syntax
        inc3(x); // now we are passing a reference to `x` rather than the value
        cout << x << endl;
    }

References
----------

C++ also has another pointer-like type, the **reference**:

    int y = 10;
    int &z = y;

This means that "`z` is a reference to `y`". This means that `z` is a constant pointer to `y`, but with automatic dereferencing. So whenever we write `z`, it actually means "the value pointed to by `z`", so `y` in this case. Therefore, writing `z` is equivalent to writing `y` - it has no identity of its own.

So `int *p = &z` makes `p` point to `y` and `z = 5` sets `y` to 5. Also, `sizeof(z)` is simply the size of `y`. References are more or less exactly the same as writing the variable itself - they are aliases.

References cannot be left uninitialized because they are actually constant pointers. Also, they must be initialized to something that has an address (an lvalue), so we can't do `int &z = 5`.

We cannot create a pointer to a reference itself (`int &*p = ...;`), only the lvalue it refers to (`int *p = &z`), but we can create a reference to a pointer (`int *&p = q;` after `int *q;`). However, we cannot create a reference to an array (`int &x[] = {1, 2, 3}`).

`cin` actually uses references to support things like `cin >> x`: `istream &operator>>(istream &in, int &data)`. Here, `istream in` is `cin` and `data` is a reference to `x`. Both are being taken by reference because both are modified by reading. We return a reference because we don't want to copy the `istream` instances.

References are often used for arguments and return values in order to avoid copies (when copying is an expensive operation, like copying a big struct, or simply not possible, like an `istream`) and allow modification of the lvalue they refer to.

When we have `int f(int x) { ... }` and we run `f(n)`, a copy of `n` is created and in `f`, `x` refers to that copy (this is why `n` is not modified).

# 3/6/14

An array is a set of homogenous values.

Arguments in C++ are passed by value, but we can fake passing by reference by using reference types.

Functions in C++ accept arrays in much the same way as in C: `int f(int a[])`.

THe `main` function has two possible prototypes:

    int main(); // note that we didn't need to use void
    int main( int argc, char *argv[] );

If we use the second form, `argc` is the length of `argv`, and `argv` is an array of strings representing each command line argument. `argc` is always non-zero, since there is always at least one argument.

The first element of `argv` is the name of the current program that is running. For example, `./a.out`.

Preprocessor
------------

The **preprocessor** changes the code before it actually gets to the compiler. It can do several types of manipulations to source code files.

The preprocessor can be used for many possible things, but is mainly used for substitution, file inclusion, and conditional inclusion.

The preprocessor is controlled via preprocessor directives. These are just lines that start with `#NAME_OF_DIRECTIVE` with no preceding whitespace, and are followed by the arguments to the directive.

The `#define VARIABLE ...` directive replaces all instances of `VARIABLE` with `...`, where `...` can be anything. To represent multiple lines, use a backslash at the end of the line. The `-DVARIABLE="..."` command line flag to `g++` accomplishes the same purpose.

That said, don't use `#define` whenever possible. For enumerations, use `enum`, and for functions that need to be fast, use the `inline` keyword to automatically inline the function: `RETURN_TYPE inline NAME(...)`.

The `#include` directive works much line in C, but for standard library paths we can drop the `.h` suffix - it is `#include <iostream>` rather than `#include <iostream.h>`.

The `#if EXPRESSION` directive and its corresponding `#else` and `#elseif EXPRESSION` and `#endif` operator allow us to include code depending on the value of `EXPRESSION`. `EXPRESSION` supports all of the operators as C++ source code, but the operands must be integers or characters.

The `cassert` library adds assertions, much like those in C. After using `#include <cassert>`, the `assert(EXPRESSION)` or `assert(DESCRIPTION_STRING, EXPRESSION)` function can be used.