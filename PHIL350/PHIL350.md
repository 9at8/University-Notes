PHIL350
=======

Theories of Knowledge.

    Wesley Buckwalter
    Section 001
    Office hours: Monday, Wednesday 2:30 PM-3:30 PM, Hagey Hall 325

$$
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\tup}[1]{\left\langle #1 \right\rangle}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\rem}{\operatorname{rem}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\imag}{\boldsymbol{i}}
\newcommand{\dee}{\mathop{}\!\mathrm{d}}
\newcommand{\lH}{\overset{\text{l'H}}{=}}
\newcommand{\evalat}[1]{\left.\left(#1\right)\right|}
\newcommand{\sech}{\operatorname{sech}}
\newcommand{\spn}{\operatorname{Span}}
\newcommand{\proj}{\operatorname{proj}}
\newcommand{\prp}{\operatorname{perp}}\newcommand{\refl}{\operatorname{refl}}
\newcommand{\magn}[1]{\left\lVert #1 \right\rVert}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\sys}[2]{\left[ #1 \mid #2\hskip2pt \right]}
\newcommand{\range}{\operatorname{Range}}
\newcommand{\adj}{\operatorname{adj}}
\newcommand{\cof}{\operatorname{cof}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\formlp}{\operatorname{Form}(\mathcal{L}^P)}
$$

# 14/9/15

Articles are all posted on LEARN. Articles marked with "(M)" are for the Monday class, and "(W)" are for the Wednesday class - make sure to read these before class.

Best contact method is emailing wesleybuckwalter@gmail.com with "PHIL 350" in the subject.

Epistemology is the study of knowledge.

Epistemology courses often focus on very abstract, disconnected concepts. This course focuses on the more practical, concrete aspects of modern epistemology - the study of what we know and how we know it, and what we think other people believe or know.

Knowledge tells us how to act, who to trust, which beliefs to form, and how to act virtuously. One good example of the importance of epistemology is in the law - the knowledge and beliefs of the defendant has a significant impact on the proceedings. A defendant that does something unknowingly will be treated differently from one that acts knowingly.

In the law, **ignorance** is not knowing something, and not knowing that one doesn't know. **Willful ignorance** is not knowing something, knowing that one doesn't know, and intentionally avoiding knowing it. Knowledge is awareness and strong belief.

# 16/9/15

Readings: Quine, Kim

Naturalized and Normalized Epistemology
---------------------------------------

Willard Van Orman Quine proposed **naturalized epistemology**, in opposition to "old philosophy". In "Epistemology naturalized", Quine complains about various writings about old epistemology. For example, pragmatically speaking if Descartes doubts the senses then all the sciences are suspect - doubting the senses doesn't leave us with anything practical.

According to Quine, old epistemology views itself as superior to and justifying the existance of science, allowing us to rationally generate discoveries. Additionally, old epistemology cares only about certainty, the things that must be true beyond all doubt (the foundationalist view).

Quine criticizes Descartes' arguments by asking where the guarantee of truth comes from. The commonly accepted answer is that the definition of the words themselves mean that the conclusion follows. Quine then asks where the meanings of words come from, to which it is generally agreed that it is simply convention.

Circular arguments are those that assume what they're trying to prove, and circularity is generally considered a negative feature of science.

In old epistemology, we cannot say we have knowledge until we have certainty. However, certainty is only guaranteed by subjective experiences, valid deductive arguments, and the meaning of words. However, science is based on inductive arguments and observation. Epistemology justifies science, but we actually need to assume things happen in order for science to explain them. Quine criticizes this as being circular - "the world exists because the world exists".

The inductive arguments that are so essential to science cannot give us certain knowledge. To justify this, David Hume adds the key assumption known as the **Principle of the Uniformity of Nature** - that the future will resemble the past. Hume justifies this inductively, by saying that the future has resembled the past in the past, so the future will resemble the past in the future. However, this is obviously a circular argument. According to Quine, **circularity is unavoidable in epistemology**, and maybe that's just fine.

Quine is essentially criticizing that superiority of old epistemology to science, its reliance on certain knowledge, and its avoidance of circularity. In Quine's naturalized epistemology, science comes first, and **epistemology is a branch of science**, specifically related to cognitive science and psychology. Here, the new goal of epistemology is to understand how science and our practices of science actually work, rather than justifying the existance of science.

Additionally, science is the best way of getting information about the world, so we might as well use science to study science. It is circular to some extent, but this is fine since we no longer care about certainty. It is circular, but not in a way that blocks progress - progress can be made without certainty, through incrementally gaining confidence in our fallible beliefs as we obtain more discoveries and scrutinize our beliefs publicly.

Kim's criticism of Quine's naturalized epistemology starts off by agreeing with Quine's criticism of old epistemology - that naturalized epistemology cannot replace old esptemology. According to naturalized epistemology, individuals accept senses asinput and output beliefs. However, Kim says that there is more to believing and knowing things.

Kim says that the central tenet of epistemology is justification, that epistemologists actually catre about how justified beliefs are formed. In other words, justification is normative, while science is descriptive, so naturalized epistemology cannot answer these normative questions - science cannot tell us how we **should** form beliefs, only **how we do**.

For example, naturalized epistemology cannot tell us what makes evidence good, what beliefs count as being justified, what counts as a fallacy, what is rational to believe, and so on. According to Kim, belief isn't even possible without normative rules - to believe something, one needs a baseline of what counts as believable or not.

If a person believes that it's raining when it's sunny outside, naturalized epistemology would only tell us that the person is wrong, or what caused the wrongness. Epistemology must also be able to tell us what the person should believe instead, any why it is unjustified to think that it is raining.

Fundamentally, there is some egalitarian aspect to this sort of epistemology - beliefs are the same regardless of who thinks them. This is another one of the underlying assumptions in old and naturalized epistemology, though modern epistemology is more likely to take the individual into account.

Knowledge is valuable because it's a foundation to base our science on, according to old epistemology. According to Kim, what counts as justified is normative and cannot be deterined by science.

# 21/9/15

Readings: Kvanvig, Lackey

Assertion
---------

According to Kvanvig, knowledge is not valuable, so we should stop studying it.

Most philosophers agree that knowledge is better than opinion/belief, even if that belief happens to be true. One of these reasons is because the beliefs can be false, while knowledge cannot - **knowledge requires truth**.

Guessing the right answer on a multiple choice test is different from and worse than knowing the right answer. According to Socrates, belief is "untethered", while knowledge is "tethered" - **knowledge requires justification**.

This leads us to the Justified True Belief (JTB) - a working definition of knowledge as a belief that is both true and justified.

However, this definition is challenged by the **Gettier Problem**, which proposes situations where someone has justified true beliefs, but obviously doesn't have knowledge. These sitations are **Gettier situations**.

For example, you walk past a farm and see things that look exactly like sheep, and believed that there are sheep on the farm. Getting closer, you see that what you saw were actually dogs with long hair. However, there are actually sheep in another part of the farm. Arguably, you did not know that there are sheep on the farm, yet you had a justified true belief.

This implies that there is something more to knowledge - that it requires truth, justification, belief, and even more things. Trying to figure out what these criteria are is an ongoing problem, but Kvanvig says we shouldn't need to care about it.

Kvanvig says that the goal of epistemology is to figure out what the ultimate cognitive state for humans is, and knowledge is not that state. The ultimate state, he says, is that to be able to tell immediately and easily whether any claim that affects one's life is true or false, and that no cognitive mistakes could occur.

Kvanvig argues that it is possible to be in that state without knowing or even understanding what knowledge is. In the example Gettier situation, you had no knowledge that there is a sheep, but ended up correct anyways. Kvanvig says that ideal cognition is possible without knowledge - that you could accidentally get the right answer and it's just as good as knowing the right answer.

However, many object to this by saying that there are certain virtues to knowledge that accidentally true beliefs don't have. Are these virtues important in themselves? Answering a question correctly because of your own knowledge feels better than answering correctly by guessing.

An **assertion** is a claim that something is true. An objection to Kvanvig is that knowledge is needed as a basis for assertion. The **knowledge rule for assertion** says that one should only assert what one knows. Assertion is very practically useful, and if knowledge is the basis of assertion as per the knowledge rule for assertion, then knowledge is not useless, and is worth studying.

The knowledge rule for assertion is suppoorted by real-world usage of assertions. Intuitively, what we want to assert as true are things that are true - when we ask someone what the current time is, we want the right answer. We might also want to ask them how they came up with that answer - how did they get the current time? We can challenge assertions by presenting evidence that the assertion was false, or saying that there is no evidence that what they asserted is actually true. In other words, assertions are proper not when we are wrong, but when we don't have knowledge of what we assert.

Lackey presents **selfless assertion** - when someone makes an assertion without having any knowledge about it, but the assertion is still proper. In the case of askin someone what the current time is, Lackey says that the mind of the person being asked doesn't matter.

For example, a pediatrician who, in grief of his daughter being diagnosed with autism, starts believe that vaccines cause autism, even though he also respects the teachings of science. To his patients, he says that this is not the case, because he thinks that this is most likely to be true, and this is what is in the best interests of the patients. The argument is that the pediatrician does not believe something, and therefore did not have knowledge of something, but his assertion is still proper, even if the patients know that he doesn't have knowledge of what he is asserting. Basically, he believes one thing, but asserts another in the best interests of his patients.

In other words, selfless assertion challenges either the knowledge rule, or the idea that knowledge requires belief (this is supported by the pediatrician thinking that there being no connection is most likely to be true). Perhaps the pediatrician believes both (even though they are conflicting), or the "best interests" qualifier has some significance.

;wip: potentially a good topic for the paper is whether a better rule for assertion is whether what is asserted is in the best interests of people being asserted to

Another example is a Catholic teacher who believes in creationism, but still teaches students the evidence presented by science. Although the teacher's faith has her believe one thing, she asserts another, without having knowledge, and this seems to be a proper assertion. However, the examples provided so far have been quite complex, and it is important to consider other factors in play that could influence how we view the assertions or knowledge.

# 23/9/15

Readings: Turri

There are different types of speech acts, and each one have their own norms and rules. For example, guessing has different norms from speculating, conjecturing, asserting, promising, or guaranteeing. The norms and rules are what we are trying to define for each relevant speech act.

There are different types of normativity. **Constitutive normalivity** are the internal rules that consitute a practice - the rules that basically define the practice. **Moral normativity** are rules that say when a practice is morally permissible - the rules than define when we should do the practice. **Prudential normativity** are rules that say when a practice is prudent/wise - when it would be a good idea to do a practice.

For example, the rules of chess is contitutive normativity, while going easy on new chess players is moral normativity. If you have a bet that you will lose a chess game, it would be prudent to lose it in order to win the bet, and this is prudential normativity.

What is the constitutive norm of assertion? In other words, what is the fundamental rule of assertion? Do assertions need to be factive (requires truth)?

One factive account of assertion is the **truth rule** - one should assert something only if it's true, and knowledge/justification/belief is not necessary.

Another factive account is the **knowledge rule**, which we looked at earlier - one should assert something only if you know it, so that needs truth, belief, and evidence.

A non-fictive account is the **belief rule** - one should assert something only if one believes it, so it's still fine even if the assertion is totally false.

Another non-fictive account is the **justification rule** - one should assert something only one can justify it, so that needs belief and justification.

Lackey's account is non-factive, and modern literature tends to favor non-factive accounts. It feels like when people make well-justified assertions that turn out to be false, they didn't do anything wrong and are not to blame. In other words, there are **reasonable false assertions**.

For example, if we have 99.9% certainty that something would happen, it seems proper to assert it as true, even though we could turn out to be wrong - we should not be to blame for making such an assertion.

Turri's account is a factive one, and he argues for the knowledge rule. According to Turri, if assertion is rule governed, then we should look at how people are actually acting out these rules in real life, particularly people who are competent at using the language - we should obtain empirical evidence for rules governing assertion.

Turri conducted social psychology experiments, testing how people reacted to assertions in a game for whether people approve or disapprove of well justified false assertions, both when it turns out true, and when it turns out false.

As it turns out, people think false but justified assertions should not be made, even when that justification is very good. However, various objections to these results were raised, such as the experiment also measuring prudential/moral normativity rather than just constitutive normativity. Also, there was a sliding scale from "very wrong" to "very right", to eliminate the possibility of a false dichotomy.

In response, Turri conducted further experiments with different situations in order to eliminate variables. The reasoning was **excuse validation** - the maker of the false assertion has a reasonable excuse for being wrong. Turri concludes that factive accounts of assertion better explain people's reactions to assertions.

Interestingly, blame depends on character judgements of the person - when people perceived as good broke a rule, they were blamed less or not considered to have broken rules more often than people perceived as bad. In other words, people will simply say someone did not break the rule if they are not to blame, because blame is associated with punishment, and a blameless person doesn't deserve punishment.

# 28/9/15

Readings: Fantl, McGrath

We now look at the act of asserting itself. Do the practical consequences of acting affect justification?

For now, we will say that one is justified in believing something if one has good enough evidence to know it. We will assume that justification is required for knowledge.

**Evidentialism** is a theory of what justification is like, which states that whether one is justified in believing something depends only on **how much evidence is available** - the person believing doesn't matter, so two people with the same evidence should always have the save belief. Evidentialism ignores motives, pre-existing beliefs, and preconceptions in favor of following the evidence, and only the evidence.

However, Fantl and McGrath deny evidentialism - there are things other than evidence that can affect whether beliefs are justified and whether one has knowledge. For example, if you know X, it is no problem to act as if X. However, if it is a problem to act as if X, then you could explain it away as though you didn't know X, even though you did. The main idea is that if you know that something is true, then it is fine to act on it - it is rational to act on your knowledge. Also, if you're justified in beliecing something is true, then it is also fine to act on it.

However, how much is at stake affects how rational it is o perform certain actions - what is the cost of getting something wrong? For example, suppose we were vacationing, and we ask someone whether a train stops in Foxboro, and we don't really care if it's right or not. Since this is pretty good evidence that it does stop there, we would believe the person and get on the train. However, if we were on the way to a critical job interview, we would probably double check just in case. In this case, the evidence is not good enough to believe the person, and would get more evidence instead.

In other words, in one case it is rational to believe the justification, and in another case it is not - so in one case, your belief is justified, and in another, it is not, even though there is exactly the same evidence in both cases. This implies that there is more than just evidence at play in belief and actions. This is at odds with evidentialism - perhaps each person actually has their own personal threshold of justification.

The rationality of acting, according to Fantl and McGrath, sets the standard for how much evidence is needed in order to know or be justified in believing something. In their example, the stakes of the situation influence whether a belief is justified.

# 30/9/15

Readings: Buckwalter, Turri

The accepted norm of assertion is knowledge - you should assert something only if you know it. This is supported by empirical studies of assertion in the real world, as discussed earlier. In the real world, showing is more costly than telling - so if knowledge is important for showing (asserting), it should also be important for showing.

In other words, if knowledge is the norm of assertion, is knowledge also the norm of showing? The readings seem to suggest that yes, this is the case - **we should only show something if we know it**:

* "How is this done?" (asking for instruction/demonstration/showing) is similar to "do you know how this is done?" (asking for the presence of knowledge), just like "what is this?" works like "do you know what this is?". If one knows, then one can show.
* Saying "I don't know how to do this" is a legitimate reason to not demonstrate it. If you don't know how to do something, it tells everyone that you should not need to demonstrate it. Without knowledge, one should not show.
* "How do you know that?" challenges one's authority, and implicitly requests a demonstration. Challenges to knowledge are challenges to demonstrate.
* Being able to show something, but not knowing how to do something seems inconsistent - saying "I don't know how to drive" while driving perfectly seems weird. Showing something seems to imply knowing something.

If knowledge is the norm of both showing and telling, knowledge is also the norm of instruction - the criteria by which we should decide whether to transmit information.

An interesting thing to consider is muscle memory - if muscle memory is knowledge, then it is possible to have knowledge without belief, justification, or truth. For example, muscle memory might store the relationship between the gas pedal and the current acceleration, but one need not even believe that the gas pedal affects acceleration to act on it.

"Descartes' Schism, Locke's Reunion" looks at whether things like the train thought experiments held up empirically. Descartes' view is that knowledge is completely separate from action, while Locke states that they are intricately linked.

Locke basically says that knowledge is truth, evidence, belief, and practical factors - practical factors directly influene knowledge. Descartes basically says that knowledge is truth, evidence, and belief, all of which are affected by practical factors - practical factors are removed from knowledge. We want to test these empirically, using psychological and sociological experiments.

These experiments tested things like how knowledge was affected by two identical sitations with different stakes, as well as many other variables. Each of the 600+ particupants were given situations with different stakes, and then questioned regarding the state of belief, truth, evidence, action, knowledge, and importance.

As it turns out, stakes had a negative correlation with action, truth, and evidence, and these in turn had a positive correlation with knowledge. So if the stakes are high, actionability, confidence in truth, and amount of evidence are decreased, and if they are low they are all increased. Acting had the most significant impact on having knowledge, truth a little less, but evidence a lot less.

So essentially, action does have a direct impact on knowledge, like Locke's model, but the stakes are also somewhat removed from knowledge, like Descartes' model. So the ability to act on something had the largest impact on whether one thinks one has knowledge. Note that since this experiment only measures correlation, it doesn't tell us anything about which way the knowledge/action link goes - does knowledge result in actionability, or does actionability imply knowledge?

# 5/10/15

Readings: Fricker, Lackey

Testimony
---------

We want to investigate the relationship between knowledge, and the person hearing it - in particular, what is testimony, when should be believe it, and when does it count as knowledge?

Justification is necessary for knowledge. Justification, in turn, is done through good evidence - from memory, observation, reasoning, and testimony.

In legal systems, testimony is rigidly defined and is given on the witness stand. For us, giving testimony is making an assertion, claim, or presents something as true. Where we previously looked at the speaker's side (when we should say something), we will now look at the listener's side (when we should believe something).

A **testimonial belief** is a belief formed by testimony. Most of our beliefs actually seem to be testimonial beliefs. When we believe things people say, we seem to often gain real knowledge, often without us thinking about it much at all. We also seem to sometimes gain false beliefs, and our goal is to find a criteria for belief that helps us gain only real knowledge.

One informal one people often use is the speaker's track record - how good their testimony has been in the past. Others include the stakes, relationship with the speaker, and the motives of the speaker.

According to **reductionism**, testimonial beliefs are justified in the same way as any other source of evidence, like induction, past observations, and reasoning - **testimony is not special**. **Anti-reductionism** is the opposite view - that testimonial beliefs are justified by a special principle.

Fricker investigates the reductionist/anti-reductionist distinction, and argues for reductionism.

The **PR thesis** is presented as a principle for justifying testimonial beliefs, in favour of anti-reductionism: that hearers of testimony can assume, without other evidence, that the speaker is trustworthy, unless there are special circumstances that prevent this (like the speaker not being in the right state of mind, or known to say false things often). In other words, listeners can just assume the speakers are trustworthy, unless given a good reason not to.

Fricker criticizes this by saying that hearers are never justified in simply trusting speakers - according to Fricker, hearers of testimony should always assess the speakers for trustworthiness. In other words, gullible/blind beliefs are not justified. Instead, hearers should **critically assess** the testimony, be able to **explain the testimony in their own words**, and be able to **defend the beliefs formed from the testimony**. This is called the **NC thesis** (negative claim).

This is a very internal view - all the criteria are judged in the mind of the hearer.

One objection to this is that it is often not possible for hearers of testimony to independently confirm that speakers are trustworthy - it is unrealistic to expect hearers to evaluate all these criteria. Fricker responds that it is realistic - people actually are always evaluating trustworthiness subconsciously, and this affects our evaluations of speakers' trustworthiness. **Counterfactuals** are essentially thoughts about hypothetical situations - thoughts about "what would happen if X happened instead of Y?". According to Fricker, testimonial justification requires **counterfactual sensitivity** - thinking about "what if the speaker is untrustworthy?" and "if they were untrustworthy, would I have spotted that?". Basically, testimonial belief is justified when the hearer would be able to tell if the speaker is being untrustworthy.

Fricker's evidence for the NC thesis is mostly common sense and ordinary/everyday experiences, and normative linguistic theories - is this good enough evidence to support the thesis? Also, this doesn't tell us how much evidence we need, or how trustworthy speakers must be before forming beliefs.

One interesting case is self-knowledge (assertions about the speaker's own experiences). In these cases, hearers generally simply trust what the speakers say, and it isn't really possible to critically assess the trustworthiness in this case. Also, should be assess strangers more heavily than trusted friends? Are there some roles when the critical assessment is already done for you (for example, when a doctor tells a patient to do something)?

Lackey investigates the properties of testimony transfer - is testimony like passing a baton? In other words, can hearers get knowledge from the speaker even if the speaker doesn't have that knowledge?

Basically, Lackey talks about whether testimony simply transmits knowledge, or whether it can actually generate new knowledge, and argues for the latter. For example, a creationist teacher that teaches evolution (despite not believing it) doesn't have knowledge of the material (she is simply following orders), yet it seems like the students can obtain knowledge, even though the speaker doesn't have knowledge.

;wip: critical response topic: knowledge cannot be generated by testimony, because if the speaker doesn't have knowledge then the hearer doesn't have justification in JTB.

# 7/10/15

A **defeater** is something that defeats evidence - it takes away confidence in evidence that one has. When people make testimony, sometimes the defeaters don't get transferred - people may not transmit counterarguments, conflicting facts, and other things that might throw the evidence into question

An interesting case of testimony: person A has good vision, but the person's doctor tells them that their vision is unreliable. Person A sees X, and tells person B as such, but does not tell person B that the doctor said person A's vision is unreliable. Person A's evidence of seeing X is defeated by the doctor's statement. However, from person B's perspective, there is nothing wrong with the evidence.

Lackey concludes, from these and other situations, that testimony can actually generate knowledge, in contrast to memory, which can only preserves knowledge.

Does the way testimony work depend on what you're talking about? Hazlett investigates this by looking at several case studies.

If someone knows a lot about football, and you ask them who won a particular game, you would probably accept the answer on the basis of testimony alone. If someone knows a lot about ethics, and you ask them whether military intervention in some country is right, you would probably not accept the answer on the basis of testimony alone.

These two situations have the same form, with only the content changed. Perhaps it's because there's just so many possible options that need to be weighed to make a decision in the latter case, or there is a difference when there are multiple plausible answers?

If someone knows a lot about art, and you ask them whether a piece of art is beautiful, it doesn't really make sense. If someone knows a lot about metaphysics, and you ask them whether god exists, you would probably not accept the answer on the basis of testimony alone.

Hazlett says there are different types of testimony, including factual testimony ("what is this thing?"), ethical testimony ("is this thing right?"), aesthetic testimony ("is this thing beautiful?"), religious testimony ("does god exist?"), and so on. In each type of testimony, there seems to be different norms. When the content of testimony is about ethics, religion, or aesthetics, there seems to be something wrong about forming beliefs based on just that testimony - there is **testimonial asymmetry**.

Hazlett assumes testimonial asymmetry exists, and attempts to diagnose the cause. For children, moral/religious/aesthetic testimony seems to be fine - parents telling children what's right or wrong seems to be good testimony.

This view is non-reductionist in that the good/bad judgement is for the testimony itself, not about the beliefs that cause the testimony. Hazlett proposes a few theories of the causes of some testimony being different.

By understanding theory, moral/religious/aesthetic knowledge requires understanding in addition to just facts, and understanding cannot be transferred via testimony.

By acquaintance theory, moral/religious/aesthetic knowledge requires acquaintance with the subjects - perception and experience with the things being talked about, that also can't be transferred via testimony.

By virtue theory, moral/religious/aesthetic knowledge requires virtues, such as the virtue of figuring this out for oneself, a virtue that cannot be transferred via testimony.

Basically, these theories push the testimonial asymmetry into knowledge asymmetry. Hazlett rejects all of these, and proposes a social theory instead: moral/religious.aesthetic knowledge is socially valuable, and testimony cannot transfer the social value via testimony - beliefs are not worth as much when they were just formed by testimony, since they reduce diversity of knowledge. In other words, testomonial beliefs are bad when they are bad for society.

;wip: critical response idea: testimonial asymmetry: testimony seems to be good if and only if we expect the speaker to have knowledge about the topic they are talking about

# 14/10/15

The second critical response is due next wednesday.

Readings: Huemer

Memories
--------

When are memory beliefs justified? When should we believe in our memories?

Just like through testimony and observation, memory is a way to get justification, which is important for obtaining knowledge.

The majority of what we believe comes from our memories. Often, our knowledge comes from information stored in our brains. However, we can sometimes remember something very accurately as true, when it's actually false.

We believe that the sun is around 93 million miles from the Earth. However, most of us don't remember what our original reason for memorising this is.

Huemer has three possible answers to when we should believe our memories - inferential, foundational, and preservative. Huemer then rejects them in favor of a dualistic view.

In the inferential theory, memory beliefs are justified by that memory being reliable in the past - if it worked out in the past, then we are justified in believing it. However, this theory is rather circular - the only things that tell us that a memory was reliable are our other memories. If we use only our present experiences and insights, it's unlikely we could judge whether memories are reliable under this theory.

In the foundational theory, memories are the foundation of justification, and just as we usually trust perception, we should also usually trust remembering something - remembering something automatically gives a good reason to believe it. However, the passage of time alone shouldn't make false beliefs justified - it's easy to create a memory of an unjustified belief, and then say it's justified because it's a memory.

In the preservation theory, memory preserves the original justification of the belief - whatever the justification for the original belief was is also the justification for memory beliefs. Even if one does not remember what the original justification was for believing something, the belief is still justified. However, if someone gets cloned, the clone remembers doing all the things the original did, without actually having done those things - the clone should have justification to believe it did those things, since it has all the memories of the original, but under this theory it does not.

The dualistic theory takes parts of all of these theories. It focuses on a few issues with the other ones: beliefs can't increase in justification just by becoming memories, and justification should depend only on the current state of people - if clones have the same memory, they should also have the same justification.

According to Huemer, the justification for believing a memory belief is the justification for forming the belief in the first place, combined with the justification in being confident that the memory was retained correctly over time. The justifications of the two, both numbers between 0 and 1 (where 0 is infallible justification that something is false and 1 is that something is true), are multiplied together to get the overall justification.

This is somewhat similar to what foundational theory and preservation theory says, but also taking memory retention into account.